{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkcbg-cY760"
      },
      "source": [
        "Загрузки для работы модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhE3pNnuY5qA",
        "outputId": "ed68b5a9-3d1a-4b55-ea5f-f046827b0f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eH898o0q-wN",
        "outputId": "83e19aa4-bb3b-445b-dc00-d9a3789bcc2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (3.1.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.10.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1kK9WlyeU07"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXH061vJgcDG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W81vyjJa0ZK-"
      },
      "source": [
        "## Add data to colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "5294e3094caa4e7abe9488c6c709d856",
            "60ec4f97e5c54f09927a2d2373458de1",
            "931136fc999a40fd96cf428afaa962be",
            "afd9ae1e4d3e4d468889c2325e3ac6f8",
            "412a60fcde884ed993689dcce6c0ab62",
            "3f954257da634a47b046c0bdaf2ca5ab",
            "16ab1d4c13d14a4b913d1fc3435e5e9b",
            "681d57b5dd4c4b908022ca96a21b0c69",
            "70f1590987954c82b1e40279d60f7367",
            "79f93bdb01ed4a08b82fc5c2436aea38",
            "a1822046aa60417b9a591d1d1f9bffbc"
          ]
        },
        "id": "mngE6wD2bskh",
        "outputId": "bd3ee7ed-7331-4c62-8788-b3e8a41c0981"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset arxiv-summarization (/root/.cache/huggingface/datasets/ccdv___arxiv-summarization/document/1.0.0/fa2c9abf4312afb8660ef8e041d576b8e3943ea96ae771bd3cd091b5798e7cc3)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5294e3094caa4e7abe9488c6c709d856",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "arxiv = load_dataset('ccdv/arxiv-summarization', \"document\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FEnzaVWebkQ",
        "outputId": "dce429ef-cfbc-48b2-8fc2-47caeeac93a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'abstract'],\n",
              "        num_rows: 203037\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'abstract'],\n",
              "        num_rows: 6436\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'abstract'],\n",
              "        num_rows: 6440\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TyYxrXyeFhm"
      },
      "outputs": [],
      "source": [
        "arxivsum_train = arxiv['train'].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnO1bnfu0sqs"
      },
      "outputs": [],
      "source": [
        "# arxivsum_test = arxiv['test'].to_pandas()\n",
        "arxivsum_validation = arxiv['validation'].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56Ih3XsVTdfM"
      },
      "outputs": [],
      "source": [
        "arxivsum_train_small = arxivsum_train[:5000]\n",
        "arxivsum_validation_small = arxivsum_train[:1500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-V1cj2gd56k"
      },
      "source": [
        "## тут лежит текст на котором тестирую"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQxO3cLsxHxG"
      },
      "outputs": [],
      "source": [
        "text_test = 'studies of laser beams propagating through turbulent atmospheres are important for many applications such as remote sensing , tracking , and long - distance optical communications . howerver , fully coherent laser beams are very sensitive to fluctuations of the atmospheric refractive index . the initially coherent laser beam acquires some properties of gaussian statistics in course of its propagation through the turbulence . as a result , the noise / signal ratio approaches unity for long - distance propagation . ( see , for example , refs.@xcite-@xcite ) . this unfavourable effect limits the performance of communication channels . to mitigate this negative effect the use of partially ( spatially ) coherent beams was proposed . the coherent laser beam can be transformed into a partially coherent beam by means of a phase diffuser placed near the exit aperture . this diffuser introduces an additional phase ( randomly varying in space and time ) to the wave front of the outgoing radiation . statistical characteristics of the random phase determine the initial transverse coherence length of the beam . it is shown in refs . @xcite,@xcite that a considerable decrease in the noise / signal ratio can occur under following conditions : ( i ) the ratio of the initial transverse coherence length , @xmath0 , to the beam radius , @xmath1 , should be essentially smaller than unity ; and ( ii ) the characteristic time of phase variations , @xmath2 , should be much smaller than the integration time , @xmath3 , of the detector . however , only limiting cases @xmath4 and @xmath5 have been considered in the literature . ( see , for example , refs . @xcite,@xcite and ref . @xcite , respectively ) . it is evident that the inequality @xmath6 can be easily satisfied by choosing a detector with very long integration time . at the same time , this kind of the detector can not distinguish different signals within the interval @xmath3 . this means that the resolution of the receiving system might become too low for the case of large @xmath3 . on the other hand , there is a technical restriction on phase diffusers : up to now their characteristic times , @xmath2 , are not smaller than @xmath7 . besides that , in some specific cases ( see , for example , ref . @xcite ) , the spectral broadening of laser radiation due to the phase diffuser ( @xmath8 ) may become unacceptably high . the factors mentioned above impose serious restrictions on the physical characteristics of phase diffusers which could be potentially useful for suppressing the intensity fluctuations . an adequate choice of diffusers may be facilitated if we know in detail the effect of finite - time phase variation , introduced by them , on the photon statistics . in this case , it is possible to control the performance of communication systems . in what follows , we will obtain theoretically the dependence of scintillation index on @xmath9 without any restrictions on the value of this ratio this is the main purpose of our paper . further analysis is based on the formalism developed in ref . @xcite and modified here to understand the case of finite - time dynamics of the phase diffuser . the detectors of the absorbed type do not sense the instantaneous intensity of electromagnetic waves @xmath10 . they sense the intensity averaged over some finite interval @xmath3 i.e. @xmath11 usually , the averaging time @xmath3 ( the integration time of the detector ) is much smaller than the characteristic time of the turbulence variation , @xmath12 , ( @xmath13 ) . therefore , the average value of the intensity can be obtained by further averaging of eq . [ one ] over many measurements corresponding various realizations of the refractive - index configurations . the scintillation index determining the mean - square fluctuations of the intensity is defined by @xmath14\\\\bigg /\\\\big < \\\\bar{i}\\\\big > ^2= \\\\frac{\\\\big < : \\\\bar i(t ) ^2:\\\\big>}{\\\\big<\\\\bar i \\\\big>^2}-1,\\\\ ] ] where the symbol @xmath15 indicates the normal ordering of the creation and annihilation operators which determine the intensity , @xmath10 . ( see more details in refs . @xcite,@xcite ) . the brackets @xmath16 indicate quantum - mechanical and atmospheric averagings . the intensity @xmath17 depends not only on @xmath18 , but also on the spatial variable @xmath19 . therefore , the detected intensity is the intensity @xmath20 averaged not only over @xmath18 as in eq . [ one ] , but also over the detector aperture . for simplicity , we will restrict ourselves to calculations of the intensity correlations for coinciding spatial points that correspond to `` small \\'\\' detector aperture . this simplification is quite reasonable for a long - distance propagation path of the beam .    in the case of quasimonochromatic light , we can choose @xmath20 in the form @xmath21 where @xmath22 and @xmath23 are the creation and annihilation operators of photons with momentum @xmath24 . they are given in the heisenberg representation . @xmath25 is the volume of the system . it follows from eqs . [ two],[three ] that @xmath26 can be obtained if one knows the average @xmath27 it is a complex problem to obtain this value for arbitrary turbulence strengths and propagation distances . nevertheless , the following qualitative reasoning can help to do this in the case of strong turbulence . we have mentioned that the laser light acquires the properties of gaussian statistics in the course of its propagation through the turbulent atmosphere . as a result , in the limit of infinitely long propagation path , @xmath28 , only diagonal \" terms , i.e. terms with ( i ) @xmath29 or ( ii ) @xmath30 , @xmath31 contribute to the right part of eq . [ four ] . for large but still finite @xmath28 , there exist small ranges of @xmath32 in case ( i ) and @xmath33 , @xmath34 in case ( ii ) contributing into the sum in eq . the presence of the mentioned regions is due to the two possible ways of correlating of four different waves ( see ref . @xcite ) which enter the right hand side of eq . [ four ] . as explained in ref . @xcite , the characteristic sizes of regions ( i ) and ( ii ) depend on the atmospheric broadening of beam radii as @xmath35 , thus decreasing with increasing @xmath28 . in the case of long - distance propagation , @xmath36 is much smaller than the component of photon wave - vectors perpendicular to the @xmath28 axis . the last quantity grows with @xmath28 as @xmath37 . ( see ref . @xcite ) . for this reason , the overlapping of regions ( i ) and ( ii ) can be neglected . in this case eq . [ four ] can be rewritten in the convenient form : @xmath38 @xmath39 where the value @xmath40 , confining summation over @xmath41 , is chosen to be greater than @xmath42 but much smaller than the characteristic transverse wave vector of the photons ; this is consistent with the above explanations . the two terms in the right - hand side correspond to the two regions of four - wave correlations . the quantity @xmath43 entering the right side of eq . [ five ] is the operator of photon density in phase space ( the photon distribution function in @xmath44 space ) . it was used in refs . @xcite,@xcite and @xcite for the description of photon propagation in turbulent atmospheres . by analogy , we can define the two - time distribution function @xmath45 then eq . [ five ] can be rewritten in terms of the distribution functions as @xmath46    let us represent @xmath47 in the form @xmath48 . we assume that @xmath49 , as explained in the text after eq.[one ] . in this case the hamiltonian of photons in a turbulent atmosphere can be considered to be independent of time . as a result , both functions defined by eqs . [ six ] and [ seven ] satisfy the same kinetic equation , i.e.    @xmath50 @xmath51 where @xmath52 is the photon velocity , @xmath53 is a random force , caused by the turbulence . this force is equal to @xmath54 , where @xmath55 is the frequency of laser radiation . @xmath56 is the refractive index of the atmosphere . the general solution of the equation for @xmath48 can be written in the form @xmath57 where @xmath58 @xmath59 the functions @xmath60 and @xmath61 obey the equations of motion @xmath62 with the boundary conditions @xmath63 . the instant @xmath64 is equal to @xmath65 , where @xmath66 is the speed of light . @xmath64 is the time of the exit of photons from the source . this choice of @xmath64 makes it possible to neglect the influence of the turbulence on the initial values of operators @xmath67 ( their dependence on time is as in vacuum ) . the term for @xmath68 can be obtained from eq . [ twelve ] by putting @xmath69 . substituting both distribution functions into eq . [ eight ] , we obtain @xmath70 @xmath71 @xmath72:\\\\big>,\\\\ ] ] where @xmath73 and @xmath74 are solutions of eqs . [ twelve ] with the initial conditions @xmath63 and @xmath75 , respectively . the operators on the right side of eq . [ thirteen ] are related through matching conditions with the amplitudes of the exiting laser radiation ( see ref . @xcite ) by the relation @xmath76 where @xmath77 is the operator of the laser field which is assumed to be a single - mode field and the subscript ( @xmath78 ) means perpendicular to the @xmath28-axis component . the function @xmath79 describes the profile of the laser mode , which is assumed to be gaussian - type function [ @xmath80 . @xmath1 desribes the initial radius of the beam .    to account for the effect of the phase diffuser , a factor @xmath81 or @xmath82 should be inserted into the integrand of eq . [ fourteen ] . the quantity @xmath83 is the random phase introduced by the phase diffuser . a similar consideration is applicable to each of four photon operators entering both terms in square brackets of eq . [ thirteen ] . it can be easily seen that the factor @xmath84},\\\\ ] ] describing the effect of phase screen on the beam , enters implicitly the integrand of eq . [ thirteen ] ( the indices @xmath78 are omitted here for the sake of brevity ) . there are integrations over variables @xmath85 as shown in eq . [ fourteen ] . furthermore , the brackets @xmath16 , which indicate averaging over different realizations of the atmosperic inhomogeneities , also indicate averaging over different states of the phase diffuser . as long as both types of averaging do not correlate , the factor ( [ fifteen ] ) entering eq . [ thirteen ] must be averaged over different instants , @xmath64 . to begin with , let us consider the simplest case of two phase correlations @xmath86}\\\\big > .\\\\ ] ] it is evident that in the case @xmath87 , as shown schematically in fig . 1 , the factor ( [ sixteen ] ) is sizable if only points @xmath19 and @xmath88 are close to one another . two curves correspond to different instants @xmath18 and @xmath89 . ]    therefore , the term given by eq . [ sixteen ] can be replaced by @xmath90 where @xmath91 is considered to be a gaussian random variable with the mean - square values given by @xmath92 ^ 2\\\\rangle =   \\\\langle [ \\\\frac { \\\\partial \\\\varphi ( { \\\\bf r},t_0)}{\\\\partial y}]^2\\\\rangle = 2\\\\lambda _ c^{-2}$ ] , where @xmath93 is the correlation length of phase fluctuations . ( see fig.1 ) . as we see , in this case the effect of phase fluctuations can be described by the schell model @xcite-@xcite,@xcite-@xcite .    a somewhat more complex situation is for the average value of @xmath94 given by eq . [ fifteen ] . there is an effective phase correlation not only in the case of coincident times , but also for differing times . for @xmath95 , two different sets of coordinates contribute considerably to phase correlations . this can be described mathematically as @xmath96}\\\\big > \\\\approx \\\\big < e^{i[\\\\varphi ( { \\\\bf r},t_0)-\\\\varphi   ( { \\\\bf r^\\\\prime},t_0)]}\\\\big > \\\\times\\\\ ] ] @xmath97}\\\\big > + \\\\big < e^{i[\\\\varphi ( { \\\\bf r},t_0)-\\\\varphi   ( { \\\\bf r^\\\\prime _ 1},t_0+\\\\tau ) ] } \\\\big > \\\\big < e^{i[\\\\varphi ( { \\\\bf r_1},t_0+\\\\tau ) -\\\\varphi   ( { \\\\bf r^\\\\prime } , t_0)]}\\\\big > .\\\\ ] ] repeating the arguments leading to eq . [ seventeen ] , we represent the difference in the last term @xmath98 as @xmath99 then , considering the random functions @xmath100 and @xmath101 as independent gaussian variables , we obtain a simple expression for @xmath102 . it is given by @xmath103}+ e^{-\\\\lambda _ c^{-2}[({\\\\bf r - r^\\\\prime}_1)^2+({\\\\bf r^\\\\prime -r_1})^2]-2\\\\nu^2\\\\tau ^2},\\\\ ] ] where @xmath104 ^ 2\\\\rangle = 2\\\\nu^2 $ ] .    as we see , the effect of the phase screen can be described by two parameters , @xmath93 and @xmath105 , which characterize the spatial and temporal coherence of the laser beam . in the limiting case , @xmath106 , the second term in eq . [ twenty ] vanishes and the problem is reduced to the case considered in refs . @xcite,@xcite . in the opposite case , @xmath107 , both terms in eq . [ twenty ] are important . this is shown in ref . @xcite . in what follows , we will see that these two limiting cases have physical interpretations where where @xmath108 ( slow detector ) and @xmath109 ( fast detector ) , respectively . there is a specific realization of the diffuser in which a random phase distribution moves across the beam . ( this situation can be modeled by a rotating transparent disk with large diameter and varying thickness . ) the phase depends here on the only variable @xmath110 , i.e. @xmath111 where @xmath112 is the velocity of the drift . then we have @xmath113}+e^{-\\\\lambda _ c^{-2}[({\\\\bf r - r^\\\\prime_1+v}\\\\tau)^2+({\\\\bf r^\\\\prime -r_1+v}\\\\tau)^2]}.\\\\ ] ] comparing eqs . [ twenty ] and [ twtw ] , we see that the quantity , @xmath114 , stands for the characteristic parameter describing the efficiency of the phase diffuser . the criterion of  slow \" detector requires @xmath115 . qualitatively , the two scenarios of phase variations , given by eqs . [ twenty ] and [ twtw ] , affect in a similar way the intensity fluctuations . in what follows , we consider the first of them as the simplest one . ( this is because the spatial and temporal variables in @xmath102 , given by eq . [ twenty ] , are separable . ) _ vs _ propagation distance @xmath28 in the case of `` slow \\'\\' detector : @xmath116 . the parameter @xmath117 indicates different initial coherence length . in the absence of phase diffuser @xmath118 ( solid line ) . @xmath119 is the conventional parameter describing a strength of the atmospheric turbulence . ] substituting the expressions for operators given by eq . [ fourteen ] with account for the phase factors @xmath120 and averaging over time as shown in eq . [ one ] , we obtain @xmath121 @xmath122\\\\bigg > , \\\\ ] ] where the notation @xmath16 after sums indicates averaging over different realizations of the atmospheric refractive index . the parameter @xmath123 describes the initial coherence length modified by the phase diffuser . other notations are defined by following relations @xmath124 @xmath125 @xmath126 further calculations follow the scheme described in ref @xcite . 2 illustrates the effect of the phase diffuser on scintillations in the limit of a  slow \" detector ( @xmath127 ) . we can see a considerable decrease in @xmath128 caused by the phase diffuser . at the same time , the effect of the phase screen on @xmath128 becomes weaker for finite values of @xmath129 . moreover , comparing the two upper curves in fig . 3 , we see the opposite effect : slow phase variations ( @xmath130 ) result in increased scintillations . there is a simple explanation for this phenomenon : the noise generated by the turbulence is complemented by the noise arising from the random phase screen . the integration time of the detector , @xmath3 , is not sufficiently large for averaging phase variations generated by the diffuser . the function , @xmath131 , has a very simple form in the two limits : ( i)@xmath132 , when @xmath133 ; and ( ii ) @xmath134 , when @xmath109 . then , in case ( i ) and for small values of the initial coherence [ @xmath135 , the asymptotic term for the scintillation index ( @xmath136 ) is given by @xmath137 the right - hand side of eq . [ twfo ] differs from analogous one in ref . @xcite by the value @xmath138 that is much less than unity but , nevertheless , can be comparable or even greater than @xmath139 .    in case ( ii ) , the asymptotic value of @xmath26 is close to unity , coinciding with the results of refs . @xcite and @xcite . this agrees with well known behavior of the scintillation index to approach unity for any source distribution , provided the response time of the recording instrument is short compared with the source coherence time . ( see , for example , survey @xcite ) . a similar tendency can be seen in both figs . 3 and 4 : the curves with the smallest @xmath129 , used for numerical calculations ( @xmath130 ) , are close to the curves  without diffuser \" in spite of the small initial coherence length [ @xmath140 . it can also be seen that all curves approach their asymptotic values very slowly . describing diffuser dynamics . the solid curve is calculated for @xmath118 ( without diffuser ) . other curves are for @xmath141 . ]    . ] it follows from our analysis that the scintillation index is very sensitive to the diffuser parameters , @xmath0 and @xmath142 , for long propagation paths . on the other hand , the characteristics of the irradience such as beam radius , @xmath143 , and angle - of - arrival spread , @xmath144 , do not depend on the presence of the phase diffuser for large values of @xmath28 . to see this , the following analysis is useful . the beam radius expressed in terms of the distribution function is given by @xmath145 straightforward calculations using eq . [ ten ] with @xmath69 ( see ref . @xcite ) result in the following explicit form : @xmath146 where @xmath147 and @xmath148 is the inner radius of turbulent eddies , which in our previous calculations was assumed to be equal @xmath149 m . as we see , the third term does not depend on the diffuser parameters and it dominates when @xmath150 . a similar situation holds for the angle - of - arrival spread , @xmath144 . ( this physical quantity is of great importance for the performance of communication systems based on frequency encoded information @xcite . ) it is defined by the distribution function as @xmath151 simple calculations , which are very similar to those while obtaining @xmath152 , result in @xmath153 ^ 2=\\\\frac 2{r_1 ^ 2q_0 ^ 2}+12tz-\\\\frac { 4z^2}{q_0 ^ 4r^2}(r_1^{-2}+3tq_0 ^ 2z)^2.\\\\ ] ] for long propagation paths , . [ twei ] reduces to @xmath154 , which like @xmath152 does not depend on the diffuser parameters . as we see , for large distances @xmath28 , the quantities @xmath152 and @xmath144 do not depend on @xmath93 and @xmath105 . this contrasts with the case of the scintillation index . so pronounced differences can be explained by differences in the physical nature of these characteristics . it follows from eq . [ two ] that the functional , @xmath26 , is quadratic in the distribution function , @xmath155 . hence , four - wave correlations determine the value of scintillation index . the main effect of a phase diffuser on @xmath26 is to destroy correlations between waves exited at different times . ( see more explanations in ref . this is achieved at sufficiently small parameters @xmath93 and @xmath156 . in contrast , @xmath152 and @xmath144 depend on two wave - correlations , both waves being given at the same instant . therefore , the values of @xmath152 and @xmath144 do not depend on the rate of phase variations [ @xmath105 does not enter the factor ( [ seventeen ] ) describing the effect of phase diffuser ] . moreover , these quantities become independent of @xmath93 at long propagation paths because light scattering on atmospheric inhomogeneities prevails in this case . the plots in figs . 3 anf 4 show that the finite - time effect is quite sizable even for very  slow \" detectors ( @xmath157 ) . our paper makes it possible to estimate the actual utility of phase diffusers in several physical regimes . we have analyzed the effects of a diffuser on scintillations for the case of large - amplitude phase fluctuations . this specific case is very convenient for theoretial analysis because only two parameters are required to describe the effects of the diffuser . phase fluctuations may occur independently in space as well as in time . also , our formalism can be applied for the physical situation in which a spatially random phase distribution drifts across the beam . [ twtw ] . ) our results show the importance of both parameters , @xmath93 and @xmath142 , on the ability of a phase diffuser to suppress scintillations . this work was carried out under the auspices of the national nuclear security administration of the u.s . department of energy at los alamos national laboratory under contract no . de - ac52 - 06na25396 . we thank onr for supporting this research .'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNpeVMbWeMzp"
      },
      "outputs": [],
      "source": [
        "abstract = 'the effect of a random phase diffuser on fluctuations of laser light ( scintillations ) is studied . not only spatial but also temporal phase variations introduced by the phase diffuser are analyzed . the explicit dependence of the scintillation index on finite - time phase variations is obtained for long propagation paths . it is shown that for large amplitudes of phase fluctuations , a finite - time effect decreases the ability of phase diffuser to suppress the scintillations .'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THsEUI9PeXVQ"
      },
      "outputs": [],
      "source": [
        "text_start = 'studies of laser beams propagating through turbulent atmospheres are important for many applications such as remote sensing , tracking , and long - distance optical communications . howerver , fully coherent laser beams are very sensitive to fluctuations of the atmospheric refractive index . the initially coherent laser beam acquires some properties of gaussian statistics in course of its propagation through the turbulence . as a result , the noise / signal ratio approaches unity for long - distance propagation . ( see , for example , refs.@xcite-@xcite ) . this unfavourable effect limits the performance of communication channels . to mitigate this negative effect the use of partially ( spatially ) coherent beams was proposed . the coherent laser beam can be transformed into a partially coherent beam by means of a phase diffuser placed near the exit aperture . this diffuser introduces an additional phase ( randomly varying in space and time ) to the wave front of the outgoing radiation . statistical characteristics of the random phase determine the initial transverse coherence length of the beam . it is shown in refs . @xcite,@xcite that a considerable decrease in the noise / signal ratio can occur under following conditions : ( i ) the ratio of the initial transverse coherence length , @xmath0 , to the beam radius , @xmath1 , should be essentially smaller than unity ; and ( ii ) the characteristic time of phase variations , @xmath2 , should be much smaller than the integration time , @xmath3 , of the detector . however , only limiting cases @xmath4 and @xmath5 have been considered in the literature . ( see , for example , refs . @xcite,@xcite and ref . @xcite , respectively ) . it is evident that the inequality @xmath6 can be easily satisfied by choosing a detector with very long integration time . at the same time , this kind of the detector can not distinguish different signals within the interval @xmath3 . this means that the resolution of the receiving system might become too low for the case of large @xmath3 . on the other hand , there is a technical restriction on phase diffusers : up to now their characteristic times , @xmath2 , are not smaller than @xmath7 . besides that , in some specific cases ( see , for example , ref . @xcite ) , the spectral broadening of laser radiation due to the phase diffuser ( @xmath8 ) may become unacceptably high . the factors mentioned above impose serious restrictions on the physical characteristics of phase diffusers which could be potentially useful for suppressing the intensity fluctuations . an adequate choice of diffusers may be facilitated if we know in detail the effect of finite - time phase variation , introduced by them , on the photon statistics . in this case , it is possible to control the performance of communication systems . in what follows , we will obtain theoretically the dependence of scintillation index on @xmath9 without any restrictions on the value of this ratio this is the main purpose of our paper . further analysis is based on the formalism developed in ref . @xcite and modified here to understand the case of finite - time dynamics of the phase diffuser . the detectors of the absorbed type do not sense the instantaneous intensity of electromagnetic waves @xmath10 . they sense the intensity averaged over some finite interval @xmath3 i.e. @xmath11 usually , the averaging time @xmath3 ( the integration time of the detector ) is much smaller than the characteristic time of the turbulence variation , @xmath12 , ( @xmath13 ) . therefore , the average value of the intensity can be obtained by further averaging of eq .'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5L2sZkfFl22"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-LDK9R-Fphv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b5bUJsHrxYq"
      },
      "source": [
        "## Prepare a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8EB7wDWhop3",
        "outputId": "12c15905-1a10-4a8d-a952-e310f07138e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-f018b889821c>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  arxivsum_train_small['text'] = '<s>Article:' +arxivsum_train_small['article'] +'\\nAbstract:' + arxivsum_train_small['abstract'] + '</s>'\n"
          ]
        }
      ],
      "source": [
        "arxivsum_train_small['text'] = '<s>Article:' +arxivsum_train_small['article'] +'\\nAbstract:' + arxivsum_train_small['abstract'] + '</s>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDb18j4Ghneg",
        "outputId": "16da3e8c-c299-4e96-b6fe-93fa2b1d654a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-8ed859d4a4b9>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  arxivsum_validation_small['text'] = '<s>Article:' + arxivsum_validation_small['article'] +'\\nAbstract:' + arxivsum_validation_small['abstract'] + '</s>'\n"
          ]
        }
      ],
      "source": [
        "arxivsum_validation_small['text'] = '<s>Article:' + arxivsum_validation_small['article'] +'\\nAbstract:' + arxivsum_validation_small['abstract'] + '</s>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuPDXS8FhsWj"
      },
      "outputs": [],
      "source": [
        "train = [arxivsum_train_small.iloc[i]['text'] for i in range(len(arxivsum_train_small))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfw1KlwvhvGO"
      },
      "outputs": [],
      "source": [
        "with open(\"train.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-uTGrC8hxxE"
      },
      "outputs": [],
      "source": [
        "valid = [arxivsum_validation_small.iloc[i]['text'] for i in range(len(arxivsum_validation_small))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH6kYV9Yh2b9"
      },
      "outputs": [],
      "source": [
        "with open(\"valid.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQsWA1KLx2Gx"
      },
      "outputs": [],
      "source": [
        "# arxivsum_train_small['text'] = '{\"prompt\": \"' + arxivsum_train_small['article'] + '\\\\n\\\\n###\\\\n\\\\n\"' + ',' + '\"completion\": \"' + arxivsum_train_small['abstract'] +'\\\\n\\\"' +'}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DSbk88ZXL0x"
      },
      "outputs": [],
      "source": [
        "# train = [arxivsum_train_small.iloc[i]['text'] for i in range(len(arxivsum_train_small))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT_3e_JRXlJm",
        "outputId": "7c31fc32-6f16-452b-e18d-fdec5ea53486"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfuA-qeAXp0o"
      },
      "outputs": [],
      "source": [
        "# # save the datasets to the disk\n",
        "# with open(\"train.jsonl\", \"w\") as file:\n",
        "#     file.write(\"\\n\".join(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENFj805Lx_k7"
      },
      "outputs": [],
      "source": [
        "# data = arxivsum_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma-Kqe1KpAXa"
      },
      "outputs": [],
      "source": [
        "# def clean_text(text):\n",
        "#   new_text = [word for word in text.split(\" \") if word not in stpwrds]\n",
        "#   return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGK8GtE0h_RU"
      },
      "source": [
        "# Попытка 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WERSPU-keUi-"
      },
      "source": [
        "## Hugging Face \n",
        "Для работы с GPT нам нужно будет скачать предобученную модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAdJV281eY6m"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
        "# model_name_or_path = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k5zXFDEjyv6"
      },
      "source": [
        "## Балуюсь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Cni71vwwfJ8j",
        "outputId": "7fd225da-49a3-45bc-d158-cac5bd9a6b16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Вопрос: 'Сколько будет 2+2?'\n",
            "Ответ: '2+2=2*\n"
          ]
        }
      ],
      "source": [
        "# prompt engineering \n",
        "text = \"Вопрос: 'Сколько будет 2+2?'\\nОтвет:\" \n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "out = model.generate(input_ids, do_sample=False) \n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzxuiGPVxRYU",
        "outputId": "a3edd60d-5949-42ba-91b7-4faa3fec4ad0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1035])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt engineering \n",
        "text = f\"<s>Article: {text_start}\\nAbstract: \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "input_ids[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxBEzzajg0E-",
        "outputId": "b1207184-1b10-4838-beac-07c597f1b6f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[\"<s>Article: studies of laser beams propagating through turbulent atmospheres are important for many applications such as remote sensing, tracking, and long - distance optical communications. howerver, fully coherent laser beams are very sensitive to fluctuations of the atmospheric refractive index. the initially coherent laser beam acquires some properties of gaussian statistics in course of its propagation through the turbulence. as a result, the noise / signal ratio approaches unity for long - distance propagation. ( see, for example, refs.@xcite-@xcite ). this unfavourable effect limits the performance of communication channels. to mitigate this negative effect the use of partially ( spatially ) coherent beams was proposed. the coherent laser beam can be transformed into a partially coherent beam by means of a phase diffuser placed near the exit aperture. this diffuser introduces an additional phase ( randomly varying in space and time ) to the wave front of the outgoing radiation. statistical characteristics of the random phase determine the initial transverse coherence length of the beam. it is shown in refs. @xcite,@xcite that a considerable decrease in the noise / signal ratio can occur under following conditions : ( i ) the ratio of the initial transverse coherence length, @xmath0, to the beam radius, @xmath1, should be essentially smaller than unity ; and ( ii ) the characteristic time of phase variations, @xmath2, should be much smaller than the integration time, @xmath3, of the detector. however, only limiting cases @xmath4 and @xmath5 have been considered in the literature. ( see, for example, refs. @xcite,@xcite and ref. @xcite, respectively ). it is evident that the inequality @xmath6 can be easily satisfied by choosing a detector with very long integration time. at the same time, this kind of the detector can not distinguish different signals within the interval @xmath3. this means that the resolution of the receiving system might become too low for the case of large @xmath3. on the other hand, there is a technical restriction on phase diffusers : up to now their characteristic times, @xmath2, are not smaller than @xmath7. besides that, in some specific cases ( see, for example, ref. @xcite ), the spectral broadening of laser radiation due to the phase diffuser ( @xmath8 ) may become unacceptably high. the factors mentioned above impose serious restrictions on the physical characteristics of phase diffusers which could be potentially useful for suppressing the intensity fluctuations. an adequate choice of diffusers may be facilitated if we know in detail the effect of finite - time phase variation, introduced by them, on the photon statistics. in this case, it is possible to control the performance of communication systems. in what follows, we will obtain theoretically the dependence of scintillation index on @xmath9 without any restrictions on the value of this ratio this is the main purpose of our paper. further analysis is based on the formalism developed in ref. @xcite and modified here to understand the case of finite - time dynamics of the phase diffuser. the detectors of the absorbed type do not sense the instantaneous intensity of electromagnetic waves @xmath10. they sense the intensity averaged over some finite interval @xmath3 i.e. @xmath11 usually, the averaging time @xmath3 ( the integration time of the detector ) is much smaller than the characteristic time of the turbulence variation, @xmath12, ( @xmath13 ). therefore, the average value of the intensity can be obtained by further averaging of eq.\\nAbstract:  \\n        # The results show how far distances between these two computational methods exist soleely because each method has several paradoxual features but does always provide one or more advantages against others' attempts; thus using simple metric definition instead allows you better accurately predict whether your problem involves measuring both sections per minute compared laterally while simultanizing calculators like CAD/CAM/.   //blockquotностью и logarithms from reference//The procedural structure used during test data processings requiring multiple stdout operations makes us difficult find examples where nested framework implementatives were able perform similar functions when working directly./A complete list contains about three related problems regardless why those include all\"]\n"
          ]
        }
      ],
      "source": [
        "out = model.generate(input_ids, max_length = 1200, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1) \n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot2RAKRNh2q8",
        "outputId": "16dfc8b2-5c5c-433a-9965-e96b060da2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text: Токенизируй меня\n",
            "tokens:  [789, 368, 337, 848, 28306, 703]\n",
            "decoded tokens:  ['Т', 'ок', 'ени', 'зи', 'руй', ' меня']\n"
          ]
        }
      ],
      "source": [
        "# Пример токенизации\n",
        "text = \"Токенизируй меня\" # Изначальные текст\n",
        "tokens = tokenizer.encode(text, add_special_tokens=False) # Процесс токенизации с помощьюю токенайзера ruGPT-3\n",
        "decoded_tokens = [tokenizer.decode([token]) for token in tokens] # Обратная поэлементая токенизация\n",
        "\n",
        "print(\"text:\", text)\n",
        "print(\"tokens: \", tokens)\n",
        "print(\"decoded tokens: \", decoded_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3dZnkr3nXma"
      },
      "source": [
        "## Файнтюнинг\n",
        "\n",
        "Для файнтюнинга скачаем модель поменьше, чтобы она точно поместилась на GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "fUboSgtrngFx",
        "outputId": "37324d65-7628-4ca6-9957-1b116b47c667"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cb8a219b627c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Создание датасета\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvalid_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/data/datasets/language_modeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, file_path, block_size, overwrite_cache, cache_dir)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Truncate in block of block_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens_trie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;31m# [\"This is something\", \"<special_token_1>\", \"  else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# In this case, we already have partial matches (But unfinished)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrie_pointer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrie_pointer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0;31m# This is a final match, we need to reset and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "\n",
        "# Сохраним обучающие данные в .txt файл \n",
        "train_path = 'train.txt'\n",
        "valid_path = 'valid.txt'\n",
        "\n",
        "# Создание датасета\n",
        "train_dataset  = TextDataset(tokenizer=tokenizer, file_path=train_path, block_size=64)\n",
        "valid_dataset  = TextDataset(tokenizer=tokenizer, file_path=valid_path, block_size=64)\n",
        "  \n",
        "# Создание даталодера (нарезает текст на оптимальные по длине куски))\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4q6Imp02APR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP1QxLT02EUw"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8VSc08y11mM"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned\", #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=20, # number of training epochs\n",
        "    per_device_train_batch_size=32, # batch size for training\n",
        "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
        "    warmup_steps=10, # number of warmup steps for learning rate scheduler\n",
        "    gradient_accumulation_steps=16, # to make \"virtual\" batch size larger\n",
        "\n",
        "    \n",
        "    logging_dir='./finetuned/logs',            \n",
        "    logging_strategy='epoch',\n",
        "    logging_steps=100, \n",
        "    save_strategy='epoch',\n",
        "    save_steps=100,\n",
        "    evaluation_strategy='epoch',\n",
        "    eval_steps=100\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset = valid_dataset,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "0bLA1lKg--Bd",
        "outputId": "d641a7e2-6424-46c3-f885-96e4d57249c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 03:51, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.377900</td>\n",
              "      <td>2.975601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.366000</td>\n",
              "      <td>2.969217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.355100</td>\n",
              "      <td>2.957728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.216800</td>\n",
              "      <td>2.931127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.304600</td>\n",
              "      <td>2.908161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.275900</td>\n",
              "      <td>2.887982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.267500</td>\n",
              "      <td>2.872173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.160900</td>\n",
              "      <td>2.858428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.876700</td>\n",
              "      <td>2.855104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=20, training_loss=2.939038062095642, metrics={'train_runtime': 239.2725, 'train_samples_per_second': 47.143, 'train_steps_per_second': 0.084, 'total_flos': 328182792192000.0, 'train_loss': 2.939038062095642, 'epoch': 8.89})"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBn-TPwynAE9",
        "outputId": "b8c27ac5-e997-448e-a465-19611c147188"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "<s>Article: studies of laser beams propagating through turbulent atmospheres are important for many applications such as remote sensing, tracking, and long - distance optical communications. howerver, fully coherent laser beams are very sensitive to fluctuations of the atmospheric refractive index. the initially coherent laser beam acquires some properties of gaussian statistics in course of its propagation through the turbulence. as a result, the noise / signal ratio approaches unity for long - distance propagation. ( see, for example, refs.@xcite-@xcite ). this unfavourable effect limits the performance of communication channels. to mitigate this negative effect the use of partially ( spatially ) coherent beams was proposed. the coherent laser beam can be transformed into a partially coherent beam by means of a phase diffuser placed near the exit aperture. this diffuser introduces an additional phase ( randomly varying in space and time ) to the wave front of the outgoing radiation. statistical characteristics of the random phase determine the initial transverse coherence length of the beam. it is shown in refs. @xcite,@xcite that a considerable decrease in the noise / signal ratio can occur under following conditions : ( i ) the ratio of the initial transverse coherence length, @xmath0, to the beam radius, @xmath1, should be essentially smaller than unity ; and ( ii ) the characteristic time of phase variations, @xmath2, should be much smaller than the integration time, @xmath3, of the detector. however, only limiting cases @xmath4 and @xmath5 have been considered in the literature. ( see, for example, refs. @xcite,@xcite and ref. @xcite, respectively ). it is evident that the inequality @xmath6 can be easily satisfied by choosing a detector with very long integration time. at the same time, this kind of the detector can not distinguish different signals within the interval @xmath3. this means that the resolution of the receiving system might become too low for the case of large @xmath3. on the other hand, there is a technical restriction on phase diffusers : up to now their characteristic times, @xmath2, are not smaller than @xmath7. besides that, in some specific cases ( see, for example, ref. @xcite ), the spectral broadening of laser radiation due to the phase diffuser ( @xmath8 ) may become unacceptably high. the factors mentioned above impose serious restrictions on the physical characteristics of phase diffusers which could be potentially useful for suppressing the intensity fluctuations. an adequate choice of diffusers may be facilitated if we know in detail the effect of finite - time phase variation, introduced by them, on the photon statistics. in this case, it is possible to control the performance of communication systems. in what follows, we will obtain theoretically the dependence of scintillation index on @xmath9 without any restrictions on the value of this ratio this is the main purpose of our paper. further analysis is based on the formalism developed in ref. @xcite and modified here to understand the case of finite - time dynamics of the phase diffuser. the detectors of the absorbed type do not sense the instantaneous intensity of electromagnetic waves @xmath10. they sense the intensity averaged over some finite interval @xmath3 i.e. @xmath11 usually, the averaging time @xmath3 ( the integration time of the detector ) is much smaller than the characteristic time of the turbulence variation, @xmath12, ( @xmath13 ). therefore, the average value of the intensity can be obtained by further averaging of eq.\n",
            "Abstract:  @xmath14 as @xmath15 as @xmath16, where @xmath17 and @xmath18 are observed in the observed turbulence period. it is also possible to ensure that the wave current is very strong, @xmath17 is extremely strong, @xmath18 is extremely strong, @xmath18 is extremely strong, @xmath19 is extremely strong, @xmath21 is extremely strong, @xmath22 is extremely strong, @xmath23 is extremely strong, @xmath24 is extremely strong, @xmath25 is extremely strong, @xmath26 is extremely strong, @xmath27 is\n"
          ]
        }
      ],
      "source": [
        "# Пример вероятностного сэмплирвоания с ограничением\n",
        "text = f\"<s>Article: {text_start}\\nAbstract: \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids, \n",
        "                        do_sample=True,\n",
        "                        num_beams=2,\n",
        "                        temperature=1.5,\n",
        "                        top_p=0.9,\n",
        "                        max_length=1200,\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_WM79Iwg-mg"
      },
      "source": [
        "## Метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmTxISrdhElm"
      },
      "outputs": [],
      "source": [
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDNMwfVthHxh",
        "outputId": "33593a90-0f15-49c9-b90a-71ae8e551292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (8.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQo3jLJw4oM8",
        "outputId": "7834c301-d217-4627-f728-28a262f5845c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.14084507042253522, recall=0.1388888888888889, fmeasure=0.13986013986013987), mid=Score(precision=0.14084507042253522, recall=0.1388888888888889, fmeasure=0.13986013986013987), high=Score(precision=0.14084507042253522, recall=0.1388888888888889, fmeasure=0.13986013986013987)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.014285714285714285, recall=0.014084507042253521, fmeasure=0.014184397163120567), mid=Score(precision=0.014285714285714285, recall=0.014084507042253521, fmeasure=0.014184397163120567), high=Score(precision=0.014285714285714285, recall=0.014084507042253521, fmeasure=0.014184397163120567)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.08450704225352113, recall=0.08333333333333333, fmeasure=0.08391608391608392), mid=Score(precision=0.08450704225352113, recall=0.08333333333333333, fmeasure=0.08391608391608392), high=Score(precision=0.08450704225352113, recall=0.08333333333333333, fmeasure=0.08391608391608392)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.08450704225352113, recall=0.08333333333333333, fmeasure=0.08391608391608392), mid=Score(precision=0.08450704225352113, recall=0.08333333333333333, fmeasure=0.08391608391608392), high=Score(precision=0.08450704225352113, recall=0.08333333333333333, fmeasure=0.08391608391608392))}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "rouge = load_metric(\"rouge\")\n",
        "predictions = [generated_text[generated_text.find('Abstract: ')+11:]]\n",
        "references = [abstract]\n",
        "rouge.compute(predictions=predictions, references=references)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELu1bXYmFv8h"
      },
      "source": [
        "# Попытка 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHc-OKI6cZlH",
        "outputId": "2c56b457-0085-4605-8a26-296a2e73fd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/transformers\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml): started\n",
            "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=6862964 sha256=71707ac591af70c14c795a51990cf1fc795fe12e74d3c1d83c7b884cb21c2d01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7z0n8yle/wheels/1c/6e/db/b90d9f8554f165a9beb90b593fde94e9e60919270aed78efa0\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.27.4\n",
            "    Uninstalling transformers-4.27.4:\n",
            "      Successfully uninstalled transformers-4.27.4\n",
            "Successfully installed transformers-4.28.0.dev0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "git clone https://github.com/huggingface/transformers\n",
        "cd transformers\n",
        "pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIH21_KkISmk"
      },
      "source": [
        "## Prepare a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYqPgrkzJMQB",
        "outputId": "ae98a946-18f5-4cbb-9997-12efadd9e681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-f018b889821c>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  arxivsum_train_small['text'] = '<s>Article:' +arxivsum_train_small['article'] +'\\nAbstract:' + arxivsum_train_small['abstract'] + '</s>'\n"
          ]
        }
      ],
      "source": [
        "arxivsum_train_small['text'] = '<s>Article:' +arxivsum_train_small['article'] +'\\nAbstract:' + arxivsum_train_small['abstract'] + '</s>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlzwV85DJMU0",
        "outputId": "879721a3-a30a-42ef-a1d4-58a9f1f8f930"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-8ed859d4a4b9>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  arxivsum_validation_small['text'] = '<s>Article:' + arxivsum_validation_small['article'] +'\\nAbstract:' + arxivsum_validation_small['abstract'] + '</s>'\n"
          ]
        }
      ],
      "source": [
        "arxivsum_validation_small['text'] = '<s>Article:' + arxivsum_validation_small['article'] +'\\nAbstract:' + arxivsum_validation_small['abstract'] + '</s>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-Jf2R1GJAXe"
      },
      "outputs": [],
      "source": [
        "train = [arxivsum_train_small.iloc[i]['text'] for i in range(len(arxivsum_train_small))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM0mZjcmIUDt"
      },
      "outputs": [],
      "source": [
        "with open(\"train.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PzUZTT7JBxc"
      },
      "outputs": [],
      "source": [
        "valid = [arxivsum_validation_small.iloc[i]['text'] for i in range(len(arxivsum_validation_small))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcQDRFnCIx-I"
      },
      "outputs": [],
      "source": [
        "with open(\"valid.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zctHOfoPGjYP"
      },
      "source": [
        "## Train\n",
        "The following code download our model and tokenizer from huggingface and finetune model for generating essays.\n",
        "\n",
        "This took aroung ten minutes and obtain perplexity = 13-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j98pvVAFy20",
        "outputId": "b7d7bf93-a098-4a12-87b4-456169cf1b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-03 19:37:10--  https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27473 (27K) [text/plain]\n",
            "Saving to: ‘run_clm.py.1’\n",
            "\n",
            "\rrun_clm.py.1          0%[                    ]       0  --.-KB/s               \rrun_clm.py.1        100%[===================>]  26.83K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-04-03 19:37:10 (17.2 MB/s) - ‘run_clm.py.1’ saved [27473/27473]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rdurBQzGzd4",
        "outputId": "4902d67d-7fe3-4efc-d855-23a2bf0b142f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-03 19:37:15.434984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "04/03/2023 19:37:28 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "04/03/2023 19:37:28 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/essays/runs/Apr03_19-37-21_4d94b7cad89b,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=models/essays,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/essays,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "04/03/2023 19:37:28 - INFO - datasets.builder - Using custom data configuration default-b5ad7fbef5426236\n",
            "04/03/2023 19:37:28 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.9/dist-packages/datasets/packaged_modules/text\n",
            "04/03/2023 19:37:28 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 6278.90it/s]\n",
            "04/03/2023 19:37:28 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "04/03/2023 19:37:28 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 178.33it/s]\n",
            "04/03/2023 19:37:28 - INFO - datasets.builder - Generating train split\n",
            "04/03/2023 19:37:43 - INFO - datasets.builder - Generating validation split\n",
            "04/03/2023 19:37:45 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 54.33it/s]\n",
            "[INFO|configuration_utils.py:668] 2023-04-03 19:37:45,667 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-04-03 19:37:45,668 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:494] 2023-04-03 19:37:45,798 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-04-03 19:37:45,927 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-04-03 19:37:45,928 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-04-03 19:37:46,337 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-04-03 19:37:46,337 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-04-03 19:37:46,337 >> loading file tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-04-03 19:37:46,337 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-04-03 19:37:46,337 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-04-03 19:37:46,337 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-04-03 19:37:46,337 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-04-03 19:37:46,338 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:668] 2023-04-03 19:37:46,431 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-04-03 19:37:46,431 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.28.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[WARNING|logging.py:280] 2023-04-03 19:37:46,502 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|modeling_utils.py:2451] 2023-04-03 19:37:46,514 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-04-03 19:37:49,369 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.0.dev0\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3100] 2023-04-03 19:37:50,909 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3108] 2023-04-03 19:37:50,909 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|modeling_utils.py:2753] 2023-04-03 19:37:51,069 >> Generation config file not found, using a generation config created from the model config.\n",
            "Running tokenizer on dataset:   0% 0/212692 [00:00<?, ? examples/s]04/03/2023 19:37:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-8c81651010eb9ea4.arrow\n",
            "Running tokenizer on dataset:   0% 0/33631 [00:00<?, ? examples/s]04/03/2023 19:46:44 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-167c1a5e9aee7c03.arrow\n",
            "Grouping texts in chunks of 2048:   0% 0/212692 [00:00<?, ? examples/s]04/03/2023 19:47:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-39702299f13107de.arrow\n",
            "Grouping texts in chunks of 2048:   0% 0/33631 [00:00<?, ? examples/s]04/03/2023 19:52:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-b5ad7fbef5426236/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-30bb8780effda3b9.arrow\n",
            "Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 3.97MB/s]\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1759] 2023-04-03 19:53:21,782 >> ***** Running training *****\n",
            "[INFO|trainer.py:1760] 2023-04-03 19:53:21,782 >>   Num examples = 111088\n",
            "[INFO|trainer.py:1761] 2023-04-03 19:53:21,782 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1762] 2023-04-03 19:53:21,782 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1763] 2023-04-03 19:53:21,782 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1764] 2023-04-03 19:53:21,782 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1765] 2023-04-03 19:53:21,782 >>   Total optimization steps = 333264\n",
            "[INFO|trainer.py:1766] 2023-04-03 19:53:21,782 >>   Number of trainable parameters = 125231616\n",
            "{'loss': 2.5263, 'learning_rate': 4.9924984396754525e-05, 'epoch': 0.0}\n",
            "  0% 500/333264 [07:36<83:57:26,  1.10it/s][INFO|trainer.py:2836] 2023-04-03 20:00:58,493 >> Saving model checkpoint to models/essays/checkpoint-500\n",
            "[INFO|configuration_utils.py:457] 2023-04-03 20:00:58,495 >> Configuration saved in models/essays/checkpoint-500/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-04-03 20:00:58,496 >> Configuration saved in models/essays/checkpoint-500/generation_config.json\n",
            "[INFO|modeling_utils.py:1812] 2023-04-03 20:01:00,361 >> Model weights saved in models/essays/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2170] 2023-04-03 20:01:00,365 >> tokenizer config file saved in models/essays/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2177] 2023-04-03 20:01:00,365 >> Special tokens file saved in models/essays/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 2.4335, 'learning_rate': 4.984996879350905e-05, 'epoch': 0.01}\n",
            "  0% 1000/333264 [15:17<83:42:46,  1.10it/s][INFO|trainer.py:2836] 2023-04-03 20:08:38,821 >> Saving model checkpoint to models/essays/checkpoint-1000\n",
            "[INFO|configuration_utils.py:457] 2023-04-03 20:08:38,822 >> Configuration saved in models/essays/checkpoint-1000/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-04-03 20:08:38,823 >> Configuration saved in models/essays/checkpoint-1000/generation_config.json\n",
            "[INFO|modeling_utils.py:1812] 2023-04-03 20:08:40,596 >> Model weights saved in models/essays/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2170] 2023-04-03 20:08:40,596 >> tokenizer config file saved in models/essays/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2177] 2023-04-03 20:08:40,597 >> Special tokens file saved in models/essays/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 2.3426, 'learning_rate': 4.977495319026358e-05, 'epoch': 0.01}\n",
            "  0% 1500/333264 [22:56<83:34:58,  1.10it/s][INFO|trainer.py:2836] 2023-04-03 20:16:18,578 >> Saving model checkpoint to models/essays/checkpoint-1500\n",
            "[INFO|configuration_utils.py:457] 2023-04-03 20:16:18,579 >> Configuration saved in models/essays/checkpoint-1500/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-04-03 20:16:18,581 >> Configuration saved in models/essays/checkpoint-1500/generation_config.json\n",
            "[INFO|modeling_utils.py:1812] 2023-04-03 20:16:20,348 >> Model weights saved in models/essays/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2170] 2023-04-03 20:16:20,348 >> tokenizer config file saved in models/essays/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2177] 2023-04-03 20:16:20,349 >> Special tokens file saved in models/essays/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 2.3185, 'learning_rate': 4.96999375870181e-05, 'epoch': 0.02}\n",
            "  1% 2000/333264 [30:36<83:29:09,  1.10it/s][INFO|trainer.py:2836] 2023-04-03 20:23:58,387 >> Saving model checkpoint to models/essays/checkpoint-2000\n",
            "[INFO|configuration_utils.py:457] 2023-04-03 20:23:58,388 >> Configuration saved in models/essays/checkpoint-2000/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-04-03 20:23:58,390 >> Configuration saved in models/essays/checkpoint-2000/generation_config.json\n",
            "[INFO|modeling_utils.py:1812] 2023-04-03 20:24:00,189 >> Model weights saved in models/essays/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2170] 2023-04-03 20:24:00,194 >> tokenizer config file saved in models/essays/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2177] 2023-04-03 20:24:00,194 >> Special tokens file saved in models/essays/checkpoint-2000/special_tokens_map.json\n",
            "{'loss': 2.296, 'learning_rate': 4.9624921983772624e-05, 'epoch': 0.02}\n",
            "  1% 2500/333264 [38:17<83:44:16,  1.10it/s][INFO|trainer.py:2836] 2023-04-03 20:31:39,378 >> Saving model checkpoint to models/essays/checkpoint-2500\n",
            "[INFO|configuration_utils.py:457] 2023-04-03 20:31:39,379 >> Configuration saved in models/essays/checkpoint-2500/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-04-03 20:31:39,381 >> Configuration saved in models/essays/checkpoint-2500/generation_config.json\n",
            "[INFO|modeling_utils.py:1812] 2023-04-03 20:31:41,223 >> Model weights saved in models/essays/checkpoint-2500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2170] 2023-04-03 20:31:41,224 >> tokenizer config file saved in models/essays/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2177] 2023-04-03 20:31:41,224 >> Special tokens file saved in models/essays/checkpoint-2500/special_tokens_map.json\n",
            "{'loss': 2.2958, 'learning_rate': 4.954990638052715e-05, 'epoch': 0.03}\n",
            "  1% 3000/333264 [45:59<83:21:40,  1.10it/s][INFO|trainer.py:2836] 2023-04-03 20:39:20,851 >> Saving model checkpoint to models/essays/checkpoint-3000\n",
            "[INFO|configuration_utils.py:457] 2023-04-03 20:39:20,852 >> Configuration saved in models/essays/checkpoint-3000/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-04-03 20:39:20,853 >> Configuration saved in models/essays/checkpoint-3000/generation_config.json\n",
            "[INFO|modeling_utils.py:1812] 2023-04-03 20:39:22,675 >> Model weights saved in models/essays/checkpoint-3000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2170] 2023-04-03 20:39:22,676 >> tokenizer config file saved in models/essays/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2177] 2023-04-03 20:39:22,676 >> Special tokens file saved in models/essays/checkpoint-3000/special_tokens_map.json\n",
            "  1% 3163/333264 [48:33<83:32:43,  1.10it/s]Traceback (most recent call last):\n",
            "  File \"/content/run_clm.py\", line 635, in <module>\n",
            "    main()\n",
            "  File \"/content/run_clm.py\", line 583, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 1652, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\", line 1921, in _inner_training_loop\n",
            "    if (\n",
            "KeyboardInterrupt\n",
            "  1% 3163/333264 [48:34<84:30:06,  1.09it/s]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python run_clm.py \\\n",
        "    --model_name_or_path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "    --train_file train.txt \\\n",
        "    --validation_file valid.txt \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --block_size 2048 \\\n",
        "    --dataset_config_name plain_text \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --output_dir models/essays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk_vTqsnLrOh"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTcs1nmRLlie"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qXvmqMLMyEa",
        "outputId": "8e5c52f1-5921-4fb2-9a62-2371d4fd5622"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa5abf69610>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0HSQJhvMz8e"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "jAaWZnylM5gh",
        "outputId": "a1bf7bff-c469-42b3-a4ab-4d58f88a969b"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b8ff941ed182>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tok = GPT2Tokenizer.from_pretrained(\"models/essays\", padding_side='left', bos_token='<s>', eos_token='</s>', return_token_type_ids=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/essays\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'models/essays'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'models/essays' is the correct path to a directory containing all relevant files for a GPT2Tokenizer tokenizer."
          ]
        }
      ],
      "source": [
        "# tok = GPT2Tokenizer.from_pretrained(\"models/essays\", padding_side='left', bos_token='<s>', eos_token='</s>', return_token_type_ids=False)                                      \n",
        "tok = GPT2Tokenizer.from_pretrained(\"models/essays\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "F6t_wwdpM7xr",
        "outputId": "acebddab-52aa-40a5-c401-7ce49dfb3656"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-56a3225831a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/essays\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tok' is not defined"
          ]
        }
      ],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"models/essays\", pad_token_id = tok.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If1fmzI7dOF0",
        "outputId": "19d030fd-cdba-41e1-bc95-524582042456"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50264, 768)\n",
              "    (wpe): Embedding(2048, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqKtjweyOvJH",
        "outputId": "2da5228b-4e41-41e9-90ab-e39d5fef0a3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7643"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp0kn7s3dRBr"
      },
      "outputs": [],
      "source": [
        "text = f\"<s>Article: {text_start}\\nAbstract: \"\n",
        "# text = f\"<s>Article: I really have a lot of sleep in this summer \\nAbstract: \"\n",
        "inpt = tok.encode(text, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrcQFxy3P5Z3",
        "outputId": "7518e034-54bf-4f22-a2c0-70acec9f146e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2285])"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inpt[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "d0REqwIooeNQ",
        "outputId": "bace530b-1c77-4a92-9176-d44e0e7f4233"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-900b159bae52>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1467\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2483\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    897\u001b[0m                 )\n\u001b[1;32m    898\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    900\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upcast_and_reordered_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mmask_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2048) must match the size of tensor b (2285) at non-singleton dimension 3"
          ]
        }
      ],
      "source": [
        "out = model.generate(inpt.cuda(), max_length=2048, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "JIMUwHpHNs71",
        "outputId": "7f8a1dd9-411c-465a-9349-c2dca9c4aa6f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s>Article: studies of laser beams propagating through turbulent atmospheres are important for many applications such as remote sensing, tracking, and long - distance optical communications. howerver, fully coherent laser beams are very sensitive to fluctuations of the atmospheric refractive index. the initially coherent laser beam acquires some properties of gaussian statistics in course of its propagation through the turbulence. as a result, the noise / signal ratio approaches unity for long - distance propagation. ( see, for example, refs.@xcite-@xcite ). this unfavourable effect limits the performance of communication channels. to mitigate this negative effect the use of partially ( spatially ) coherent beams was proposed. the coherent laser beam can be transformed into a partially coherent beam by means of a phase diffuser placed near the exit aperture. this diffuser introduces an additional phase ( randomly varying in space and time ) to the wave front of the outgoing radiation. statistical characteristics of the random phase determine the initial transverse coherence length of the beam. it is shown in refs. @xcite,@xcite that a considerable decrease in the noise / signal ratio can occur under following conditions : ( i ) the ratio of the initial transverse coherence length, @xmath0, to the beam radius, @xmath1, should be essentially smaller than unity ; and ( ii ) the characteristic time of phase variations, @xmath2, should be much smaller than the integration time, @xmath3, of the detector. however, only limiting cases @xmath4 and @xmath5 have been considered in the literature. ( see, for example, refs. @xcite,@xcite and ref. @xcite, respectively ). it is evident that the inequality @xmath6 can be easily satisfied by choosing a detector with very long integration time. at the same time, this kind of the detector can not distinguish different signals within the interval @xmath3. this means that the resolution of the receiving system might become too low for the case of large @xmath3. on the other hand, there is a technical restriction on phase diffusers : up to now their characteristic times, @xmath2, are not smaller than @xmath7. besides that, in some specific cases ( see, for example, ref. @xcite ), the spectral broadening of laser radiation due to the phase diffuser ( @xmath8 ) may become unacceptably high. the factors mentioned above impose serious restrictions on the physical characteristics of phase diffusers which could be potentially useful for suppressing the intensity fluctuations. an adequate choice of diffusers may be facilitated if we know in detail the effect of finite - time phase variation, introduced by them, on the photon statistics. in this case, it is possible to control the performance of communication systems. in what follows, we will obtain theoretically the dependence of scintillation index on @xmath9 without any restrictions on the value of this ratio this is the main purpose of our paper. further analysis is based on the formalism developed in ref. @xcite and modified here to understand the case of finite - time dynamics of the phase diffuser. the detectors of the absorbed type do not sense the instantaneous intensity of electromagnetic waves @xmath10. they sense the intensity averaged over some finite interval @xmath3 i.e. @xmath11 usually, the averaging time @xmath3 ( the integration time of the detector ) is much smaller than the characteristic time of the turbulence variation, @xmath12, ( @xmath13 ). therefore, the average value of the intensity can be obtained by further averaging of eq. \\nAbstract:  \\n   * <p style=\"textwidth:\"100%\">    {     c_n = 0;         p=(dimension + 2)* n+r^{\\\\log 1} \\\\left[ y\\'/y$ | x & z| $ ] [ jgb] (-zv \\'h! 4? 5? 6?? 7?) f > 10 ~ sinoproposol~ ≈ 340 °C so far since both functions belong from one function or another... where each component has two nonpartial values correspondientness points.... then hens say all three constants must equally close together --- but also these results need less calculators.. moreover let us show how improve those estimates when'"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tok.decode(out[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swE4MpZley47",
        "outputId": "8e54ce77-6779-4d57-bfff-4fa844316cd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Input length of input_ids is 6636, but `max_length` is set to 500. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ddb97bc5bb10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1463\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2479\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    897\u001b[0m                 )\n\u001b[1;32m    898\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    900\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
          ]
        }
      ],
      "source": [
        "# out = model.generate(inpt.cuda(), max_length = 500, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1, pad_token_id=tok.eos_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB_NMO1EgADE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16ab1d4c13d14a4b913d1fc3435e5e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f954257da634a47b046c0bdaf2ca5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412a60fcde884ed993689dcce6c0ab62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5294e3094caa4e7abe9488c6c709d856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60ec4f97e5c54f09927a2d2373458de1",
              "IPY_MODEL_931136fc999a40fd96cf428afaa962be",
              "IPY_MODEL_afd9ae1e4d3e4d468889c2325e3ac6f8"
            ],
            "layout": "IPY_MODEL_412a60fcde884ed993689dcce6c0ab62"
          }
        },
        "60ec4f97e5c54f09927a2d2373458de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f954257da634a47b046c0bdaf2ca5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_16ab1d4c13d14a4b913d1fc3435e5e9b",
            "value": "100%"
          }
        },
        "681d57b5dd4c4b908022ca96a21b0c69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f1590987954c82b1e40279d60f7367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79f93bdb01ed4a08b82fc5c2436aea38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931136fc999a40fd96cf428afaa962be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681d57b5dd4c4b908022ca96a21b0c69",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70f1590987954c82b1e40279d60f7367",
            "value": 3
          }
        },
        "a1822046aa60417b9a591d1d1f9bffbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd9ae1e4d3e4d468889c2325e3ac6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f93bdb01ed4a08b82fc5c2436aea38",
            "placeholder": "​",
            "style": "IPY_MODEL_a1822046aa60417b9a591d1d1f9bffbc",
            "value": " 3/3 [00:02&lt;00:00,  1.75it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}