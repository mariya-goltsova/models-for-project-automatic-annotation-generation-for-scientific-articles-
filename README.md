# models

Участие в проекте "Автоматическая генерация аннотаций к научным статьям" (https://git.miem.hse.ru/1407). Написание кода для T5, цепей Маркова, seq2seq. 

## Описание основных файлов и директорий

### Поддиректория GPT содержит в себе 3 файлa:

GPT_train.ipynb - 
Ноутбук с дообучением модели ai-forever/rugpt3small_based_on_gpt2 двумя спосабами

test_gpt_models.ipynb - 
Ноутбук с тестированием дообученных моделей GPT для суммаризации с huggindface

test_our_GPT.ipynb - 
Ноутбук с тестированием нашей модели


### Поддиректория MarkovChain содержит в себе 2 файлa:

MarkovChains2.ipynb - 
Ноутбук с цепями Маркова для суммаризации текста

Цепи_Маркова.ipynb - 
Ноутбук с созданием цепей Маркова  


### Поддиректория T5 содержит в себе 3 файлa:

T5_train.ipynb.ipynb - 
Ноутбук с дообучением модели T5 для задачи суммаризации текста

test_t5_models.ipynb - 
Ноутбук с тестированием дообученных моделей T5 для суммаризации с huggindface

test_our_T5.ipynb - 
Ноутбук с тестированием нашей модели


### Поддиректория Bart содержит в себе 3 файлa:

Bart_train.ipynb.ipynb - 
Файн-тьюнинг модели Bart

test_Bart_models.ipynb - 
Тестирование моделей группы Bart

test_our_Bart.ipynb - 
Тестирование нашей модели


### Поддиректория Seq2seq содержит в себе 1 файл:

Обучение_модели_Seq2Seq.ipynb - 
Ноутбук с Seq2seq моделями, написанными на TensorFlow и PyTorch
