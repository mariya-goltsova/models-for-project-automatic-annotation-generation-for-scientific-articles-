{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C-m1tx_9mks",
        "outputId": "b4ee4c04-26be-417b-d699-ae8c1e8d1f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.8/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "TDvc3wz6FPEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
        "from itertools import count, islice\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "H2Vw5yB5FMXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Доступ к данным"
      ],
      "metadata": {
        "id": "IU2HW4yZFsvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"outoutGeneralRelativityAndQuantumCosmology_0_result.feather\"\n",
        "df = pd.read_feather(filename)\n",
        "title_list = df[\"Title\"].tolist()\n",
        "annotation_list = df[\"Annotation\"].tolist()\n",
        "clear_list = df[\"clear\"].tolist()"
      ],
      "metadata": {
        "id": "C2tFxaaoFYhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "eSes2k5dGTFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VwAwObMIhCu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# import torchtext\n",
        "# from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "J9_inlMmEJMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_W = WordPunctTokenizer()\n",
        "\n",
        "def tokenize_ru_in(x, tokenizer=tokenizer_W):\n",
        "    return tokenizer.tokenize(x.lower())[::-1]\n",
        "\n",
        "def tokenize_ru_out(x, tokenizer=tokenizer_W):\n",
        "    return tokenizer.tokenize(x.lower())"
      ],
      "metadata": {
        "id": "tGE10HiJInHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_data(df):\n",
        "    i = 0\n",
        "    for title in df[\"Title\"].tolist():\n",
        "        annotation = df[df[\"Title\"] == title]['Annotation'].tolist()[0]\n",
        "        clear = df[df[\"Title\"] == title]['clear'].tolist()[0]\n",
        "        if not(clear is None or annotation is None):\n",
        "          data_dict[i] = (title, tokenize_ru_out(annotation), tokenize_ru_in(clear))\n",
        "          i += 1\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "IQSBeaDoI6j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {}\n",
        "data_dict = collect_data(df)\n",
        "data = list(data_dict.keys())"
      ],
      "metadata": {
        "id": "w_1sdbRKI9_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmjXXkdsJBoU",
        "outputId": "2dff8c1d-0596-47d0-8b08-5c5e0d2e044f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1021"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def collect_data_list(df):\n",
        "#     data_list = []\n",
        "#     for title in df[\"Title\"].tolist():\n",
        "#         annotation = df[df[\"Title\"] == title]['Annotation'].tolist()[0]\n",
        "#         clear = df[df[\"Title\"] == title]['clear'].tolist()[0]\n",
        "#         if not(clear is None or annotation is None):\n",
        "#           data_list.append({'title': title, 'annotation': tokenize_ru_out(annotation), 'clear': tokenize_ru_in(clear)})\n",
        "#     return data_list"
      ],
      "metadata": {
        "id": "IulxYHO3OJQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_list = []\n",
        "# data_list = collect_data_list(df)\n",
        "# len(data_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0S48ImhODTe",
        "outputId": "4154d258-6b7a-46c3-a7c7-5816dfd3941c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1021"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
        "import time"
      ],
      "metadata": {
        "id": "okdgADnxFvqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(IterableDataset):\n",
        " def __init__(self, data):\n",
        "    self.data_dict = data\n",
        "    self.data = data.values()\n",
        "    self.data_len = len(data)\n",
        "  \n",
        " def __len__(self):\n",
        "    #  worker_info = torch.utils.data.get_worker_info()\n",
        "    #  dataset = worker_info.dataset\n",
        "     return self.data_len\n",
        "\n",
        " def __getitem__(self, i):\n",
        "     return self.data_dict[i]\n",
        "\n",
        " def __iter__(self):\n",
        "  for x in self.data:\n",
        "    worker = torch.utils.data.get_worker_info()\n",
        "    worker_id = worker.id if worker is not None else -1\n",
        "    start = time.time()\n",
        "    time.sleep(0.1)\n",
        "    end = time.time()\n",
        "    yield x, worker_id, start, end\n",
        "\n",
        "iterable_dataset = MyIterableDataset(data_dict)\n",
        "# iterable_dataset = MyIterableDataset(data_list)"
      ],
      "metadata": {
        "id": "2n245PETFvsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def worker_init_fn(_):\n",
        " worker_info = torch.utils.data.get_worker_info()\n",
        "\n",
        " dataset = worker_info.dataset\n",
        " worker_id = worker_info.id\n",
        " split_size = len(dataset.data) // worker_info.num_workers\n",
        " dataset.data = list(dataset.data)[worker_id * split_size:(worker_id + 1) * split_size]\n",
        "\n",
        "loader = DataLoader(iterable_dataset, batch_size=4, num_workers=2, worker_init_fn=worker_init_fn)"
      ],
      "metadata": {
        "id": "5vLE8i_XFvvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data\n",
        "\n",
        "Here comes the preprocessing"
      ],
      "metadata": {
        "id": "z5n66F-VE_6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer_W = WordPunctTokenizer()\n",
        "\n",
        "# def tokenize_ru_in(x, tokenizer=tokenizer_W):\n",
        "#     return tokenizer.tokenize(x.lower())[::-1]\n",
        "\n",
        "# def tokenize_ru_out(x, tokenizer=tokenizer_W):\n",
        "#     return tokenizer.tokenize(x.lower())"
      ],
      "metadata": {
        "id": "3_6DGOBZEJRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SRC = Field(tokenize=tokenize_ru_in,\n",
        "#             init_token = '<sos>', \n",
        "#             eos_token = '<eos>', \n",
        "#             lower = True)\n",
        "\n",
        "# TRG = Field(tokenize=tokenize_ru_out,\n",
        "#             init_token = '<sos>', \n",
        "#             eos_token = '<eos>', \n",
        "#             lower = True)\n",
        "\n",
        "\n",
        "# # dataset = torchtext.legacy.data.TabularDataset(\n",
        "# #     path='data.txt',\n",
        "# #     format='tsv',\n",
        "# #     fields=[('trg', TRG), ('src', SRC)]\n",
        "# # )\n",
        "\n",
        "# dataset = torchtext.legacy.data.TabularDataset(\n",
        "#     path=\"./data_for_seq2seq.csv\",\n",
        "#     format='csv',\n",
        "#     skip_header=True,\n",
        "#     fields=[('trg', TRG), ('src', SRC)],\n",
        "#     # csv_reader_params = {'delimiter': '\\t'}\n",
        "# )"
      ],
      "metadata": {
        "id": "uZg7TNY1EJTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(iterable_dataset))\n",
        "print(iterable_dataset[0][0]) #заголовок\n",
        "print(iterable_dataset[0][1]) #аннотация\n",
        "# print(iterable_dataset[0][2]) #статья"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S78p5Rw8IAQb",
        "outputId": "92f6929f-7719-485b-919a-12e8d41619c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1021\n",
            "The Statistical Mechanics of Black Hole Thermodynamics\n",
            "['although', 'we', 'have', 'convincing', 'evidence', 'that', 'a', 'black', 'hole', 'bears', 'an', 'entropyproportional', 'to', 'its', 'surface', '(', 'horizon', ')', 'area', ',', 'the', '``', 'statistical', 'mechanical', \"''\", 'explanation', 'of', 'this', 'entropy', 'remains', 'unknown', '.', 'two', 'basic', 'questions', 'in', 'thisconnection', 'are', ':', 'what', 'is', 'the', 'microscopic', 'origin', 'of', 'the', 'entropy', ',', 'and', 'why', 'does', 'thelaw', 'of', 'entropy', 'increase', 'continue', 'to', 'hold', 'when', 'the', 'horizon', 'entropy', 'is', 'included', '?', 'after', 'a', 'review', 'of', 'some', 'of', 'the', 'difficulties', 'in', 'answering', 'these', 'questions', ',', 'ipropose', 'an', 'explanation', 'of', 'the', 'law', 'of', 'entropy', 'increase', 'which', 'comes', 'near', 'to', 'aproof', 'in', 'the', 'context', 'of', 'the', '``', 'semi', '-', 'classical', \"''\", 'approximation', ',', 'and', 'which', 'alsoprovides', 'a', 'proof', 'in', 'full', 'quantum', 'gravity', 'under', 'the', 'assumption', 'that', 'the', 'latterfulfills', 'certain', 'natural', 'expectations', ',', 'like', 'the', 'existence', 'of', 'a', 'conserved', 'energydefinable', 'at', 'infinity', '.', 'this', 'explanation', 'seems', 'to', 'require', 'a', 'fundamentalspacetime', 'discreteness', 'in', 'order', 'for', 'the', 'entropy', 'to', 'be', 'consistently', 'finite', ',', 'andi', 'recall', 'briefly', 'some', 'of', 'the', 'ideas', 'for', 'what', 'the', 'discreteness', 'might', 'be', '.', 'if', 'suchideas', 'are', 'right', ',', 'then', 'our', 'knowledge', 'of', 'the', 'horizon', 'entropy', 'will', 'allow', 'us', 'to', '``', 'count', 'the', 'atoms', 'of', 'spacetime', \"''.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(dataset.examples))\n",
        "# print(dataset.examples[0].src) #статья наоборот\n",
        "# print(dataset.examples[0].trg) #аннотация\n",
        "# print(dataset.examples[0].leng)"
      ],
      "metadata": {
        "id": "QsW367OhEJVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data, valid_data, test_data = torch.utils.data.random_split(iterable_dataset, [0.8, 0.15, 0.05])\n",
        "\n",
        "train_size = int(0.8 * len(iterable_dataset))\n",
        "valid_size = int(0.15 * len(iterable_dataset))\n",
        "test_size = len(iterable_dataset) - train_size - valid_size\n",
        "train_data, valid_data, test_data = torch.utils.data.random_split(iterable_dataset, [train_size, valid_size, test_size])\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")\n",
        "\n",
        "# train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n",
        "\n",
        "# print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "# print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "# print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb-ooGYSdFk1",
        "outputId": "205b219f-db57-4a76-84b1-1f08ac489b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 816\n",
            "Number of validation examples: 153\n",
            "Number of testing examples: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SRC.build_vocab(train_data, min_freq = 2)\n",
        "# TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "metadata": {
        "id": "YcJi_pa_dFn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Unique tokens in source (article) vocabulary: {len(SRC.vocab)}\")\n",
        "# print(f\"Unique tokens in target (abstruct) vocabulary: {len(TRG.vocab)}\")"
      ],
      "metadata": {
        "id": "xq1vCQ-ydFrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here is example from train dataset:"
      ],
      "metadata": {
        "id": "OVbYMRm2gi9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCvrbbtedFuV",
        "outputId": "dbc06fcc-f1e6-4d89-df54-bae5cf19048f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Quantum Theory of Geometry II: Volume operators', ['a', 'functional', 'calculus', 'on', 'the', 'space', 'of', '(', 'generalized', ')', 'connections', 'was', 'recentlyintroduced', 'without', 'any', 'reference', 'to', 'a', 'background', 'metric', '.', 'it', 'is', 'used', 'to', 'continuethe', 'exploration', 'of', 'the', 'quantum', 'riemannian', 'geometry', '.', 'operators', 'corresponding', 'tovolume', 'of', 'three', '-', 'dimensional', 'regions', 'are', 'regularized', 'rigorously', '.', 'it', 'is', 'shownthat', 'there', 'are', 'two', 'natural', 'regularization', 'schemes', ',', 'each', 'of', 'which', 'leads', 'to', 'awell', '-', 'defined', 'operator', '.', 'both', 'operators', 'can', 'be', 'completely', 'specified', 'by', 'givingtheir', 'action', 'on', 'states', 'labelled', 'by', 'graphs', '.', 'the', 'two', 'final', 'results', 'are', 'closelyrelated', 'but', 'differ', 'from', 'one', 'another', 'in', 'that', 'one', 'of', 'the', 'operators', 'is', 'sensitiveto', 'the', 'differential', 'structure', 'of', 'graphs', 'at', 'their', 'vertices', 'while', 'the', 'second', 'issensitive', 'only', 'to', 'the', 'topological', 'characteristics', '.', '(', 'the', 'second', 'operator', 'wasfirst', 'introduced', 'by', 'rovelli', 'and', 'smolin', 'and', 'de', 'pietri', 'and', 'rovelli', 'using', 'asomewhat', 'different', 'framework', '.)', 'the', 'difference', 'between', 'the', 'two', 'operators', 'can', 'beattributed', 'directly', 'to', 'the', 'standard', 'quantization', 'ambiguity', '.', 'underlyingassumptions', 'and', 'subtleties', 'of', 'regularization', 'procedures', 'are', 'discussed', 'in', 'detailin', 'both', 'cases', 'because', 'volume', 'operators', 'play', 'an', 'important', 'role', 'in', 'the', 'currentdiscussions', 'of', 'quantum', 'dynamics', '.'], ['.', 'vertices', 'the', 'surrounding', 'cells', 'small', 'sufficiently', 'of', 'boundary', 'the', 'at', 'registered', 'be', 'can', 'which', 'structure', \"'\", 'extrinsic', '`', 'the', 'on', 'only', 'depends', 'and', 'vertices', 'its', 'at', 'graph', 'the', 'of', 'structure', \"'\", 'intrinsic', '`', 'the', 'to', 'insensitive', 'is', 'expression', 'final', 'the', '.', 'in', 'reported', 'was', 'that', 'formula', 'the', 'is', 'this', '.', 'graph', 'the', 'of', 'vertices', 'the', 'all', 'over', 'extends', 'sum', 'the', 'where', 'ee', ',\\\\', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', '}\\\\,', 'q_v', '{\\\\', 'sqrt', '\\\\', '}', 'v', '{', 'sum_', '\\\\', '=\\\\', '\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\,\\\\', 'v_r', '}', 'volim', '{', 'label', '\\\\', 'be', '\\\\', 'by', 'given', 'is', 'operator', 'volume', 'the', ',', 'sections', '-', 'sub', 'previous', 'the', 'in', 'stated', 'restrictions', 'the', 'satisfies', 'which', '$', 'p', '$\\\\', 'partition', 'any', 'for', ',', 'hence', '$.', 'c_v', '$', 'cells', 'the', 'of', 'of', 'shrinking', 'the', 'to', 'respect', 'with', 'invariant', 'manifestly', 'is', 'formula', 'the', ':', 'section', 'in', 'encountered', 'we', 'that', 'as', 'same', 'the', 'is', 'situation', 'the', 'now', '$.', 'v', '$', 'at', 'edges', 'the', 'label', '$', 'k', ',', 'j', ',', 'i', '$', 'where', 'ee', '\\\\', 'g', '\\\\', 'psi_', '|\\\\', 'k', '}^', 've_k', '{', 'jj_', '}^', 've_j', '{', 'ij_', '}^', 've_i', '{', 'j_', '}', 'ijk', '{', 'e_', '|\\\\', '}', 'i', '=', 'not', '\\\\', 'k', '=', 'not', '\\\\', 'j', '=', 'not', '\\\\', 'i', '{', 'sum_', '}\\\\', '48', 'over', '\\\\', '1', '{', '=\\\\', '\\\\', 'g', '\\\\', 'psi_', '}\\\\', 'c_v', '{', 'q_', '\\\\', '}', '24', '.', '6', '{', 'label', '\\\\', 'be', '\\\\', '$,', 'v', '$', 'vertex', 'a', 'containing', '$', 'c_v', '$', 'cell', 'a', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'with', 'compatible', '$', 'g', '\\\\', 'psi_', '$\\\\', 'function', 'cylindrical', 'a', 'for', ',', 'finally', '$.', '1', '$', 'to', 'out', 'integrate', 's', \"$'\", 'f', '$', 'the', ',', 'property', 'normalization', 'the', 'to', 'due', ',', 'where', 'and', 'independent', '$', 'z', '$', 'is', '$|...|$', 'factor', 'last', 'the', 'where', 'ee', '\\\\', 'g', '\\\\', 'psi_', '|...|\\\\,\\\\,\\\\', '\\\\,\\\\,', '6z', '^', 'd', ')\\\\,', 'w_k', ',', 'z_3', '(', 'f', ')', 'w_j', ',', 'z_2', '(', 'f', ')', 'w_i', ',', 'z_1', '(', 'f', '}', 'delta_k', '{\\\\', 'int_', '}\\\\', 'delta_j', '{\\\\', 'int_', '}\\\\', 'delta_i', '{\\\\', 'int_', '}\\\\', 'k', ',', 'j', ',', 'i', '{', 'sum_', '\\\\', '=\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '\\\\,\\\\,', '6z', '^', 'd', '}...|\\\\,', 'k', ',', 'j', ',', 'i', '{', 'sum_', '|\\\\', '}\\\\,', '3', ')^', 'pc', '{(\\\\', 'int_', '\\\\', 'be', '\\\\', '()', 'in', 'then', '$.', 'emptyset', '=\\\\', 'delta_j', '\\\\', 'cup', '\\\\', 'delta_i', '$\\\\', 'satisfy', ',.)$', 'w_j', '(', 'f', '$', 'and', ',.)$', 'w_i', '(', 'f', '$', 'functions', 'the', 'of', '$', 'delta_j', '$\\\\', 'and', '$', 'delta_i', '$\\\\', 'supports', 'the', '$,', 'c', '$', 'intersecting', '$', 'e_j', '=', 'not', '\\\\', 'e_i', '$', 'edges', 'two', 'every', 'for', 'that', 'such', 's', '$', 'f', '$', 'choose', '$', 'c', '$', 'cell', 'a', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'given', '().', 'in', '$', 'f', '$', 'functions', 'the', 'from', 'comes', 'integrand', 'the', 'of', 'dependence', '$', 'z_3', ',', 'z_2', ',', 'z_1', '$', 'only', 'the', ',', 'case', 'our', 'in', ',', 'however', '.', 'defined', 'well', 'be', 'not', 'may', 'function', 'valued', '-', 'operator', 'an', 'of', 'integral', 'the', ',', 'apriori', '.', 'value', 'absolute', 'its', 'take', 'to', 'meaningful', 'is', 'it', ',', 'hence', ')$.', 'ab', ')}(\\\\', '3', '^{(', 'cyl', '$\\\\', 'in', 'adjoint', '-', 'self', 'essentially', 'is', 'operator', 'total', 'the', ',', 'edges', 'different', 'with', 'associated', 'operators', 'of', 'commutativity', 'the', 'and', 'operators', '$', 'j', '$', 'the', 'of', 'adjointness', '-', 'self', 'the', 'to', 'due', ')$.', 'ab', '(\\\\', 'cyl', '$\\\\', 'in', 'defined', 'consistently', 'is', 'operator', 'the', 'so', ')$', 'ab', \"'}(\\\\\", 'g', '{\\\\', '_', ')}', '3', '^{(', 'cyl', '\\\\', 'cap', ')\\\\', 'ab', '(\\\\', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '$\\\\', 'any', 'on', 'agrees', 'result', 'the', 'that', 'see', 'to', 'easy', 'is', 'it', '$.', 'g', '$\\\\', 'every', 'for', '$', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '$\\\\', 'subspace', 'a', 'in', '()', 'by', 'defined', 'is', ')$', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '$\\\\', 'operator', 'the', ')$.', 'ab', '(\\\\', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '\\\\', 'in', '\\\\', 'g', '\\\\', 'psi_', '$\\\\', 'for', 'ee', '\\\\', 'g', '\\\\', 'psi_', '\\\\', ')\\\\,', 'big', '\\\\,\\\\,\\\\', '2z_3', '^', 'd', '\\\\,', '2z_2', '^', 'd', '\\\\,', '2z_1', '^', 'd', ')', 'big', ')\\\\,\\\\', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'big', '\\\\', 'tr', '\\\\', '}\\\\,', '3', ')^', 'pc', '{(\\\\', 'int_', '(\\\\', 'big', '\\\\', '}\\\\,', '12', '}{', '1', '{', 'frac', '\\\\', '=\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'q_c', '\\\\', 'be', '\\\\', 'evaluate', 'to', 'want', 'we', ',', 'thus', '().', 'formula', 'full', 'the', 'of', 'version', 'quantum', 'the', 'to', 'turn', 'now', 'can', 'we', '$.', 'pc', '$\\\\', 'with', '$', 'e_i', '$', 'of', 'point', 'intersection', 'the', 'is', '$', 'w_i', '$', '$,', 'i', '$', 'given', ',', 'and', '$', 'v', '$', 'at', 'intersecting', '$', 'g', '$\\\\', 'of', 'edges', 'the', 'labelling', 'set', 'the', 'through', 'run', '$', 'k', ',', 'j', ',', 'i', '$', 'where', 'ee', '\\\\', '},', 'k', '}^{', 've_k', '{', 'j_', '}', 'j', '}^{', 've_j', '{', 'j_', '}', 'i', '}^{', 've_i', '{', 'j_', '}', 'ijk', '{', 'e_', '\\\\', ')', 'w_k', ',', 'z_3', '(', 'f', ')', 'w_j', ',', 'z_2', '(', 'f', ')', 'w_i', ',', 'z_1', '(', 'f', '}', 'i', '=', 'not', '\\\\', 'k', '=', 'not', '\\\\', 'j', '=', 'not', '\\\\', 'i', '{', 'sum_', '}\\\\', '4', 'over', '\\\\', '1', '-{', '\\\\', '=', ')', 'big', ')\\\\', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'big', '\\\\', 'tr', '\\\\', '{|...|}', 'label', '\\\\', 'be', '\\\\', 'is', ')$', 'ab', '(\\\\', 'g', '\\\\', 'cyl_', '$\\\\', 'space', 'the', 'in', 'operator', 'the', 'of', 'action', 'the', 'for', 'result', 'the', '.', 'form', 'general', 'its', 'derive', 'to', '$', 'u_i', '=', '_i', '^+', 'u', '$', 'and', '$', '1', '=', '_i', '^-', 'u', '$', 'substitution', 'the', 'make', 'may', 'one', 'that', 'so', '^-$', 'u_i', '^+', 'u_i', '=', 'u_i', '$', 'transports', 'parallel', 'entire', 'the', 'of', 'function', 'a', 'fact', 'in', 'is', '()', 'of', 'side', 'hand', 'right', 'the', 'that', 'means', 'that', 'ee', '\\\\', ').', 'ab', '(\\\\', 'g', '\\\\', '_', ')}', '0', '^{(', 'cyl', '\\\\', '\\\\', 'rightarrow', '\\\\', ')\\\\', 'ab', '(\\\\', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '\\\\', ':\\\\', ')\\\\', 'big', ')\\\\', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'big', '\\\\', 'tr', '\\\\', 'be', '\\\\', ',', 'therefore', '$.', 'pc', '$\\\\', 'of', 'points', 'the', 'at', 'transformations', 'gauge', 'the', 'to', 'respect', 'with', '$', 'g', '\\\\', 'psi_', '$\\\\', 'of', 'invariance', 'the', 'preserves', 'it', ',', 'invariant', 'gauge', 'is', 'operator', 'the', 'since', ',', 'however', '$.', 'pc', '$\\\\', 'intersect', 'they', 'where', 'points', 'the', 'at', 'edges', 'the', 'splitting', 'by', '$', 'g', '$\\\\', 'from', 'obtained', 'graph', 'the', 'is', '$', 'g_1', '$\\\\', 'where', 'ee', '\\\\', ')', 'ab', '}(\\\\', 'g_1', '{\\\\', '_', ')}', '0', '^{(', 'cyl', '\\\\', '\\\\', 'rightarrow', '\\\\', ')\\\\', 'ab', '(\\\\', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '\\\\', 'be', '\\\\', 'map', 'a', 'defines', '))$', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'tr', '$\\\\', 'operator', 'the', '().', 'of', 'consequence', 'a', 'is', 'which', 'property', 'following', 'the', 'by', 'simplified', 'considerably', 'is', 'side', 'hand', 'right', 'the', 'of', 'evaluation', 'the', 'ea', '\\\\', ')).', 'a', '(', 'u_n', '),...,', 'a', '(', 'u_1', '(', 'psi', '\\\\', '}', 'e_f', '}^', 'u_k', '{', 'partial', '\\\\', 'c_d', '}^', 'u_j', '{', 'partial', '\\\\', 'a_b', '}^', 'u_i', '{', 'partial', '\\\\', 'over', '\\\\', '3', '^', 'partial', '{\\\\', 'times', '&\\\\', '&', '\\\\\\\\', 'nonumber', '\\\\', 'e_f', ')^', '_k', '^-', 'tau_ku', '\\\\', '_k', '^+', 'u', '(', 'c_d', ')^', '_j', '^-', 'tau_ju', '\\\\', '_j', '^+', 'u', '(', 'a_b', ')^', '_i', '^-', 'u', 'tau_i', '\\\\', '_i', '^+', 'u', '(', ')', 'big', '\\\\', '}', '1', ')^{-', '_i', '^-', 'u', '(', '_k', '^-', 'u', 'tau_k', '}\\\\', '1', ')^{-', '_k', '^-', 'u', '(', '_j', '^-', 'u', 'tau_j', '\\\\', '}', '1', ')^{-', '_j', '^-', 'u', '(', '_i', '^-', 'u', 'tau_i', '(\\\\', 'big', '\\\\', 'tr', '\\\\', 'times', '\\\\', '&', '&', '\\\\\\\\', 'nonumber', ')\\\\', 'w_k', ',', 'z_3', '(', 'f', ')', 'w_j', ',', 'z_2', '(', 'f', ')', 'w_i', ',', 'z_1', '(', 'f', '}', 'pc', '\\\\', 'in', '\\\\', 'w_i', '=', 'not', '\\\\', 'w_k', '=', 'not', '\\\\', 'w_j', '=', 'not', '\\\\', 'w_i', '{', 'sum_', '\\\\', '&=&\\\\', '\\\\\\\\', 'nonumber', '\\\\', ')\\\\', 'a', '(', 'g', '\\\\', 'psi_', '))\\\\', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'tr', '&\\\\', '&', '{|..|}', 'label', '\\\\', 'ba', '\\\\', 'reads', 'now', '()', 'eq', 'that', 'so', 'ee', '\\\\', '}.', 'a_b', '}^', 'u_i', '{', 'partial', '\\\\', 'over', '\\\\', 'psi', '\\\\', 'partial', '{\\\\', 'a_b', '))^', 'a', '^-(', 'u_i', 'tau_i', ')\\\\', 'a', '^+(', 'u_i', '(', '=\\\\', ')\\\\', 'a', '(', 'g', '\\\\', 'psi_', '}\\\\', 'i', '}^{', 'w_i', '{', 'j_', 'be', '\\\\', 'by', 'given', 'is', '))$', 'a', '(', 'u_n', '),...,', 'a', '(', 'u_1', '(', 'psi', ')=\\\\', 'a', '(', 'g', '\\\\', 'psi_', '$\\\\', 'function', 'cylindrical', 'a', 'on', '}$', 'i', '}^{', 'w_i', '{', 'j_', '$', 'of', 'action', 'the', '.', 'respectively', '$', '_i', '^+', 'u', '$', 'and', '$', '_i', '^-', 'u', '$', '$,', 'u_i', '$', 'by', '$', '_i', '^+', 'e', '$', 'and', '$', '_i', '^-', 'e', '$', '$,', 'e_i', '$', 'along', 'transports', 'parallel', 'the', 'denote', ',', 'assignment', 'path', 's', \"'\", 'pietri', 'de', 'using', '.', 'sections', '-', 'sub', 'two', 'last', 'the', 'of', 'restrictions', 'the', 'satisfies', '$', 'p', '$\\\\', 'partition', 'the', 'that', 'suppose', 'now', 'us', 'let', '$.', 'j', ',', 'i', '$', 'in', 'antisymmetric', 'is', 'trace', 'the', 'because', 'vanishes', 'ee', '\\\\', '}\\\\', 'i', '}^{', 'w_i', '{', 'j_', '}', 'j', '}^{', 'w_i', '{', 'j_', '}', 'k', '}^{', 'w_k', '{', 'j_', ')', 'big', '}\\\\', 'w_kw_i', '{', 'tau_ku_', '}\\\\', 'w_iw_k', '{', 'tau_ju_', '\\\\', 'tau_i', '(\\\\', 'big', '\\\\', 'tr', '\\\\', 'be', '\\\\', '$', 'w_j', '=', 'w_i', '$', 'to', 'corresponding', 'term', 'the', 'hence', 'ee', '\\\\', '.', '\\\\,', '0', '=\\\\', '}]\\\\', 'j', '^', 'w_i', '{', 'j_', '},', 'i', '^', 'w_i', '{', 'j_', '[', 'be', '\\\\', ',', 'commute', '$', 'w_i', '$', 'with', 'associated', 'operators', 'the', ')$,', 'ab', '(\\\\', 'g', '\\\\', 'cyl_', '$\\\\', 'to', 'restricted', ',', 'particular', 'in', 'ee', '\\\\', '}).', 'i', '}^{', '_i', '^-', 'e', '{', 'j_', '-\\\\', '}\\\\', 'i', '}^{', '_i', '^+', 'e', '{', 'j_', '}(', '2', 'over', '\\\\', '1', '{', '=\\\\', '}\\\\', 'i', '}^{', 'w_i', '{', 'j_', 'be', '\\\\', ':', 'have', 'we', '$,', 'pc', '\\\\', 'in', '\\\\', 'w_i', '$', 'point', 'intersection', 'an', 'at', 'meet', 'that', '$', 'g', '$\\\\', 'of', '$', '_i', '^+', 'e', ',', '_i', '^-', 'e', '$', 'segments', 'the', 'of', 'terms', 'in', ',', 'that', 'note', ',', 'this', 'see', 'to', '$|...|$.', 'of', 'entries', 'the', 'of', 'adjointness', 'self', 'the', 'for', 'relevant', 'is', 'which', 'sum', 'the', 'to', 'contribute', '$', 'w_1', '=', 'not', '\\\\', 'w_3', '=', 'not', '\\\\', 'w_2', '=', 'not', '\\\\', 'w_1', '$', 'terms', 'the', 'only', 'that', 'show', 'can', 'one', '))$.', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')\\\\', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'tr', '$\\\\', 'operator', 'the', 'investigate', 'and', '()', 'to', 'return', 'now', 'us', 'let', '.', 'possible', 'as', 'of', 'treatment', 'the', 'to', 'close', 'as', 'keep', 'to', 'so', 'do', 'not', 'did', 'we', '$.', 'ab', '$\\\\', 'on', 'regularization', \"'\", 'external', '`', 'the', 'out', 'carrying', 'by', 'entirely', 'dependence', 'path', 'of', 'issue', 'the', 'avoided', 'have', 'could', 'we', ':', 'choice', 'a', 'is', 'there', ',', 'representation', 'connection', 'the', 'in', '.', 'triads', 'smeared', 'of', 'invariance', 'gauge', 'ensure', 'to', 'necessary', 'become', 'paths', 'extra', 'the', 'and', '$', 'gb', '/\\\\', 'ab', '$\\\\', 'with', 'only', 'deals', ',', 'hand', 'other', 'the', 'on', ',', 'in', 'used', 'representation', 'loop', 'the', '.', 'themselves', 'connections', 'generalized', 'of', '$', 'ab', '$\\\\', 'space', 'the', 'on', 'but', 'transformations', 'gauge', 'modulo', 'connections', 'generalized', 'of', '$', 'gb', '/\\\\', 'ab', '$\\\\', 'space', 'the', 'on', 'not', 'worked', 'we', 'because', 'regularization', \"'\", 'internal', '`', 'the', 'in', 'arise', 'not', 'did', 'assignments', 'path', 'of', 'issue', 'the', 'that', 'note', 'us', 'let', 'discussion', 'this', 'conclude', 'to', '$.', 'v', '$', 'at', 'exactly', 'intersect', '$', 'c', '$', 'in', '$', 's_a', '$', 'surfaces', '-', '2', 'the', 'that', 'assumption', 'regularization', \"'\", 'internal', '`', 'the', 'of', 'part', 'counter', 'regularization', \"'\", 'external', '`', 'the', 'is', '$', 'v', '$', 'at', 'right', 'begin', 'paths', 'the', 'all', 'making', '$,', 'v', '$', 'vertex', 'a', 'containing', 'cell', 'a', 'given', ':', 'schemes', 'regularization', 'two', 'the', 'in', 'used', 'partitions', 'on', 'restrictions', 'the', 'between', 'similarity', 'the', 'on', 'comment', 'just', 'will', 'we', ',', 'present', 'the', 'for', '.', 'sections', '-', 'sub', 'two', 'next', 'the', 'in', 'limit', 'the', 'evaluate', 'will', 'we', '.', 'unambiguously', 'removed', 'be', 'can', 'regulator', 'the', '$,', 'p', '$\\\\', 'partition', 'the', 'on', 'restrictions', 'these', 'with', ').', 'satisfied', 'is', '()', 'assumption', 'regularity', 'previous', 'the', 'that', 'such', '(', '}$', 'zv', '{', 'p_', '$', 'path', 'any', 'assign', ',', 'edge', 'an', 'by', 'intersected', 'not', 'is', 'which', '$', 'pc_v', '\\\\', 'in', '\\\\', 'z', '$', 'point', 'a', 'to', 'and', '$', '_i', '^{-}', 'e', ':=\\\\', '}\\\\', 'w_iv', '{', 'p_', '$', 'set', '$', 'pc_v', '\\\\', 'cap', '\\\\', 'e_i', 'in', '\\\\', 'w_i', '$', 'point', 'intersection', 'each', 'to', '$.', 'e_i', '$', 'of', 'segment', 'remaining', 'the', '$', '_i', '^+', 'e', '$', 'by', 'and', '$', 'c_v', '$', 'inside', 'contained', '$', 'e_i', '$', 'of', 'segment', 'the', '$', '_i', '^-', 'e', '$', 'by', 'denote', '.', 'outgoing', 'be', 'to', 'them', 'orient', 'and', '$,', 'k', ',...,', '1', '=', 'i', '$', '$,', 'e_i', '$', 'by', '$', 'v', '$', 'at', 'meet', 'that', '$', 'g', '$\\\\', 'of', 'edges', 'the', 'denote', '.', 'follows', 'as', 'defined', 'is', 'it', '.', 'pietri', 'de', 'by', 'us', 'to', 'out', 'pointed', 'was', 'and', 'exist', 'does', 'assignment', 'an', 'such', '.', 'cell', 'every', 'for', 'ee', '\\\\', '.', 'g', '\\\\', '=\\\\', '\\\\', '_1', \"'}\", 'g', '{\\\\', '=\\\\', '\\\\', '_1', '}', 'g', '{\\\\', '}', 'grpr', '{', 'label', '\\\\', 'be', '\\\\', 'have', 'we', 'graphs', 'above', 'the', 'for', 'that', 'such', 'assignment', 'paths', 'a', 'choose', 'we', '$,', 'g', '$\\\\', 'graph', 'a', 'given', ',', 'if', 'disappear', 'obviously', 'problems', 'these', '.', 'refined', 'is', '$', 'p', '$\\\\', 'as', 'convergent', '-', 'non', 'highly', '$', 'g', '\\\\', 'psi_', '}\\\\', 'p', '{\\\\', 'v_', '$', 'vectors', 'of', 'sequence', 'the', 'makes', 'this', 'all', '.', 'projection', 'the', 'of', 'norm', 'the', 'affect', 'not', 'does', 'shrinking', 'hence', '$.', '_1', '}', 'g', '${\\\\', 'to', 'corresponding', 'space', 'the', 'on', '$', 'g', '\\\\', 'psi_', '}}}\\\\', 'v', '{', '_', '}', 'c', '{{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'of', 'projection', 'the', 'to', 'equivalent', 'diffeomorphism', ',', 'generically', ',', 'is', '$', '_1', \"'}\", 'g', '${\\\\', 'to', 'corresponding', 'space', 'the', 'on', '$', 'g', '\\\\', 'psi_', '}}}\\\\', 'v', '{', '_', \"'}\", 'c', '{{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'of', 'projection', 'the', ',', 'moreover', '$.', 'g_1', '$\\\\', 'then', 'different', ')', 'generically', '(', 'is', '$', 'g', '\\\\', 'psi_', '}}}\\\\', 'v', '{', '_', \"'}\", 'c', '{{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'to', 'corresponding', '$', '_1', \"'}\", 'g', '${\\\\', 'graph', 'the', '}$.', 'w_ix_0', '{', 'p_', '$', 'paths', 'the', ',', 'edges', 'new', 'adding', 'and', '$', 'pc', '$\\\\', 'with', '$', 'w_i', '$', 'points', 'intersection', 'the', 'at', 'made', 'vertices', 'new', 'introducing', 'by', '$', 'g', '$\\\\', 'from', 'obtained', '$', 'g_1', '$\\\\', 'graph', 'a', 'on', 'component', 'zero', '-', 'non', 'a', 'has', '$', 'g', '\\\\', 'psi_', '}}}\\\\', 'v', '{', 'c_', '{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'that', 'is', 'reason', 'main', 'the', '$.', '_v', \"'}\", 'c', '${', 'of', 'independently', ',', 'zero', '-', 'non', 'is', '\\\\|$', 'g', '\\\\', 'psi_', '}}}\\\\', 'v', '{', '_', \"'}\", 'c', '{{', 'q_', '{\\\\', 'sqrt', '\\\\', '-', 'g', '\\\\', 'psi_', '}}}\\\\', 'v', '{', 'c_', '{', 'q_', '{\\\\', 'sqrt', '$\\\\|\\\\', 'norm', 'the', ',', 'assignment', 'paths', 'generic', 'a', 'for', 'then', '$', 'v', '$', 'containing', '$', '_v', \"'}\", 'c', '${', 'cell', 'a', 'to', '$', 'c_v', '$', 'shrink', 'we', 'if', 'but', '$.', 'v', '$', 'vertex', 'every', 'for', 'separately', '$', 'v', '$', 'to', '$', 'c_v', '$', 'shrink', 'we', 'as', '$', 'g', '\\\\', 'psi_', '}}\\\\', 'c_v', '{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'each', 'of', 'convergence', 'the', 'to', 'reduces', 'convergence', 'of', 'problem', 'the', 'so', '$.', 'g', '$\\\\', 'of', '$', 'v', '=', 'not', \"'\\\\\", 'v', '$', 'vertex', 'any', 'to', 'corresponding', '$', 'g', '\\\\', 'psi_', \"'}}}\\\\\", 'v', '{', 'c_', '{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'to', 'orthogonal', '.}', 'networks', '-', 'spin', 'by', 'given', 'graphs', 'distinct', 'to', 'associated', 'subspaces', 'orthogonal', 'into', ')$', 'ab', '(\\\\', 'cyl', '$\\\\', 'of', 'decomposition', 'the', 'to', 'refers', \"'\", 'component', '`', 'here', '{', 'footnote', '\\\\', '%', 'component', 'a', 'contains', '$', 'g', '\\\\', 'psi_', '}}\\\\', 'c_v', '{', 'q_', '{\\\\', 'sqrt', '$\\\\', 'vector', 'the', '$,', 'p', '$\\\\', 'in', 'assignment', 'path', 'generic', 'and', '$', 'v', '$', 'vertex', 'given', 'a', 'for', ',', 'indeed', '.}', 'in', 'reported', 'one', 'the', 'from', 'different', 'be', 'would', 'limit', 'final', 'the', ',', 'operator', 'constraint', 'hamiltonian', 'the', 'of', 'definition', 'the', 'in', 'as', '()', 'topology', 'same', 'the', 'use', 'to', 'wishes', 'one', 'if', 'that', 'means', 'this', '.', 'concerned', 'is', 'states', 'such', 'of', 'action', 'the', 'as', 'far', 'as', 'disappear', 'never', 'they', 'so', ',', 'paths', 'of', 'shrinking', 'the', 'to', 'sensitive', 'not', 'are', '()', 'in', '|$', 's', 'bra', '$\\\\', 'states', 'dual', 'invariant', 'diffeomorphism', 'that', 'however', 'note', '.', 'matrix', 'identity', 'the', 'by', 'paths', 'shrunk', 'the', 'to', 'corresponding', 'holonomies', 'the', 'setting', 'simply', 'by', 'obtained', 'being', 'root', 'square', 'the', 'under', 'limit', 'the', '...}$,', 'lim', '{\\\\', 'sqrt', '\\\\', ':=', '{...}', 'sqrt', '\\\\', 'lim', '$\\\\', 'setting', 'by', 'taken', 'is', 'limit', 'the', ',', 'operator', 'this', 'of', 'derivation', 'original', 'the', 'in', '{', 'footnote', '\\\\', '.%', 'exist', 'not', 'still', 'may', 'cells', 'the', 'shrink', 'we', 'as', 'limit', 'its', 'and', 'assignments', 'path', 'through', '$', 'p', '$\\\\', 'partition', 'the', 'on', 'depends', 'still', '$', 'g', '\\\\', 'psi_', '}\\\\', 'p', '^{\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'vector', 'resulting', 'the', '$.', 'v', '$', 'containing', 'cell', 'the', 'is', '$', 'c_v', '$', 'and', '$', 'g', '$\\\\', 'of', 'vertices', 'of', 'set', 'the', 'through', 'runs', '$', 'v', '$', 'where', 'ee', '\\\\', 'g', '\\\\', 'psi_', '}}\\\\', 'c_v', '{', 'q_', '{\\\\', 'sqrt', '\\\\', 'sum_v', '\\\\', '=\\\\', '\\\\', 'g', '\\\\', 'psi_', '}\\\\', 'p', '^{\\\\', '_r', '}', 'v', '{', 'hat', '\\\\', '}', 'volada', '{', 'label', '\\\\', 'be', '\\\\', 'by', 'given', 'is', 'operator', 'volume', 'regulated', 'the', ',', 'restriction', 'above', 'the', 'satisfying', '$', 'p', '$\\\\', 'partition', 'a', 'for', '.', 'section', 'in', 'used', 'that', 'to', 'similar', 'very', 'is', 'restriction', 'this', ')$.', 'iia', '$(', 'and', ')$', 'i', '$(', 'types', 'the', 'of', 'only', 'cells', 'containing', 'partitions', 'to', 'ourselves', 'restrict', 'to', 'is', '---', 'available', 'one', 'natural', 'only', 'the', 'be', 'to', 'seems', 'which', '---', 'make', 'will', 'we', 'choice', 'the', '$.', 'g', '$\\\\', 'graph', 'the', 'using', 'taken', 'is', 'limit', 'the', 'how', 'on', 'restrictions', 'put', 'to', 'has', 'one', ',', 'section', 'in', 'as', ',', 'convergence', 'ensure', 'to', ',', 'summarize', 'to', '.', 'limit', 'the', 'in', 'diverges', '\\\\|$', 'g', '\\\\', 'psi_', '\\\\', 'c', '\\\\', '_', '}', 'v', '{', 'hat', '$\\\\|\\\\', 'norm', 'the', 'that', 'is', 'consequence', 'the', 'that', 'check', 'can', 'one', '.', 'infinity', 'to', 'tends', '$', 'e_2', '$', 'and', '$', 'e_1', '$', 'by', 'simultaneously', 'crossed', 'cells', 'of', 'number', 'the', ',', 'cells', 'of', 'size', 'maximal', 'the', 'shrinks', 'one', 'as', ',', 'generically', ',', 'case', 'this', 'in', '$.', 'v', '$', 'at', 'other', 'each', 'to', 'tangent', 'are', '$', 'e_2', '$', 'and', '$', 'e_1', '$', 'when', 'divergences', 'produces', 'procedure', 'limiting', 'the', ',', 'reasons', 'similar', 'for', '.', 'size', 'its', 'to', 'than', 'rather', '$', 'c_v', '$', 'given', 'a', 'of', 'rotations', 'to', 'sensitive', 'is', 'which', 'ambiguity', 'that', 'eliminate', 'not', 'does', '$', 'p', '$\\\\', 'of', 'shrinking', '.', 'dependence', 'coordinates', 'the', 'by', 'caused', 'ambiguity', 'the', 'out', 'bring', 'to', 'serves', 'simply', 'this', 'but', '.', 'cell', 'adjacent', 'same', 'the', 'cross', 'not', 'do', 'and', '$', '_v', \"'}\", 'c', '${', 'of', 'faces', 'disjoint', 'intersect', '$', 'e_2', '$', 'and', '$', 'e_1', '$', 'that', 'such', 'system', 'coordinate', 'another', 'choose', ',', 'course', 'of', ',', 'may', 'one', '$.', 'g', '\\\\', 'psi_', '}\\\\', 'c', '{', 'q_', '$\\\\', 'term', 'zero', '-', 'non', 'a', 'produces', 'this', '$.', 'e_2', '$', 'and', '$', 'e_1', '$', 'edges', 'the', 'by', 'crossed', 'is', 'face', 'that', 'shares', 'which', '$', 'c', '$', 'cell', 'other', 'the', ').', '3', '.', 'fig', 'see', '(', '$', 'v', '$', 'containing', '$', 'c_v', '$', 'cell', 'a', 'of', 'face', 'same', 'the', 'cross', '$', 'v', '$', 'at', 'intersecting', '$', 'e_2', '$', 'and', '$', 'e_1', '$', 'edges', 'two', 'when', 'case', 'a', 'consider', '$.', 'r', '$', 'on', 'system', 'coordinates', 'fixed', 'the', 'by', 'defined', '$', 'l', '$', 'size', 'the', 'of', 'lattice', 'cubic', 'a', 'by', 'given', '$', 'p_l', '$\\\\', 'partition', 'the', 'use', 'just', 'we', 'suppose', ',', 'this', 'see', 'to', '.', 'diverge', 'even', 'may', 'and', 'dependent', 'coordinate', 'be', 'can', 'contributions', 'these', ';', 'simply', 'so', ')', 'iib', '(', 'type', 'of', 'cells', 'of', 'rid', 'get', 'not', 'can', 'one', 'that', 'is', 'overlooked', 'easily', 'be', 'may', 'what', '.', 'ignored', 'be', 'can', 'type', 'this', 'of', 'cells', '();', 'to', 'contribute', '$', 'w_1', '=', 'not', '\\\\', 'w_3', '=', 'not', '\\\\', 'w_2', '=', 'not', '\\\\', 'w_1', '$', 'only', ',', 'below', 'see', 'will', 'we', 'as', ',', 'because', 'ee', '\\\\', '0', '=\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '}', 'p', '{\\\\', 'q_', '\\\\', 'be', '\\\\', '),', 'iia', '(', 'type', 'of', 'cell', 'a', 'for', ',', 'indeed', '.', 'result', 'final', 'the', 'to', 'trivially', '-', 'non', 'contribute', 'should', 'that', 'cells', ')', 'i', '(', 'type', 'the', 'only', 'is', 'it', ',', 'suggests', 'section', 'and', 'of', 'discussion', 'the', 'as', '$.', 'g', '$\\\\', 'of', 'edge', 'one', 'than', 'more', 'intersects', 'and', '$', 'g', '$\\\\', 'of', 'vertex', 'any', 'surround', 'not', 'does', '$', 'pc', '$\\\\', '):', 'iib', '(', 'type', ';\\\\\\\\', 'points', 'two', 'most', 'at', 'in', '$', 'g', '$\\\\', 'of', 'edge', 'one', 'most', 'at', 'intersects', 'and', '$', 'g', '$\\\\', 'of', 'vertex', 'any', 'surround', 'not', 'does', '$', 'pc', '$\\\\', '):', 'iia', '(', 'type', ';\\\\\\\\', 'once', 'exactly', 'vertex', 'that', 'meets', 'which', 'edge', 'every', 'intersects', 'and', '$', 'g', '$\\\\', 'of', 'vertex', 'a', 'surrounds', '$', 'pc', '$\\\\', '):', 'i', '(', 'type', ':\\\\\\\\', 'way', 'following', 'the', 'in', 'classified', 'be', 'can', '$', 'p', '$\\\\', 'of', 'cells', 'the', ',', 'coordinates', 'the', 'rescaling', 'the', 'by', 'say', ',', 'refined', 'sufficiently', 'been', 'has', 'partition', 'the', 'that', 'assume', 'we', 'if', ',', 'now', '.)', 'independent', '$', 'g', '$\\\\', 'graph', 'being', 'assumption', 'the', ',', 'fixed', 'remains', 'cell', 'any', 'of', 'segment', 'no', 'that', 'way', 'a', 'such', 'in', 'shrunk', 'is', '$', 'p', '$\\\\', 'that', 'assuming', 'by', 'ensured', 'be', 'can', 'property', 'this', '(', '$.', 'pc', '$\\\\', 'any', 'intersects', '$', 'g', '$\\\\', 'of', 'vertex', 'no', 'that', '.,', 'e', '.', 'i', ',', 'generic', 'is', '$', 'p', '$\\\\', 'partition', 'the', 'that', 'assumed', 'only', 'have', 'we', ',', 'far', 'so', '$.', 'g', '\\\\', 'psi_', '$\\\\', 'with', 'compatible', 'graph', 'a', 'be', '$', 'g', '$\\\\', 'let', '.', 'problems', 'potential', 'the', 'isolate', 'us', 'let', '.', 'converge', 'to', '$', 'g', '\\\\', 'psi_', '}\\\\', 'p', '^{\\\\', 'v_r', '$', 'vector', 'the', 'for', 'sufficient', 'not', 'is', '$', 'p', '$\\\\', 'in', 'cells', 'of', 'shrinking', 'the', 'that', 'out', 'turns', 'it', '$,', 'cyl', '\\\\', 'in', '\\\\', 'g', '\\\\', 'psi_', '$\\\\', 'given', '.', 'procedure', 'limiting', 'the', 'restricting', 'appropriately', 'by', 'overcome', 'be', 'can', 'they', 'how', 'and', 'arise', 'they', 'how', 'discuss', 'first', 'to', 'convenient', 'is', 'it', '.', 'regulators', 'the', 'removing', 'in', 'obstacles', 'are', 'there', ',', 'completed', 'are', 'steps', 'these', 'when', 'even', 'that', 'out', 'turns', 'it', '.', 'later', 'detail', 'in', 'steps', 'these', 'out', 'carry', 'will', 'we', '.', 'defined', '-', 'well', 'be', 'could', '()', 'of', '}|$', 'z_1z_2z_3', '{', 'q_', '|\\\\', '2z_3', '^', 'd', '2z_2', '^', 'd', '2z_1', '^', 'd', 'int', '$\\\\', 'version', 'quantum', 'the', 'then', ',', 'adjoint', '-', 'self', 'is', 'it', 'that', 'show', 'could', 'we', 'it', '}$.', 'z_1z_2z_3', '{', 'q_', '$\\\\', 'by', '()', 'of', 'of', 'side', 'right', 'the', 'denote', 'us', 'let', '$.', 'pc', '$\\\\', 'with', '$', 'g', '$\\\\', 'of', 'points', 'intersection', 'isolated', 'the', 'with', 'coincide', 'simultaneously', 'they', 'if', 'only', 'contribute', '$', 'pc', '$\\\\', 'on', '$', 'w_j', ',', 'w_j', ',', 'w_i', '$', 'points', 'the', 'where', 'ea', '\\\\', '},', 'i', '}^{', 'w_i', '{', 'j_', '}', 'j', '}^{', 'w_j', '{', 'j_', 'k', '}^', 'w_k', '{', 'j_', ')', 'big', ')\\\\', 'w_i', ',', 'w_k', '(', 'u', 'tau_k', '\\\\', ')', 'a', ')(', 'w_k', ',', 'w_j', '(', 'u', 'tau_j', '\\\\', ')', 'a', ')(', 'w_j', ',', 'w_i', '(', 'u', 'tau_i', '(\\\\', 'big', '\\\\', 'tr', '\\\\', '\\\\,', 'times', '\\\\', '\\\\\\\\', 'nonumber', ')\\\\', 'w_k', ',', 'z_3', '(', 'f', ')', 'w_j', ',', 'z_2', '(', 'f', ')', 'w_i', ',', 'z_1', '(', 'f', '}\\\\,', 'pc', '\\\\', 'in', '\\\\', 'w_k', ',', 'w_j', ',', 'w_i', '{', 'sum_', '\\\\', '=\\\\', '\\\\', 'psi', '))\\\\', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'tr', '\\\\', '{|.|}', 'label', '\\\\', 'ba', '\\\\', ',', 'then', 'ee', '\\\\', '.', \"'}}\\\\,\", 'z', ',', 'x_0', '{', 'p_', '{', 'u_', '}}', 'zx_0', '{', 'p_', '{', 'u_', ':=\\\\', \"')\\\\\", 'z', ',', 'z', '(', 'u', 'be', '\\\\', 'set', 'and', '$', 'p', '$\\\\', 'partition', 'the', 'in', 'paths', 'the', 'be', '}$', 'x_0z', '{', 'p_', '$', 'let', '$.', 'pc', '\\\\', 'in', '\\\\', 'w_i', '$', 'intersecting', '$', 'g', '$\\\\', 'of', 'edges', 'of', 'segments', 'of', 'set', 'the', 'over', 'runs', '$', 'p_i', '$', 'where', 'ee', '\\\\', 'i', '}^', 'p_i', ',', 'w_i', '{', 'j_', ')\\\\,', 'p_i', '(', 'k_c', '\\\\', '}', 'w_i', '}\\\\', 'at', 'rm', '{\\\\', '\\\\', 'p_i', '{', 'sum_', '}\\\\', '2', 'over', '\\\\', '1', '{', ':=\\\\', '\\\\', 'i', '}^', 'w_i', '{', 'j_', 'be', '\\\\', '$,', 'pc', '$\\\\', 'with', '$', 'g', '$\\\\', 'of', '$', 'e_i', '$', 'edges', 'the', 'of', 'points', 'intersection', 'the', 'are', '$', 'w_i', '$', 'where', '(),', 'of', '}$', 'p_i', ',', 'w_i', '{', 'i_', '^', 'j', '$', 'operators', 'the', 'through', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'of', 'elements', 'on', 'acts', '))$', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '\\\\', ')', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(\\\\', 'tr', '$\\\\', 'operator', 'the', '$.', 'g', '$\\\\', 'to', 'respect', 'with', 'generic', 'is', 'partition', 'the', 'that', 'assume', 'only', 'will', 'we', '$.', 'g', '$\\\\', 'graph', 'a', 'with', 'compatible', ')$', 'ab', '(\\\\', 'g', '\\\\', 'cyl_', '$\\\\', 'functions', 'cylindrical', 'consider', 'and', '$', 'p', '$\\\\', 'partition', 'arbitrary', 'an', 'with', 'begin', 'then', 'us', 'let', '}$.', 'f', ',', 'pc', '{\\\\', 'e_', '$\\\\', 'operator', 'the', 'by', ')$', 'e', ',', 'a', '}(', 'c', '{', 'q_', '$', 'functional', 'the', 'in', ')$', 'z', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '$', 'every', 'replace', 'to', 'is', 'idea', 'main', 'the', ':', 'section', 'in', 'adopted', 'one', 'the', 'to', 'parallel', 'is', 'procedure', 'overall', 'the', '$.', 'g', '\\\\', 'h_', '$\\\\', 'space', 'hilbert', 'the', 'on', 'operators', 'regulated', 'the', 'of', 'action', 'the', 'study', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'on', 'focus', 'first', 'will', 'we', ',', 'paper', 'main', 'the', 'in', 'as', '.', 'regulators', 'the', 'remove', 'then', 'and', 'theory', 'quantum', 'the', 'to', '}$', 'p', '^{\\\\', 'v_r', '$', 'expression', 'regulated', 'the', 'promote', 'to', 'again', 'is', 'idea', 'the', ')$.', 'e', '(', 'v_r', 'goesto', '\\\\', ')', 'e', ',', 'a', '}(', 'p', '{\\\\', 'v_', '$', ':', 'have', 'we', ',', 'cells', 'shrink', 'we', 'as', '.', 'space', 'phase', 'classical', 'the', 'on', 'functional', 'volume', 'regulated', 'smolin', '-', 'rovelli', 'the', 'is', 'this', 'ee', '\\\\', ')}.', 'e', ',', 'a', '}(', 'c', '{', 'q_', '{', 'sqrt', '\\\\', '}', 'c', '\\\\', 'in', '\\\\', 'c', '{', 'sum_', '\\\\', ':=\\\\', ')\\\\', 'e', ',', 'a', '}(', 'p', '}^{\\\\', 'r', '{', 'v_', '}', 'rsvol', '{', 'label', '\\\\', 'be', '\\\\', 'set', ',', 'finally', '.', 'invariant', 'gauge', 'is', 'trace', 'the', ')$,', 'x_0', '(', 'g', ')', 'z', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')', 'x_0', '}(', '1', '^{-', 'g', 'mapsto', ')\\\\', 'z', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '$', 'is', 'law', 'transformation', 'gauge', 'the', 'since', '.', 'thereof', 'parametrization', 'any', 'by', 'given', '$', 'pc', '$\\\\', 'on', 'element', 'area', 'dependent', 'parametrization', 'the', 'mean', 'we', '$', '2z', '^', 'd', '$', 'by', 'where', 'ee', '\\\\', ',', '\\\\,', '2z_3', '^', '2z_2d', '^', 'd', '2z_1', '^', 'd', '))|\\\\,', 'z_3', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')', 'z_2', '}(', 'f', ',', 'pc', '{\\\\', 'e_', ')', 'z_1', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '(', 'tr', '|\\\\', '}\\\\,', '3', ')^', 'pc', '{(\\\\', 'int_', '}\\\\', '12', 'over', '\\\\', '1', '{', ':=\\\\', ')\\\\', 'e', '}(', 'c', '{', 'q_', \"'}\", 'rsdet', '{', 'label', '\\\\', 'be', '\\\\', '.}', 'there', 'used', 'notation', 'the', 'in', 'formulas', 'various', 'writing', 'by', 'easier', 'with', 'comparison', 'make', 'to', 'is', 'aim', 'our', '.', 'arguments', 'our', 'for', 'relevant', 'be', 't', \"'\", 'won', 'that', 'but', ',', 'paths', 'extra', 'the', 'of', 'choice', 'the', 'in', 'freedom', 'more', 'some', 'introduces', 'variables', 'loop', 'smolin', '-', 'rovelli', 'the', 'of', 'use', 'the', '{', 'footnote', '\\\\', '%', 'by', 'given', 'is', '$', 'c', '$', 'of', 'volume', 'squared', ',', 'regularized', 'smolin', '-', 'rovelli', 'the', 'ee', '\\\\', '.', 'b', \"'}^\", 'z', '{', 'd', 'wedge', '\\\\', 'a', \"'}^\", 'z', '{', 'd', '}\\\\,\\\\,', 'abc', '{', 'eta_', '\\\\', '}}\\\\,', 'x_0', \"'\", 'z', '{', 'p_', '{', 'u_', \"')\", 'z', '(', 'c', '^', 'e', '}', '1', '}})^{-', 'x_0', \"'\", 'z', '{', 'p_', '{', 'u_', \"')(\", 'z', ',', 'z', '(', 'f', '}', 'pc', '{\\\\', 'int_', '\\\\', '}', '2', 'over', '\\\\', '1', '{', '=\\\\', ')\\\\', 'z', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '}', 'efinv', '{', 'label', '\\\\', 'be', '\\\\', 'as', 'defined', 'is', ')$', 'z', '}(', 'f', ',', 'pc', '{\\\\', 'e_', '$', 'momentum', 'classical', 'regularized', 'covariantly', 'the', ',', 'hand', 'at', 'machinery', 'this', 'with', 'ee', '\\\\', '.', '\\\\,', '1', '=', 'drds', \"')\", 'z', '),', 's', ',', 'r', '(', 'z', '(', 'f', '}\\\\,', 'pc', '{\\\\', 'int_', '\\\\', 'be', '\\\\', 'that', 'such', \"'$,\", 'z', '$', 'in', 'scalar', 'a', 'and', '$', 'z', '$', 'in', 'one', 'weight', 'of', 'density', 'a', 'is', 'which', '$,', 'pc', '$\\\\', 'on', \"')$\", 'z', ',', 'z', '(', 'f', '$', 'field', 'point', 'two', 'negative', '-', 'non', 'a', 'introduce', 'us', 'let', ',', 'finally', '$.', 'p', '$\\\\', 'by', 'denoted', 'be', 'will', 'assignment', 'path', 'a', 'such', 'with', '$', 'c', '$\\\\', 'partition', 'cell', 'a', '$.', 'c', '$\\\\', 'in', 's', '$', 'c', '$', 'the', 'all', 'for', '$,', 'pc', '\\\\', 'in', '\\\\', 'z', '$', 'to', 'respect', 'with', 'uniformly', 'ee', '\\\\', ')', '2', '(', 'su', 'in', '\\\\', '1', '\\\\', 'goesto', '\\\\', ')\\\\', 'a', '}(', 'zx_0', '{', 'u_', '}', 'pr', '{', 'label', '\\\\', 'be', '\\\\', ':', 'have', 'we', '}$', 'zx_0', '{', 'p_', '$', 'path', 'every', 'for', ',', 'cell', 'the', 'of', 'size', 'the', 'shrink', 'we', 'as', ',', 'that', 'such', 'is', 'assignment', 'path', 'the', 'that', 'assume', 'will', 'we', ',', 'convenience', 'later', 'for', '$.', 'c', '$', 'in', '$', 'x_0', '$', 'point', 'fixed', 'a', 'with', 'it', 'connecting', '}$', 'x_0', \"'\", 'z', '{', 'p_', '$', 'path', 'a', 'assign', 'us', 'let', '$', 'pc', '\\\\', 'in', \"'\\\\\", 'z', '$', 'every', 'to', ',', 'purpose', 'this', 'for', '.', 'manner', 'covariant', 'gauge', 'a', 'in', '$', 'pc', '$\\\\', 'over', '$', 'e', '$', 'smear', 'to', 'wish', 'we', '$', 'c', '$', 'of', 'face', 'a', ')', 'of', 'interior', 'the', '(', 'to', 'belongs', 'which', '$', 'pc', '\\\\', 'in', '\\\\', 'z', '$', 'point', 'every', 'for', '$.', 'c', '\\\\', 'in', '\\\\', 'c', '$', 'cell', 'the', 'of', 'boundary', 'topological', 'the', 'of', 'part', 'differential', 'the', 'mean', 'will', 'we', '$', 'pc', '$\\\\', 'by', '.', 'cells', 'cubic', 'into', '$', 'r', '$', 'of', 'partition', 'the', 'be', '$', 'c', '$\\\\', 'let', 'and', 'system', 'coordinate', 'global', 'a', 'with', '$', 'r', '$', 'cover', 'then', 'us', 'let', ',', 'section', 'in', 'as', '.', 'exist', 'does', 'chart', 'global', 'a', 'which', 'on', 'region', 'trivial', 'topologically', 'a', 'to', 'attention', 'our', 'restrict', 'therefore', 'can', 'we', '.', 'apply', 'to', 'continue', 'will', 'section', 'of', 'beginning', 'the', 'in', 'presented', 'argument', 'the', ',', 'however', '.', 'chart', 'single', 'a', 'with', '$', 'r', '$', 'cover', 'to', 'able', 'be', 'not', 'may', 'one', ',', 'general', 'in', '.', 'before', 'as', '$', 's', '$\\\\', 'of', 'subset', 'open', 'an', 'be', '$', 'r', '$', 'let', '.', 'representation', 'connection', 'the', ',', 'however', ',', 'using', 'smolin', 'and', 'rovelli', 'of', 'strategy', 'overall', 'the', 'outline', 'will', 'section', '-', 'sub', 'this', 'in', '.', 'scheme', 'regularization', \"'\", 'internal', '`', 'the', 'in', 'do', 'section', 'of', 'restrictions', 'the', 'that', \"'\", 'extent', 'same', '`', 'the', 'to', 'partitions', 'permissible', 'the', 'specialize', 'restrictions', 'these', ',', 'speaking', 'roughly', '.', 'pietri', 'de', 'by', 'given', 'prescription', 'a', 'following', ',', 'manner', 'specific', 'a', 'in', 'paths', 'choose', 'to', 'has', 'one', ',', 'defined', '-', 'well', 'is', 'operator', 'limiting', 'the', 'that', 'ensure', 'to', ',', 'partitions', 'restricted', 'such', 'for', 'even', ',', 'furthermore', '$.', '0', 'goesto', '\\\\', 'e', '$\\\\', 'limit', 'the', 'in', 'diverge', 'may', 'cells', 'some', 'from', 'contributions', ',', 'section', 'of', 'that', 'to', 'similar', 'manner', 'a', 'in', 'restricted', 'is', 'partition', 'the', 'unless', ';', 'cells', 'these', 'of', 'size', 'the', 'shrink', 'just', 'not', 'can', 'one', 'theory', 'quantum', 'the', 'in', 'regulator', 'the', 'remove', 'to', 'that', 'however', 'see', 'will', 'we', '.', 'cubes', 'coordinate', 'the', 'by', 'given', 'being', 'cells', 'the', ',', 'integers', 'the', 'ranges', '$', 'n', '$', 'and', '$', '3', ',', '2', ',', '1', '=', 'a', '$', 'where', '$,', 'epsilon', '\\\\', 'n', '=', '\\\\', 'a', '^', 'x', '$', 'surfaces', '-', 'two', 'of', 'family', 'a', 'introducing', 'and', '$', 'r', '$', 'covering', '$', 'a', '^', 'x', '$', 'coordinates', 'fixing', 'by', 'obtained', ',', 'partition', 'smolin', '-', 'rovelli', 'the', 'be', 'may', '$', 'c', '$\\\\', ',', 'particular', 'in', '.', 'cells', 'into', '$', 'r', '$', 'of', '$', 'c', '$\\\\', 'partition', 'arbitrary', 'an', 'choose', 'us', 'let', '.', 'point', 'fixed', 'a', 'to', '$', 'e', '$', 'triads', 'the', 'transport', 'parallel', 'to', 'paths', 'extra', '$', 'c', '$', 'cell', 'each', 'to', 'associates', 'but', 'and', 'cells', 'to', 'in', '$', 'r', '$', 'region', 'open', 'the', 'of', '$', 'c', '$\\\\', 'partition', 'a', 'with', 'begins', 'one', ',', 'before', 'as', '.', 'constraint', 'hamiltonian', 'the', 'in', 'constant', 'cosmological', 'the', 'incorporate', 'to', 'wishes', 'one', ',', 'example', 'for', ',', 'if', 'essential', 'quite', 'but', 'pleasing', 'aesthetically', 'this', 'is', 'only', 'not', '.', 'constraint', 'hamiltonian', 'the', 'as', 'well', 'as', 'operator', 'volume', 'the', 'to', 'applicable', \"'\", 'uniformly', '`', 'is', 'which', 'procedure', 'general', 'a', 'provides', 'regularization', 'our', ',', 'of', 'that', 'to', 'equivalent', 'is', 'answer', 'final', 'our', 'while', ',', 'thus', '().', 'by', 'defined', 'action', 'the', 'with', 'coincides', 'space', 'dual', 'the', 'on', 'operator', 'this', 'of', 'action', 'dual', 'the', '$.', 'h', '$\\\\', 'on', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'defined', 'densely', 'a', 'obtain', 'and', 'topology', 'space', 'hilbert', 'the', 'using', 'regulator', 'the', 'remove', 'will', 'we', ',', 'text', 'main', 'the', 'in', 'as', ',', 'treatment', 'our', 'in', ').', '13', 'footnote', 'see', '(', 'in', 'given', 'that', 'from', 'different', 'be', 'would', 'result', 'final', 'the', '(),', 'to', 'corresponding', 'topology', 'the', 'using', 'limits', 'final', 'the', 'take', 'we', ',', 'in', 'proposed', 'one', 'the', 'in', 'or', ',', 'in', 'presented', 'derivation', 'the', 'in', 'if', ',', 'indeed', '.)', 'topology', 'that', 'of', 'discussion', 'the', 'for', 'see', '(', '().', 'to', 'inequivalent', 'is', 'in', 'implicitly', 'used', 'topology', 'the', 'that', 'appears', 'it', ',', 'consideration', 'under', 'now', 'operator', 'volume', 'the', 'of', 'case', 'the', 'in', '}|$.', 'o', 'cal', '{\\\\', 'hat', '\\\\', 's', 'bra', '$\\\\', 'of', 'domain', 'the', 'in', '$', 'h', '\\\\', 'in', '\\\\', 'psi', '$\\\\', 'every', 'for', 'ee', '\\\\', 'ket', '\\\\', 'psi', '\\\\', 'epsilon', '}^\\\\', 'o', 'cal', '{\\\\', 'hat', '\\\\', '|', 's', 'bra', '\\\\', '}\\\\,', '0', 'rightarrow', '\\\\', 'epsilon', '{\\\\', 'lim_', '\\\\', '\\\\', ':=', 'ket', '\\\\', 'psi', '\\\\', '|', 's', '}', 'o', 'cal', '{\\\\', 'hat', '\\\\', 'bra', '\\\\', '}', 'top', '{', 'label', '\\\\', 'be', '\\\\', 'formula', 'following', 'the', 'by', '|$', 's', 'bra', '$\\\\', 'on', '|$', 's', '}', 'o', 'cal', '{\\\\', 'hat', '\\\\', 'bra', '$\\\\', 'action', 'its', 'via', 'defined', 'is', '$', '0', 'rightarrow', '\\\\', 'epsilon', '$\\\\', 'as', '}$', 'o', 'cal', '{\\\\', 'hat', '$\\\\', 'limit', 'the', 'then', ',', 'state', 'dual', 'a', '|$', 's', 'bra', '$\\\\', 'and', ')', 'regulator', 'the', 'symbolizes', '$', 'epsilon', '$\\\\', 'where', '(', '$', 'h', '$\\\\', 'on', 'operator', 'regulated', 'the', 'denotes', '$', 'epsilon', '}^\\\\', 'o', 'cal', '{\\\\', 'hat', '$\\\\', 'if', '.', 'follows', 'as', 'defined', 'is', 'regulator', 'the', 'removing', 'while', 'limit', 'the', 'take', 'to', 'uses', 'one', 'topology', 'the', '.', 'thereof', 'extension', 'appropriate', 'an', 'or', ',', '$', 'h', '$\\\\', 'space', 'hilbert', 'the', 'to', 'dual', 'algebraic', 'the', 'of', 'subspace', 'invariant', 'diffeomorphism', 'the', 'is', 'operator', 'constraint', 'this', 'of', 'domain', 'the', 'that', 'first', 'recall', '.', 'detail', 'some', 'in', 'point', 'this', 'discuss', 'us', 'let', '.', 'literature', 'the', 'in', 'constraint', 'hamiltonian', 'the', 'of', 'treatment', 'the', 'with', 'consistent', 'is', 'regularization', \"'\", 'external', '`', 'our', ',', 'text', 'main', 'the', 'in', 'discussed', 'regularization', \"'\", 'internal', '`', 'the', 'for', 'case', 'the', 'is', 'as', ',', 'finally', '.', 'in', 'overlooked', 'were', ',', 'below', 'and', 'subsections', 'in', 'discussed', ',', 'subtleties', 'these', '.', 'suitably', 'restricted', 'are', 'partitions', 'permissible', 'the', 'unless', 'exist', 'even', 'not', 'may', 'or', 'used', 'system', 'coordinate', 'the', 'of', 'memory', 'a', 'carry', 'can', 'operator', 'limiting', 'the', 'and', 'regularization', \"'\", 'external', '`', 'this', 'in', 'also', 'procedure', 'subtle', 'a', 'is', 'regulators', 'of', 'removal', 'the', ',', 'section', 'in', 'as', ',', 'second', '.', 'representation', '---', 'loop', 'than', 'rather', '---', 'connection', 'the', 'in', 'work', 'we', ',', 'first', '.', 'ways', 'some', 'in', 'theirs', 'from', 'differs', 'treatment', 'our', ',', 'however', '.', 'smolin', 'and', 'rovelli', 'to', 'due', 'are', 'regularization', 'this', 'behind', 'ideas', 'key', '.', 'scheme', 'regularization', \"'\", 'external', '`', 'an', 'from', 'results', 'which', ')', 'in', 'reported', '(', 'operator', 'volume', 'the', 'of', 'formula', 'analytic', 'the', 'of', 'derivation', 'detailed', 'a', 'provide', 'will', 'we', ',', 'appendix', 'this', 'in', 'bigskip', '\\\\', 'regularization', \"'\", 'extrinsic', '`', 'or', \"'\", 'external', '`', ':', 'appendix', 'centerline', '\\\\', '}', 'sec7', '{', 'label', '\\\\', 'appendix', '\\\\', 'bigskip', '\\\\', 'bigskip', '\\\\', '.', 'cooperation', 'german', '-', 'polish', 'for', 'foundation', 'the', 'and', ')', '12', '017', 'p03b', '2', '.', 'no', 'grant', ',', 'kbn', '(', 'research', 'scientific', 'on', 'committee', 'polish', 'the', '),', 'avh', '(', 'stiftung', '-', 'humboldt', 'von', 'alexander', 'the', 'by', 'part', 'in', 'supported', 'was', ')', 'jl', '(', 'other', 'the', '.', 'state', 'pen', 'of', 'funds', 'research', 'eberly', 'the', 'by', 'and', '14240', '-', 'phy95', 'grant', 'nsf', 'the', 'by', 'part', 'in', 'supported', 'was', ')', 'aa', '(', 'us', 'of', 'one', '.', 'convergent', 'regularization', \"'\", 'external', '`', 'the', 'makes', 'which', 'assignment', 'loop', 'the', 'us', 'to', 'showing', 'for', 'and', ',', 'operator', 'volume', 'the', 'about', 'discussions', 'numerous', 'for', 'pietri', 'de', 'roberto', 'thank', 'we', '.', 'acknowledgements', 'bigskip', '\\\\', '$.', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'corresponding', 'the', 'in', 'difference', 'subtle', 'a', 'is', 'there', ',', 'theory', 'quantum', 'the', 'in', '.', 'removed', 'are', 'regulators', 'the', 'when', '$', 'v_r', '$', 'function', 'same', 'the', 'to', 'lead', 'both', 'they', ',', 'theory', 'classical', 'the', 'in', '.', 'expressions', 'classical', \"'\", 'regulated', '`', 'the', 'of', 'choice', 'the', 'in', 'lies', 'difference', 'the', '.', 'theory', 'quantum', 'to', 'over', 'expressions', 'classical', \"'\", 'regulated', '`', 'these', 'takes', 'and', 'triads', 'smeared', 'dimensionally', '-', 'two', 'of', 'terms', 'in', '$', 'v_r', '$', 'function', 'volume', 'classical', 'the', 'expressing', '-', 're', 'by', 'begins', 'one', ',', 'approaches', 'both', 'in', '.', 'ambiguities', 'quantization', 'of', 'only', 'reflection', 'a', 'is', 'operators', 'distinct', 'two', 'of', 'existence', 'the', 'that', 'emphasize', 'to', 'wish', 'we', ',', 'conclude', 'to', '.', 'constant', 'overall', 'an', 'by', 'differ', 'can', 'operators', 'volume', 'quantum', 'corresponding', 'the', ',', 'cells', 'elementary', 'of', 'geometry', 'the', 'of', 'details', 'the', 'to', 'insensitive', 'is', 'expression', 'regulated', ',', 'classical', 'the', 'of', 'limit', 'the', 'while', ',', 'approach', \"'\", 'external', '`', 'the', 'in', ',', 'similarly', '.', 'constant', 'overall', 'an', 'to', 'up', 'only', 'unique', 'is', 'operator', 'quantum', 'the', 'of', 'limit', 'the', ',', 'averaging', 'the', 'in', 'used', 'measure', 'the', 'of', 'choice', 'the', 'to', 'insensitive', 'is', 'expression', 'averaged', ',', 'classical', 'the', 'of', 'limit', 'the', 'while', ',', 'because', 'arose', 'ambiguity', '$-', 'k_o', '$\\\\', 'the', ',', 'there', '.', 'text', 'main', 'the', 'of', 'approach', \"'\", 'internal', '`', 'the', 'in', 'that', 'to', 'parallel', 'is', 'situation', 'the', ',', 'indeed', '.', 'change', 'would', 'operator', 'volume', 'that', 'of', 'front', 'in', 'constant', 'overall', 'the', ',', 'example', 'for', ',', 'cells', 'tetrahedral', 'to', 'changes', 'one', 'if', '.', 'cells', \"'\", 'rectangular', '`', 'of', 'choice', 's', \"'\", 'one', 'in', 'the', 'in', 'buried', 'is', 'it', ',', 'there', '.', 'regularization', \"'\", 'external', '`', 'the', 'in', 'also', 'exists', 'constant', 'overall', 'an', 'of', 'ambiguity', 'the', ',', 'stated', 'explicitly', 'not', 'often', 'is', 'it', 'although', ',', 'finally', ').', 'constant', 'a', 'from', 'apart', '(', 'coincide', 'operators', 'two', 'the', ',', 'treatments', 'simplicial', 'in', 'considered', 'those', 'as', 'such', 'situations', 'simple', 'in', ',', 'however', '.', 'section', 'in', 'out', 'spelled', 'sense', 'the', 'in', '$', 's', '$\\\\', 'on', 'homeomorphisms', 'also', 'but', 'diffeomorphisms', 'under', 'only', 'not', 'covariantly', 'transform', 'they', 'hence', '.', 'vertices', 'at', 'edges', 'the', 'to', 'vectors', 'tangent', 'the', 'of', 'details', 'the', 'about', 'information', 'any', 'have', 'not', 'do', 'operators', '---', 'final', 'the', 'also', 'hence', 'and', '---', 'regulated', 'these', ',', 'regularization', \"'\", 'external', '`', 'the', 'of', 'because', '.', 'paper', 'the', 'of', 'body', 'main', 'the', 'in', 'presented', 'that', 'from', 'differ', 'does', 'result', 'final', 'the', '.', 'section', 'in', 'introduced', 'those', 'to', 'analogous', 'completely', 'are', 'exists', 'limit', 'defined', '-', 'well', 'a', 'that', 'ensure', 'to', 'needed', 'assumptions', 'the', ';', 'case', 'the', 'not', 'is', 'this', 'that', 'shows', 'limit', 'the', 'of', 'treatment', 'careful', 'a', ',', 'however', '.', 'theory', 'quantum', 'the', 'in', 'limit', 'continuum', 'the', 'taking', 'while', 'section', 'in', 'encountered', 'we', 'subtleties', 'the', 'of', 'free', 'is', 'regularization', 'this', 'that', 'believed', 'was', 'it', ',', 'discussions', 'early', 'the', 'in', '.', 'cell', 'the', 'of', 'boundary', 'the', 'on', 'smeared', 'triads', 'of', 'terms', 'in', 'cell', 'elementary', 'an', 'of', 'volume', 'the', 'of', 'expression', 'an', 'is', 'point', 'starting', 'the', 'because', 'regularization', \"'\", 'external', '`', 'an', 'called', 'be', 'may', 'this', '.', 'representation', 'loop', 'the', 'in', 'pietri', 'de', 'and', 'smolin', ',', 'rovelli', 'by', 'given', 'constructions', 'on', 'based', ',', 'scheme', 'regularization', 'another', 'discusses', 'appendix', 'the', '.', 'situation', 'the', 'worsen', 'not', 'does', '$', 'k_o', '$\\\\', 'of', 'choice', 'the', 'in', 'freedom', 'the', ',', 'viewpoint', \"'\", 'practical', '`', 'a', 'from', ',', 'therefore', '.', 'input', 'additional', 'without', 'eliminated', 'be', 'not', 'can', 'which', 'spectrum', 'the', 'in', 'constant', 'multiplicative', 'a', 'of', 'ambiguity', 'an', 'is', 'there', 'that', 'is', 'effect', 'net', 'the', ',', 'operators', 'volume', 'for', '.', 'operators', 'triad', '-', 'holonomy', 'the', 'of', 'representations', 'inequivalent', 'unitarily', 'of', 'family', 'parameter', 'one', 'a', 'to', 'leads', 'and', 'implementable', 'unitarily', 'be', 'to', 'fails', 'which', 'transformation', 'canonical', 'a', 'of', 'existence', 'the', 'from', 'arises', 'this', '.', 'barbero', 'of', 'work', 'earlier', 'using', 'immirzi', 'by', 'out', 'pointed', 'first', ',', 'level', 'kinematical', 'the', 'at', 'ambiguity', 'another', 'is', 'there', 'that', 'section', 'from', 'however', 'recall', '.', 'feature', 'undesirable', 'an', 'be', 'to', 'appears', '$', 'k_o', '$\\\\', 'constant', 'multiplicative', 'a', 'of', 'ambiguity', 'the', ',', 'sight', 'first', 'at', 'least', 'at', ',', 'next', '.', 'covariance', 'diffeomorphism', 'enjoy', 'does', 'result', 'final', 'our', 'since', 'issue', 'aesthetic', 'an', 'largely', 'is', 'this', ',', 'however', '.', 'covariant', 'diffeomorphism', 'manifestly', 'procedure', 'regularization', 'the', 'make', 'to', 'difficult', 'more', 'be', 'would', 'it', '.', 'invariant', 'gauge', 'already', 'is', 'which', 'result', 'the', 'affect', 'not', 'does', 'step', 'additional', 'this', '.', 'point', 'fixed', 'at', 'ending', 'paths', 'fixed', 'some', 'along', 'transport', 'parallel', 'the', 'with', 'combined', 'integration', 'with', 'surface', '-', 'two', 'a', 'over', '()', 'in', '$', 'e', '$', 'of', 'integration', 'simple', 'the', 'replace', 'to', 'suffices', 'it', ':', 'result', 'final', 'the', 'or', 'arguments', 'our', 'affecting', 'without', 'situation', 'this', 'rectify', 'can', 'change', 'cosmetic', 'a', ',', 'however', '.', 'invariant', 'gauge', 'not', 'are', ')', '(,', 'expressions', 'regulated', 'the', ',', 'first', '.', 'respects', 'some', 'in', 'improved', 'be', ',', 'however', ',', 'could', 'procedure', 'regularization', 'the', '$.', 'h', '$\\\\', 'on', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'adjoint', '-', 'self', 'a', 'defines', 'therefore', 'and', 'consistent', 'be', 'to', 'out', 'turned', 'family', 'our', '.};', 'theories', 'field', 'quantum', 'minkowskian', 'in', 'operators', 'order', 'normal', 'to', 'structure', 'space', 'fock', 'the', 'use', 'to', 'is', 'it', 'as', '$', 'g', '\\\\', 'h_', '$\\\\', 'on', 'operator', 'an', 'regulate', 'to', '$', 'g', '$\\\\', 'use', 'to', 'natural', 'as', 'is', 'it', ':', 'situation', 'the', 'clarifies', '$', 'g', '^\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'of', 'family', 'consistent', 'a', 'as', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'regarding', \"'.\", 'dependent', '-', 'state', '`', 'be', 'to', 'seemed', 'procedure', 'regularization', 'the', 'because', 'concern', 'some', 'was', 'there', ',', 'stages', 'initial', 'the', 'in', '{', 'footnote', '\\\\', '%', 'happen', 'not', 'did', 'this', '.', 'consistent', 'be', 'to', 'failed', 'have', 'could', 'regulated', 'so', '$', 'g', '^\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'the', ':', 'requirement', 'consistency', 'from', 'comes', 'procedure', 'the', 'of', 'test', 'key', 'the', '$.', 'g', '$\\\\', 'graph', 'the', 'to', 'refer', 'could', 'we', ',', 'therefore', ',', 'procedure', 'regularization', 'the', 'in', '$.', 'g', '\\\\', 'h_', '$\\\\', 'to', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'desired', 'the', 'of', '$', 'g', '^\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'restrictions', 'the', 'on', 'focus', 'could', 'we', ',', 'particular', 'in', ',', 'case', 'present', 'the', 'in', '..', '$', 'g', '$\\\\', 'graphs', 'with', 'associated', '$', 'g', '\\\\', 'h_', '$\\\\', 'spaces', 'hilbert', 'partial', 'on', 'operators', 'of', 'family', 'consistent', 'a', 'as', 'considered', 'naturally', 'be', 'can', '$', 'h', '$\\\\', 'space', 'hilbert', 'kinematical', 'the', 'on', 'operators', ')', 'of', 'class', 'large', 'a', '(', 'because', 'occurs', 'simplification', 'key', 'a', ',', 'case', 'our', 'in', '.', 'there', 'encountered', 'those', 'as', 'nature', 'same', 'the', 'of', 'are', 'limit', 'continuum', 'the', 'in', 'involved', 'subtleties', 'the', 'and', 'theories', 'field', 'quantum', 'other', 'in', 'used', 'that', 'as', 'same', 'the', 'is', 'here', 'philosophy', 'overall', 'the', '.', 'procedure', 'regularization', 'the', 'of', 'intricacies', 'the', 'discuss', 'which', 'and', 'sections', 'in', 'contained', 'is', 'paper', 'the', 'of', 'part', 'central', 'the', '.', 'discrete', 'purely', 'is', 'spectrum', 'its', '.', 'diffeomorphisms', '$-', 's', '$\\\\', 'of', 'action', 'the', 'under', 'covariantly', 'transforms', 'and', 'operator', 'adjoint', '-', 'self', ',', 'positive', ',', 'defined', 'densely', 'a', 'is', 'it', '$.', 'k_o', '$\\\\', 'constant', ')', 'independent', '$-', 'r', '($', 'overall', 'an', 'to', 'up', 'defined', 'uniquely', 'is', '}$', 'v_r', '{', 'hat', '$\\\\', 'operator', 'resulting', 'the', '.', 'regulators', 'the', 'removed', 'then', 'and', 'structures', 'background', \"'\", 'relevant', '`', 'the', 'over', 'expressions', 'regulated', 'the', 'averaged', 'first', 'we', ',', 'situation', 'this', 'rectify', 'to', '$.', 's', '$\\\\', 'of', 'diffeomorphisms', 'under', 'covariantly', 'transform', 'to', 'fails', 'and', 'procedure', 'regularization', 'the', 'in', 'used', 'structures', 'background', 'the', 'of', 'memory', 'a', 'carries', 'operator', 'resulting', 'the', 'the', 'that', 'out', 'turned', 'it', ',', 'however', '.', 'regulators', 'the', 'remove', 'and', 'theory', 'quantum', 'the', 'to', 'expression', 'classical', 'the', 'over', 'carry', 'to', 'straightforward', 'relatively', 'was', 'it', '.', 'cell', 'the', 'of', 'interior', 'the', 'through', 'passing', 'surfaces', '-', 'two', 'three', 'over', 'smeared', 'triads', 'of', 'terms', 'in', 'expressed', 'is', 'cell', 'elementary', 'an', 'of', 'volume', 'the', 'which', 'in', 'regularization', \"'\", 'internal', '`', 'an', 'chose', 'we', 'and', 'step', 'first', 'the', 'in', 'freedom', 'considerable', 'is', 'there', '.', 'regulators', 'the', 'remove', 'finally', 'and', 'theory', 'quantum', 'to', 'expression', 'classical', \"'\", 'regulated', '`', 'this', 'promote', 'then', ',', 'analogs', 'quantum', 'unambiguous', 'have', 'which', ')', 'triads', 'smeared', 'dimensionally', '-', 'two', ',', 'case', 'our', 'in', '(', 'variables', \"'\", 'elementary', '`', 'of', 'terms', 'in', ')', 'space', 'phase', 'classical', 'the', 'on', '$', 'v_r', '$', 'functions', ',', 'case', 'our', 'in', '(', 'interest', 'of', 'observable', 'classical', 'the', 'express', 'first', 'to', 'is', 'idea', 'the', \"',\", 'quantization', '`', 'any', 'in', 'as', '.', 'operators', 'these', 'of', 'properties', 'few', 'a', 'discussed', 'and', '$', 's', '$\\\\', 'manifolds', '-', '3', \"'\", 'spatial', '`', 'the', 'of', '$', 'r', '$', 'regions', 'open', 'with', 'associated', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'volume', 'obtain', 'to', 'scheme', 'regularization', 'a', 'presented', 'we', 'paper', 'the', 'of', 'body', 'main', 'the', 'in', '.', 'integers', 'are', '|$', 'j_4', '-', 'j_3', '|', '-', 'j', '$', 'and', '|$', 'j_2', '-', 'j_1', '-|', 'j', '$', 'both', 'that', 'such', 'and', 'ee', '\\\\', '|,', 'j_4', '+', 'j_3', '|', 'le', '\\\\', 'j', 'le', '\\\\', '|\\\\', 'j_4', '-', 'j_3', '|', '\\\\', '|,', 'j_2', '+', 'j_1', '|', 'le', '\\\\', 'j', 'le', '\\\\', '|\\\\', 'j_2', '-', 'j_1', '|', 'be', '\\\\', ':', 'simultaneously', 'satisfies', 'which', 'of', 'each', '$', 'j', '$', 'numbers', 'different', 'of', 'number', 'the', 'by', 'given', 'is', '}$', 'm', ',,', 'j_4', ',...,', 'x0j_1', '{', '_', '}', 't', 'cal', '${\\\\', 'subspace', 'invariant', 'corresponding', 'the', 'of', 'dimension', 'the', ',', 'finally', 'ee', '\\\\', '.', '2', ',\\\\,', '0', ',\\\\,', '3', ',\\\\,', '1', '-', ',\\\\,', '4', ',\\\\,', '2', '-', '=\\\\', ')\\\\', 'e_4', ',', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'k', '\\\\', 'be', '\\\\', 'are', ')$', 'e_4', ',', 'e_3', ',', 'e_2', ',', 'e_1', '(\\\\', 'k', '$\\\\', 'of', 'values', 'corresponding', 'the', 'ee', '\\\\', '.', 'de_3', '-\\\\', ',\\\\,', 'de_3', '\\\\', '),\\\\,', '0', ',', '1', ',-', '1', '(-', '),\\\\,', '0', ',', '1', ',', '1', '),\\\\,(', '1', ',-', '1', ',-', '1', '(-', '),\\\\,', '1', ',', '1', ',', '1', '(', '=', 'de_4', '\\\\', 'be', '\\\\', '$:', 'de_4', '$\\\\', 'of', 'values', 'possible', 'following', 'the', 'by', 'given', 'cases', 'the', 'of', 'one', 'to', 'diffeomorphic', 'is', ')', 'renumbering', 'modulo', '(', 'case', 'every', ',', 'that', 'see', 'can', 'one', '$.', 'de_4', '$\\\\', 'by', 'determined', 'is', 'character', 'intersection', 'the', ',', 'then', 'ee', '\\\\', ').', '1', ',', '0', ',', '0', '=(', 'de_3', '\\\\', '),\\\\,', '0', ',', '1', ',', '0', '=(', 'de_2', '\\\\,\\\\', '),', '0', ',', '0', ',', '1', '=(', 'de_1', '\\\\', 'be', '\\\\', ',', 'renumbering', 'possible', 'a', 'after', 'that', 'such', ',', 'coordinates', 'find', 'always', 'can', 'we', ',', 'otherwise', '.', 'zero', 'identically', 'is', '$', 'q_x', '$\\\\', 'then', '),', 'plane', '-', 'two', 'a', 'to', 'tangent', 'are', 'edges', 'four', 'the', ',', 'is', 'that', '(', 'planar', 'is', 'intersection', 'the', 'if', '$.', 'x', '$', 'at', 'edges', 'the', 'by', 'defined', 'vectors', 'the', 'of', '$', '4', ',...', '1', '=', 'i', '$', '$,', 'de_i', '$\\\\', 'directions', 'oriented', 'the', 'on', 'only', 'depends', 'it', 'that', 'section', 'from', 'recall', '$.', 'x', '$', 'at', 'edges', 'ordered', 'the', 'between', 'intersection', 'the', 'of', 'characteristics', 'the', 'on', 'depends', '$', 'k', '$\\\\', 'factor', 'invariant', 'diffeomorphism', 'the', 'of', 'value', 'the', '.)', 'subspace', 'this', 'on', 'vanishes', '$', 'q_x', '$\\\\', 'that', 'implies', '()', 'then', '}$.', 'e_2', ',', 'x', '{', 'i_', '^', 'j', '-', '}', 'e_1', ',', 'x', '{', 'i_', '^', 'j', '-', '=', '}', 'e_3', ',', 'x', '{', 'i_', '^', 'j', '$', 'as', '}$', 'e_3', ',', 'x', '{', 'i_', '^', 'j', '$', 'express', 'further', 'can', 'one', ',', 'case', 'invariant', 'gauge', 'valent', '-', 'three', 'a', 'in', '(', '$.}', '4', ')=', 'e_4', ',', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'k', '$\\\\', 'with', '()', 'of', '|$', 'q_x', '$|\\\\', 'with', 'coincides', '()', 'operator', '$', 'q_x', '$\\\\', 'our', 'of', '()', 'counterpart', 'smolin', '-', 'rovelli', 'the', ',', 'case', 'valent', '-', '4', 'a', 'in', ',', 'that', 'arguments', 'same', 'the', 'from', 'follows', 'it', '{', 'footnote', '\\\\', '$.', 'e_3', '$', 'and', '$', 'e_2', '$', '$,', 'e_1', '$', 'edges', 'the', 'between', 'vertex', ',', 'invariant', 'gauge', '-', 'non', 'but', ',', 'valent', '-', 'three', 'a', 'at', 'that', 'as', 'same', 'the', 'is', 'action', 'the', ')$,', 'e_4', ',', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'k', '$\\\\', 'factor', 'geometric', 'the', 'modulo', ',', 'thus', 'ea', '\\\\', ').', 'e_3', ',', 'e_2', ',', 'e_4', '(', 'e', '\\\\', '-\\\\', ')\\\\', 'e_3', ',', 'e_4', ',', 'e_1', '(', 'e', '\\\\', '-\\\\', ')\\\\', 'e_4', ',', 'e_2', ',', 'e_1', '(', 'e', '\\\\', '-\\\\', ')\\\\', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'e', '\\\\', '\\\\', '&=&', ')\\\\', 'e_4', ',', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'k', '\\\\', '\\\\\\\\', 'nonumber', '\\\\', ',}', 'where', 'rm', '{\\\\', '},\\\\,\\\\,', 'e_3', ',', 'x', '{', 'k_', '^', 'j', '}', 'e_2', ',', 'x', '{', 'j_', '^', 'j', '}', 'e_1', ',', 'x', '{', 'i_', '^', 'j', '}', 'ijk', '{', 'e_', '\\\\', ')\\\\,', 'e_4', ',', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'k', '\\\\', '}\\\\,', '8', '}{', 'k_o', '{\\\\', 'frac', '\\\\', '&=&\\\\', '\\\\', 'q_x', '\\\\', '}', '4valent', '{', 'label', '\\\\', 'ba', '\\\\', 'find', 'we', 'ee', '\\\\', '0', '=\\\\', '})\\\\', 'e_2', ',', 'x', '{', 'k_', '^', 'j', '+\\\\', '}\\\\', 'e_1', ',', 'x', '{', 'k_', '^', 'j', '}(', 'e_2', ',', 'x', '{', 'j_', '^', 'j', '}', 'e_1', ',', 'x', '{', 'i_', '^', 'j', '}\\\\,', 'ijk', '{', 'e_', '\\\\', '}', 'id', '{', 'label', '\\\\', 'be', '\\\\', 'that', 'observation', 'the', 'and', 'constraint', 'gauss', 'the', 'using', 'ea', '\\\\', ').', 'big', '}\\\\', 'e_4', ',', 'x', '{', 'k_', '^', 'j', '}', 'e_2', ',', 'x', '{', 'j_', '^', 'j', '}', 'e_1', ',', 'x', '{', 'i_', '^', 'j', ')', 'e_4', ',', 'e_2', ',', 'e_1', '(', 'e', '\\\\', '+\\\\,', '}\\\\,', 'e_3', ',', 'x', '{', 'k_', '^', 'j', '}', 'e_4', ',', 'x', '{', 'j_', '^', 'j', '}', 'e_1', ',', 'x', '{', 'i_', '^', 'j', ')', 'e_3', ',', 'e_4', ',', 'e_1', '(', 'e', '\\\\', '&+&', '\\\\\\\\', 'nonumber', '\\\\', '}', 'e_3', ',', 'x', '{', 'k_', '^', 'j', '}', 'e_2', ',', 'x', '{', 'j_', '^', 'j', '}', 'e_4', ',', 'x', '{', 'i_', '^', 'j', ')', 'e_3', ',', 'e_2', ',', 'e_4', '(', 'e', '\\\\,\\\\', '+', '\\\\,', '}', 'e_3', ',', 'x', '{', 'k_', '^', 'j', '}', 'e_2', ',', 'x', '{', 'j_', '^', 'j', '}', 'e_1', ',', 'x', '{', 'i_', '^', 'j', ')', 'e_3', ',', 'e_2', ',', 'e_1', '(', 'e', '(\\\\', 'big', '\\\\', '}\\\\,', 'ijk', '{', 'e_', '}\\\\,\\\\', '8', 'over', '\\\\', 'k_o', '{\\\\', '\\\\', '&=&', 'q_x', '\\\\', 'ba', '\\\\', 'have', 'we', ',', 'then', '.', 's', '$', 'j', '$', 'remaining', 'the', 'of', 'favor', 'in', '}$', 'e_4', ',', 'x', '{', 'i_', '^', 'j', '$', 'eliminate', 'to', 'equation', 'this', 'use', 'we', 'ee', '\\\\', '.', '0', '=\\\\', '}\\\\', 'e_4', ',', 'x', '{', 'i_', '^', 'j', '+\\\\', '}\\\\', 'e_3', ',', 'x', '{', 'i_', '^', 'j', '+\\\\', '}\\\\', 'e_2', ',', 'x', '{', 'i_', '^', 'j', '+\\\\', '}\\\\', 'e_1', ',', 'x', '{', 'i_', '^', 'j', 'be', '\\\\', ':', 'have', 'we', '$', 'x', '$', 'vertex', 'the', 'at', ',', 'thus', '.', 'subspace', 'this', 'on', 'identically', 'vanishes', 'constraint', 'gauss', 'that', 'statement', 'the', 'to', 'equivalent', 'is', 'subspace', 'this', 'in', 'states', 'of', 'invariance', 'gauge', '$.', 'x', '$', 'vertex', 'a', 'at', 'intersecting', 'edges', 'the', '$', '4', ',', '3', ',', '2', ',', '1', '=', 'i', '$', '$,', 'e_i', '$', 'by', 'denote', '$.', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '$\\\\', 'of', 'elements', 'invariant', 'gauge', 'of', 'subspace', 'corresponding', 'the', 'in', 'acting', '$', 'q_x', '$\\\\', 'consider', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'of', 'vertex', 'valent', 'four', 'a', 'is', '$', 'x', '$', 'suppose', '.', 'detail', 'some', 'in', 'case', 'this', 'discuss', 'therefore', 'us', 'let', ',', 'operators', 'these', 'of', 'action', 'the', 'for', 'feel', 'a', 'get', 'to', ',', 'therefore', '.', 'vertex', 'valent', '-', '4', 'invariant', 'gauge', 'a', 'of', 'that', 'is', 'case', 'trivial', '-', 'non', 'simplest', 'the', ',', 'concerned', 'are', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'and', '$', 'q_x', '$\\\\', 'operators', 'the', 'as', 'far', 'as', \"'\", 'trivial', '`', 'are', 'meet', 'edges', 'less', 'or', 'three', 'which', 'at', 'vertices', 'since', '.', 'is', 'eigenvalue', 'zero', '-', 'non', 'smallest', 'the', 'what', 'even', 'or', ',', 'line', 'real', 'the', 'on', \"'\", 'packed', 'are', 'eigenvalues', 'the', 'densely', '`', 'how', 'know', 'even', 'not', 'do', 'we', ',', 'indeed', ').', 'operators', 'area', 'with', 'situation', 'the', 'to', 'contrast', 'in', '(', 'explicitly', 'known', 'not', 'is', 'spectrum', 'complete', 'the', '.', 'elements', 'of', 'number', 'countable', 'a', 'has', 'it', 'sense', 'the', 'in', 'discrete', 'is', 'volume', 'the', 'of', 'spectrum', 'the', ',', 'finally', '.', 'lattice', 'cubic', 'a', 'in', 'contained', 'loops', 'the', 'by', 'given', 'functions', 'cylindrical', 'the', 'to', 'restricted', ',', 'operator', 'above', 'the', 'with', 'coincides', 'operator', 'lattice', 'the', ',', 'particular', 'in', '.', 'operators', 'these', 'all', 'between', 'relation', 'simple', 'a', 'is', 'there', 'cases', 'valent', ')', 'lower', 'or', '(', '4', 'the', 'in', ',', 'framework', 'lattice', 'the', 'within', 'derived', 'is', 'of', 'that', 'and', ',', 'ours', 'from', 'differs', 'in', 'studied', 'operator', 'volume', 'the', 'although', '.', 'in', 'studied', 'were', 'cases', 'special', 'other', 'and', 'eigenvectors', 'and', 'eigenvalues', 'the', 'of', 'examples', 'several', '.', 'operators', 'area', 'two', 'of', 'commutator', 'the', 'in', 'terms', \"'\", 'anomalous', 'apparently', '`', 'the', 'to', 'related', 'also', 'is', 'property', 'that', '.', 'case', 'valent', 'four', 'a', 'in', '$', 'q_x', '$\\\\', 'of', 'matrix', 'the', 'analyze', 'to', 'thiemann', 'by', 'used', 'and', 'observed', 'was', 'it', 'ee', '\\\\', '].', '2', '})^', 'e_j', '{', 'j_', '}+', 'e_i', '{', 'j_', '(', ',', '2', '})^', 'e_k', '{', 'j_', '}+', 'e_j', '{', 'j_', '[(', '}', '4i', 'over', '\\\\', '1', '{', '=\\\\', '}\\\\', 'ijk', '{', '_', '}', 'q', '{', 'hat', '\\\\', '\\\\', 'be', '\\\\', 'as', 'written', 'be', 'can', 'it', 'that', 'is', 'expression', 'that', 'of', 'property', 'intriguing', 'an', 'ee', '\\\\', '}.', 'ijk', '{', 'q_', '\\\\', '=:\\\\', '}\\\\', 'e_k', '{', 'k_', '^', 'j', '}', 'e_j', '{', 'j_', '^', 'j', '}', 'e_i', '{', 'i_', '^', 'j', '}', 'ijk', '{', 'e_', '\\\\', 'be', '\\\\', 'form', 'the', 'of', 'terms', 'of', 'consists', '$', 'q_x', '$\\\\', 'operator', 'the', '.', 'matrices', 'dimensional', 'finite', 'of', 'diagonalization', 'to', 'problem', 'eigen', 'the', 'reduces', 'still', 'which', 'dimensional', 'finite', 'is', '}$', 'm', ',', 'j_n', ',...,', 'j_1', ',', 'l', ',', 'x', '{', '_', '}', 't', 'cal', '${\\\\', ',', 'case', 'general', 'the', 'in', '.', 'networks', '-', 'spin', 'valent', 'three', 'on', 'acting', 'operator', 'hamiltonian', 's', \"'\", 'thiemann', 'for', 'formula', 'explicit', 'the', 'of', 'evaluation', 'the', 'in', 'emerges', '}$,', 'm', ',', 'j_3', ',', 'j_2', ',', 'j_1', '},', 'over2', '\\\\', '1', ',{', 'x', '{', '_', '}', 't', 'cal', '${\\\\', 'namely', ',', 'space', 'a', 'such', '.', 'therein', 'diagonal', 'automatically', 'is', 'volume', 'the', 'for', 'relevant', '|$', 'q_x', '$|\\\\', 'operator', 'value', 'absolute', 'the', 'then', ',', 'dimensional', '$-', '2', '$', 'be', 'to', 'happens', '}$', 'm', ',', 'j_n', ',...,', 'j_1', ',', 'l', ',', 'x', '{', '_', '}', 't', 'cal', '${\\\\', 'if', ').', 'three', 'to', 'equal', 'or', 'than', 'less', 'is', 'vertex', 'any', 'at', 'meeting', 'edges', 'of', 'number', 'the', 'if', '.,', 'e', '.', 'i', '(', 'valent', 'lower', 'or', 'three', 'are', '$', 'g', '$\\\\', 'of', 'vertices', 'all', 'if', '$', 'g', '\\\\', 'psi_', '$\\\\', 'functions', 'cylindrical', '$)', '0', '=', 'l', '($', 'invariant', 'gauge', 'all', 'annihilate', 'must', 'operator', 'volume', 'the', 'that', 'show', 'to', 'loll', 'by', 'used', 'was', 'and', '$', 'q_x', '$\\\\', 'of', 'kernel', 'the', 'find', 'to', 'argument', 'powerful', 'a', 'is', 'this', ',', 'practice', 'in', '.', 'zero', 'be', 'must', 'eigenvalue', 'corresponding', 'the', ',', 'furthermore', '$.', 'q_x', '$\\\\', 'of', 'direction', '-', 'eigen', 'an', 'necessarily', 'is', 'it', 'dimensional', '-', 'one', 'is', '}$', 'm', ',', 'j_n', ',...,', 'j_1', ',', 'l', ',', 'x', '{', '_', '}', 't', 'cal', '${\\\\', 'whenever', '.', 'operators', 'remaining', 'the', 'of', 'values', 'eigen', 'the', 'labeling', '$', 'm', '$', 'to', 'and', '$', 'x', '$', 'at', 'edges', 'the', 'labeling', '$', 'i', '$', '}}$,', 'i', '{', 'e_', ',', 'x', '{', 'i_', '^', 'j', '}}', 'i', '{', 'e_', ',', 'x', '{', 'i_', '^', 'j', '$', 'of', ')$', '1', '+', 'j_i', '(', 'j_i', '$', 'values', 'eigen', 'the', '$,', 'i_x', '}^', 'g', 'cal', '{\\\\', 'i_x', '}^', 'g', 'cal', '${\\\\', 'of', ')$', '1', '+', 'l', '(', 'l', '$', 'value', 'eigen', 'the', 'to', 'corresponding', 'subspace', 'the', '}$', 'm', ',', 'j_n', ',...,', 'j_1', ',', 'l', ',', 'x', '{', '_', '}', 't', 'cal', '${\\\\', 'by', 'denote', 'us', 'let', '.', 'operators', 'these', 'of', 'values', 'eigen', 'the', 'by', 'labelled', 'therefore', 'be', 'can', '$', 'q_x', '$\\\\', 'by', 'preserved', 'subspaces', '.', 'set', 'commuting', 'required', 'the', 'form', '$,', 'v', '$', 'each', 'for', '$', 'i_v', '$', 'fixed', 'and', '$', 'g', '$\\\\', 'of', '$', 'v', '$', 'vertex', 'every', 'for', '$', '_v', '}', 'i_v', '^{', 'g', '$\\\\', 'with', 'together', ',', 'operators', 'these', '$$', ',', '2', '}})^', 'i', '{', 'e_', ',', 'v', '{', 'j_', 'k', '}^', '1', '=', 'i', '{', 'sum_', '(\\\\', '=:\\\\', '}})\\\\', 'i', '{', 'e_', ',', 'v', '{', 'i_', '^', 'j', 'k', '}^', '1', '=', 'i', '{', 'sum_', '(\\\\', '}})\\\\,', 'i', '{', 'e_', ',', 'v', '{', 'i_', '^', 'j', 'k', '}^', '1', '=', 'i', '{', 'sum_', '(\\\\', '$$', 'operator', 'following', 'the', 'defines', '$', 'n', 'le', '\\\\', 'k', '$', 'every', 'for', 'and', '$,', 'e_n', ',...,', 'e_1', '$', 'are', 'say', ',', 'manner', 'arbitrary', 'an', 'in', '$', 'v', '$', 'at', 'edges', 'the', 'number', '$,', 'x', '=', 'not', '\\\\', 'v', '$', 'vertex', 'each', 'for', '.', 'operators', 'commuting', 'of', 'set', 'following', 'the', 'construct', 'can', 'one', ',', 'these', 'from', '{}', '$.', 'x', '$', 'at', 'edges', 'the', 'labels', 'sum', 'the', 'in', '$', 'i', '$', 'where', '},$$', 'e_i', ',', 'x', '{', 'i_', '^', 'j', 'n', '}^', '1', '=', 'i', '{', 'sum_', '\\\\', '=', 'i_x', '}^', 'g', 'cal', '$${\\\\', 'operator', 'constraint', 'gauss', 'the', 'with', 'as', 'well', 'as', '$', 'x', '=', 'not', '\\\\', 'v', '$', 'provided', '}$', 'e', ',', 'v', '{', 'i_', '^', 'j', '$', 'operators', 'the', 'of', 'each', 'with', 'commutes', '$', 'q_x', '$\\\\', '$,', 'x', '$', 'vertex', 'a', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'given', '.', 'coefficients', 'the', 'of', 'conjugation', 'complex', 'the', 'by', 'other', 'each', 'to', 'related', 'are', 'vectors', 'eigen', 'corresponding', 'the', 'and', '$', 'lambda', '$-\\\\', 'is', 'so', 'then', '$', 'q_x', '$\\\\', 'of', 'value', 'eigen', 'an', 'is', '$', 'lambda', '$\\\\', 'number', 'real', 'a', 'if', ',', 'therefore', '$.', 'q_x', '$\\\\', 'for', 'true', 'is', 'same', 'the', ',', 'operators', '$', 'i', '}^', 'e', ',', 'x', '{', 'j_', '$', 'commuting', 'the', 'of', 'products', 'the', 'from', 'constructed', 'is', '$', 'q_x', '$\\\\', 'since', '.)', 'functions', 'cylindrical', 'the', 'all', 'of', '$', 'cyl', '$\\\\', 'space', 'the', 'to', 'functions', 'cylindrical', 'invariant', 'gauge', 'of', 'space', 'the', 'from', 'networks', '-', 'spin', 'of', 'definition', 'the', 'of', 'extension', 'an', 'for', 'also', 'see', ';', 'basis', 'network', '-', 'spin', 'a', 'is', 'this', '(', '.', 'graphs', 'to', 'corresponding', 'blocks', 'dimensional', 'finite', 'of', 'matrix', 'diagonal', '-', 'block', 'and', 'real', ',', 'symmetric', '-', 'skew', 'a', 'times', '$', 'i', '$', 'form', 'the', 'of', 'is', '$', 'i', '}^', 'e', ',', 'x', '{', 'j_', '$', 'operators', 'the', 'of', 'each', 'that', 'such', 'basis', 'a', 'is', 'there', 'that', '()', 'relations', 'commutation', 'the', 'from', 'clear', 'also', 'is', 'it', '$).', 'r', '$', 'region', 'open', 'any', 'for', 'line', '-', 'half', 'negative', '-', 'non', 'entire', 'the', 'span', 'function', 'the', 'of', 'values', 'allowed', 'the', 'case', 'that', 'in', 'although', '(', '$', 'v_r', '$', 'function', 'volume', 'classical', 'the', 'by', 'shared', 'is', 'property', 'this', '$.', 'x', '$', 'of', 'neighborhood', 'small', 'arbitrarily', 'a', 'in', 'graph', 'a', 'of', 'characteristics', 'the', 'on', 'only', 'depend', '$', 'q_x', '$\\\\', 'of', 'values', 'eigen', 'the', 'that', 'fact', 'the', 'of', 'consequence', 'simple', 'a', 'is', '$', 'r', '$', 'open', 'an', 'of', 'independent', 'is', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'of', 'spectrum', 'that', 'fact', 'the', '.', 'countable', 'is', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'of', 'spectrum', 'full', 'the', 'that', 'shows', 'argument', 'same', 'the', '$.', 'g', '\\\\', 'h', '$\\\\', 'each', 'in', 'spectra', 'different', 'of', 'set', 'countable', 'the', 'of', 'union', 'countable', 'a', 'is', '$', 'q_x', '$\\\\', 'of', 'spectrum', 'full', 'the', ',', 'therefore', '.', 'countable', 'thus', 'is', 'characteristics', 'possible', 'of', 'set', 'the', '$.', 'x', '$', 'at', 'edges', 'the', 'by', 'defined', 'directions', 'tangent', 'oriented', 'of', 'triplets', 'the', 'of', 'orientations', 'relative', 'the', 'on', 'only', 'depends', '$', 'q_x', '$\\\\', 'of', 'spectrum', 'the', ',', 'however', '.', 'manner', 'continuous', 'a', 'in', 'change', 'might', 'spectra', 'the', 'that', 'possible', 'is', 'it', 'priori', 'a', '$,', 'g', '$\\\\', 'graph', 'the', 'vary', 'we', 'if', '$.', 'g', '\\\\', 'h_', '$\\\\', 'spaces', 'the', 'on', 'spectra', 'the', 'of', 'union', 'the', 'by', 'given', 'is', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'of', 'spectrum', 'full', 'the', 'hence', '$.', 'h', '$\\\\', 'in', 'dense', 'is', '$', 'g', '\\\\', '_', '}', 'e', 'cal', '{\\\\', 'g', '\\\\', 'cup_', '$\\\\', 'then', '$', 'g', '\\\\', '_', '}', 'e', 'cal', '${\\\\', 'by', '$', 'g', '\\\\', '_', '}', 'h', 'cal', '${\\\\', 'in', 'vectors', 'eigen', 'the', 'of', 'span', 'the', 'denote', 'we', '$', 'g', '$\\\\', 'each', 'for', 'if', '.', 's', '|$', 'q_v', '$|\\\\', 'of', 'roots', 'square', 'commuting', 'the', 'of', 'sum', 'finite', 'a', 'is', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'for', '$', 'g', '\\\\', '_', '}', 'h', 'cal', '${\\\\', 'to', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'of', 'restriction', 'the', 'of', 'spectrum', 'the', 'is', 'so', ',', 'therefore', '.', 'discrete', 'is', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'of', '$', 'g', '\\\\', '_', '}', 'h', 'cal', '${\\\\', 'completion', 'the', 'in', '$', 'q_v', '$\\\\', 'of', 'spectrum', 'the', 'that', '()', 'relations', 'commutation', 'momentum', 'angular', 'the', 'satisfying', 'operators', 'of', 'properties', 'known', 'well', 'the', 'from', 'follows', 'it', '}$.', 'e', ',', 'v', '{', 'i_', '^', 'j', '$', 'operators', 'the', 'of', 'triplets', 'of', 'products', 'the', 'of', 'coefficients', 'constant', 'with', 'sum', 'finite', 'a', 'is', '$', 'q_v', '$\\\\', 'operators', 'the', 'of', 'each', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'in', '$.', 's', '\\\\', 'in', '\\\\', 'x', '$', 'point', 'every', 'and', '$', 'sigma', '\\\\', 'subset', '\\\\', 'r', '$', 'region', 'every', 'for', 'thereon', 'operators', 'define', 'which', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'to', '()', 'of', 'restrictions', 'the', 'consider', 'and', '$', 'g', '$\\\\', 'fix', 'therefore', 'us', 'let', '$.', 'g', '$\\\\', 'graph', 'same', 'the', 'over', 'cylindrical', 'are', '$', 'g', '\\\\', 'psi_', '\\\\', 'q_x', '$\\\\', 'as', 'well', 'as', '$', 'g', '\\\\', 'psi_', '\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', '$', 'g', '\\\\', 'psi_', '$\\\\', 'function', 'cylindrical', 'every', 'for', ',', 'that', 'first', 'note', '.', 'spectrum', 'discrete', ',', 'same', 'the', 'have', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'volume', 'the', '$,', 'r', '$', 'region', 'open', 'the', 'of', 'choice', 'the', 'of', 'irrespective', 'that', 'show', 'first', 'will', 'we', ').', 'states', 'invariant', 'diffeomorphism', 'of', 'space', 'the', 'in', 'operator', 'the', 'induces', 'it', 'therefore', '.', 'invariant', 'diffeomorphism', 'is', '$', 'sigma', '\\\\', '_', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'total', 'the', '$,', 'sigma', '$\\\\', 'of', 'all', 'is', '$', 'r', '$', 'region', 'the', 'if', '!', 'exist', 'even', 'not', 'may', 'homeomorphisms', 'under', 'element', 'volume', 'the', 'of', 'image', ',', 'homeomorphisms', 'general', 'under', 'property', 'transformation', 'meaningful', 'a', 'have', 'to', 'fail', 'densities', 'since', '?', 'theory', 'classical', 'the', 'in', 'that', 'with', 'compare', 'situation', 'this', 'does', 'how', '.', 'covariance', 'the', 'contradicts', 'which', ',', 'property', 'above', 'the', 'with', 'graph', 'a', 'into', 'it', 'map', 'can', 'that', 'homeomorphism', 'a', 'is', 'there', 'graph', 'every', 'for', ',', 'however', '.', 'planar', '-', 'co', 'are', '$', 'g', '$\\\\', 'of', 'vertex', 'every', 'at', 'edges', 'incident', 'the', 'if', '$', 'g', '\\\\', 'psi_', '$\\\\', 'annihilates', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'that', 'recall', ',', 'particular', 'in', '.', 'homeomorphism', 'arbitrary', 'an', 'of', 'action', 'similar', 'a', 'with', 'covariant', 'be', 'to', 'fail', 'operators', 'volume', 'the', 'that', ',', 'however', ',', 'note', '$.', '0', '\\\\', '=', ']\\\\', 'q_x', ',\\\\', 'phi', '$[\\\\', 'then', '$,', 'x', '$', 'preserves', 'it', 'if', ',', 'and', ',$', '0', '=\\\\', ']\\\\', '_r', '}', 'v', '{', 'hat', ',\\\\', 'phi', '$[\\\\', 'have', 'we', '$,', 'r', '$', 'preserves', '$', 'phi', '$\\\\', 'if', 'particular', 'in', 'ea', '\\\\', '.', 'g', '\\\\', 'psi_', '\\\\', 'phi', '\\\\', ')}\\\\,', 'x', '(', 'phi', '{\\\\', 'q_', '\\\\', '&=&\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', 'q_x', '\\\\', 'phi', '\\\\', '\\\\\\\\', 'nonumber', '\\\\', ',', 'g', '\\\\', 'psi_', '\\\\', 'phi', '\\\\', ')}\\\\,', 'r', '(', 'phi', '{\\\\', '_', '}', 'v', '{', 'hat', '\\\\', '&=&\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '_r', '}', 'v', '{', 'hat', '\\\\', 'phi', '\\\\', 'ba', '\\\\', ',', 'is', 'that', '.', 'diffeomorphisms', 'these', 'to', 'respect', 'with', 'covariantly', 'transform', 'operators', 'volume', 'the', '()).', 'see', '(', '$', 'g', '\\\\', 'psi_', '$\\\\', 'determines', 'that', '$', 'n', ')]^', '2', '(', 'su', '$[', 'on', 'function', 'the', 'is', '$', 'psi', '$\\\\', 'where', 'ee', '\\\\', '))),', 'e_n', '(', 'phi', '(\\\\', 'ab', ',\\\\', '...', ')),', 'e_1', '(', 'phi', '(\\\\', 'ab', '(\\\\', 'psi', '\\\\', '\\\\,', '=', ')\\\\,', 'ab', '(\\\\', '}', 'g', '{\\\\', 'psi_', '\\\\', '\\\\,', 'phi', '\\\\', 'be', '\\\\', 'by', 'given', 'is', 'action', 'their', '$.', 'phi', '$\\\\', 'by', 'also', 'operators', 'these', 'denote', 'will', 'we', ',', 'simplicity', 'notational', 'for', '.', 'graph', 'embedded', 'analytically', 'an', 'to', '$', 'phi', '$\\\\', 'by', 'mapped', 'is', '$', 'g', '$\\\\', 'that', 'such', '$', 'g', '\\\\', 'psi_', '$\\\\', 'functions', 'cylindrical', 'all', 'of', 'span', 'linear', 'the', 'is', '.}', 'space', 'hilbert', 'whole', 'the', 'is', 'diffeomorphisms', 'each', 'of', 'domain', 'the', 'then', ',', 'graphs', 'smooth', 'the', 'all', 'by', 'given', 'of', 'space', 'hilbert', 'the', 'in', 'work', 'we', 'if', '{', 'footnote', '\\\\', '%', 'domain', 'whose', '$', 'h', '$\\\\', 'on', 'operator', 'an', 'obtain', 'we', '}$,', 'diff', 'rm', '{\\\\', 'in', '\\\\', 'phi', '$\\\\', 'given', '.', 'consider', 'can', 'one', 'that', '$', 'sigma', '$\\\\', 'of', 'diffeomorphisms', 'smooth', 'of', '}$', 'diff', 'rm', '${\\\\', ',', 'group', 'larger', 'a', 'however', 'is', 'there', '.', 'action', 'this', 'under', 'covariantly', 'transform', '$', '_x', '}', 'q', '{', 'hat', '$\\\\', 'and', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'the', '$.', 'h', '$\\\\', 'of', 'all', 'of', 'action', 'unitary', 'an', 'to', 'extends', 'and', ')}$', '3', '^{(', 'cyl', '$\\\\', 'on', 'product', 'inner', 'the', 'preserves', 'diffeomorphisms', 'these', 'of', 'action', 'the', 'hence', '.', 'action', 'this', 'under', 'invariant', 'is', '$', 'ab', '$\\\\', 'on', '$', 'o', '^', 'mu', '$\\\\', 'measure', 'the', ')}$.', '3', '^{(', 'cyl', '$\\\\', 'on', 'action', 'defined', '-', 'well', 'a', 'have', '$', 's', '$\\\\', 'on', 'diffeomorphisms', 'analytic', ',', 'analytic', 'are', 'graphs', 'our', 'of', 'edges', 'the', 'since', ')$.', 'gb', '/\\\\', 'ab', ')}(\\\\', '3', '^{(', 'cyl', '$\\\\', 'functions', 'cylindrical', 'invariant', 'gauge', 'of', 'space', 'the', 'in', 'operators', 'the', 'to', 'restrict', 'naturally', 'they', ',', 'therefore', '.', 'invariant', 'gauge', 'are', '$', 'q_x', '$\\\\', 'and', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'both', '.', 'dynamics', 'quantum', 'in', 'arise', 'that', 'operators', 'various', 'of', 'regularizations', 'recent', 'the', 'in', 'role', 'important', 'an', 'plays', 'property', 'this', '.', 'zero', 'not', 'is', 'general', 'in', 'but', 'exists', 'ee', '\\\\', 'g', '\\\\', 'psi_', '\\\\', ')}\\\\,', 'e', ',\\\\', 'x', '(', 'r', '{', '_', '}', 'v', '{', 'hat', '}\\\\', '0', 'rightarrow', '\\\\', 'e', '{\\\\', 'lim_', '\\\\', 'be', '\\\\', 'limit', 'the', '$,', 'g', '\\\\', 'psi_', '$\\\\', 'state', 'cylindrical', '$', '3', '^', 'c', '$', 'any', 'given', 'then', '$,', '0', 'rightarrow', '\\\\', 'e', '$\\\\', 'as', '$', 'x', '$', 'to', 'shrink', 'which', 'neighborhoods', 'of', 'family', 'a', 'is', ')$', 'e', ',\\\\', 'x', '(', 'r', '$', 'if', ')', '3', '.', 'operators', 'area', 'of', 'discussion', 'the', 'in', 'encountered', 'was', 'that', 'metrics', '-', '2', 'of', 'determinants', 'for', 'situation', 'the', 'to', 'analogous', 'completely', 'is', 'this', '.', 'distribution', 'valued', 'operator', 'an', 'as', 'even', 'exist', 'to', 'fails', 'metric', 'the', 'of', 'determinant', 'the', ',', 'contrast', 'by', 'ee', '\\\\', '.', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', '}}\\\\,', '2', '}{', '1', '{', 'frac', \"''}|^{\\\\\", 'e', ',', 'x', '{', 'k_', '^', 'j', \"'}\", 'e', ',', 'x', '{', 'j_', '^', 'j', '}', 'e', ',', 'x', '{', 'i_', '^', 'j', \"'')\\\\,\", 'e', \"',\", 'e', ',', 'e', '(', 'e', '\\\\', \"'']}\\\\,\", 'e', \"'],[\", 'e', '],[', 'e', '{[', 'sum_', '|\\\\', ')\\\\,', 'v', ',', 'x', '(', '3', '^', 'delta', '\\\\', '\\\\,', 'sum_v', '\\\\', '}}}', '48', '{{', 'sqrt', '\\\\', 'over', '\\\\', 'k_o', '{\\\\', '\\\\,', '=', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', ')}}\\\\,', 'x', '(', 'q', '{', 'sqrt', '{\\\\', 'widehat', '\\\\', 'be', '\\\\', ':', 'distribution', 'valued', '-', 'operator', 'an', 'as', 'metric', 'the', 'of', 'determinant', 'the', 'of', 'root', 'square', 'the', 'representing', ')}$,', 'x', '}(', 'q', '{', 'sqrt', '{\\\\', 'widehat', '$\\\\', 'operator', 'the', 'regard', 'to', 'meaningful', 'is', 'it', 'formulas', 'above', 'the', 'of', 'view', 'in', ')', '2', '.', 'adjoint', '-', 'self', 'essentially', 'is', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'and', 'defined', 'well', 'are', '()', 'of', 'equality', 'first', 'the', 'in', 'used', 'operator', 'this', 'of', 'root', 'square', 'and', 'value', 'absolute', 'the', 'therefore', '$.', 'h', '$\\\\', 'on', 'operator', 'adjoint', '-', 'self', 'essentially', 'an', 'is', 'it', ')}$,', '3', '^{(', 'cyl', '$\\\\', 'domain', 'with', ',', 'hence', '$.', 'g', '\\\\', '_', ')}', '0', '^{(', 'cyl', '\\\\', 'rightarrow', ')}\\\\', '3', '^{(', 'g', '\\\\', 'cyl_', '$\\\\', 'operators', 'adjoint', '-', 'self', 'essentially', 'of', '-', 'graphs', 'the', 'all', 'by', 'labelled', '-', 'family', 'consistent', 'cylindrically', 'a', 'by', 'given', 'is', '$', 'q_x', '$\\\\', 'operator', 'the', 'of', 'terminology', 'the', 'in', '$.', 'x', '$', 'at', 'intersecting', '$', 'g', '$\\\\', 'of', 'edges', 'three', 'overlap', \"'']$\", 'e', \"'],[\", 'e', '],[', 'e', '$[', 'germs', 'and', 'graph', 'the', 'of', 'vertex', 'a', 'is', '$', 'x', '$', 'if', 'only', 'trivial', '-', 'non', 'is', 'action', 'the', '$', 'g', '\\\\', 'psi_', '$\\\\', 'function', 'cylindrical', 'a', 'on', 'acting', ',', 'usual', 'as', '$.', 'x', '$', 'by', 'side', 'one', 'from', 'bounded', '$,', 'sigma', '$\\\\', 'of', 'manifolds', '-', 'sub', 'dimensional', '-', 'one', 'of', 'germs', 'of', 'set', 'the', 'through', 'runs', \"'']$\", 'e', '$[', 'and', \"']$\", 'e', '$[', ']$,', 'e', '$[', 'of', 'each', 'where', 'ea', '\\\\', \"''}\", 'e', ',', 'x', '{', 'k_', '^', 'j', \"'}\", 'e', ',', 'x', '{', 'j_', '^', 'j', '}', 'e', ',', 'x', '{', 'i_', '^', 'j', \"'')\\\\,\", 'e', \"',\", 'e', ',', 'e', '(', 'e', '\\\\', '}\\\\,', 'ijk', '{', 'e_', '\\\\', \"'']}\", 'e', \"'],[\", 'e', '],[', 'e', '{[', 'sum_', '\\\\', '}', '48', 'over', '\\\\', '1', '{', '&=&', '\\\\', 'q_x', '\\\\', '\\\\\\\\', 'nonumber', '\\\\', '}', 'where', 'rm', '{\\\\', 'quad', '|},\\\\', 'q_x', '{|\\\\', 'sqrt', '\\\\', '}', 'r', 'in', '\\\\', 'x', '{', 'sum_', '\\\\', 'k_o', '\\\\', '\\\\', '&=&', '\\\\', '_r', '}', 'v', '{', 'hat', '\\\\', '}', 'vfinal', '{', 'label', '\\\\', 'ba', '\\\\', '.', 'graphs', 'any', 'to', 'refer', 'not', 'does', 'that', 'fashion', \"'\", 'intrinsic', '`', 'an', 'in', 'recast', 'be', 'can', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'of', 'expression', 'the', ',', 'operators', 'area', 'with', 'as', ')', '1', '.', 'these', 'summarize', 'to', 'is', 'section', 'this', 'of', 'purpose', 'the', '.', 'explored', 'been', 'have', 'properties', 'basic', 'their', ',', 'counterparts', 'area', 'their', 'as', 'understood', 'well', 'as', 'not', 'are', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operators', 'volume', 'the', 'although', '.', 'case', 'smooth', 'that', 'to', 'extended', 'be', 'also', 'can', 'appendix', 'the', 'in', 'presented', 'volume', 'of', 'regularization', \"'\", 'external', '`', 'the', ',', 'modifications', 'analogous', 'using', '.)', 'beginning', 'the', 'from', 'decomposition', 'network', '-', 'spin', 'the', 'use', 'to', 'has', 'one', ':', 'modified', 'be', 'should', 'used', 'arguments', 'the', 'however', '(', '.', 'space', 'hilbert', 'whole', 'the', 'on', 'defined', 'well', 'now', 'is', 'diffeomorphisms', 'smooth', 'the', 'of', 'action', 'the', 'because', 'formulate', 'to', 'easier', 'even', 'is', ',', 'invariance', 'diffeomorphisms', 'the', ',', 'them', 'of', 'one', '.', 'below', 'discussed', 'properties', 'the', 'all', 'has', 'and', '()', 'formula', 'same', 'the', 'by', 'given', 'is', 'volume', 'resulting', 'the', '.', 'through', 'goes', 'construction', 'entire', 'the', 'and', ')}$', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'in', 'defined', 'well', 'are', '}$', 's_a', '{', 'i_', '^', 'e', '$', 'operators', 'surface', 'two', 'the', ',', 'hence', '.', 'construction', 'by', 'finite', 'is', '$', 'g', '$\\\\', 'and', '$', 'b', '$\\\\', 'by', 'defined', '$', 's_a', '$', 'surfaces', '-', 'two', 'the', 'between', 'intersection', 'of', 'number', 'the', '$', 'g', '$\\\\', 'graph', 'a', 'given', ',', 'then', '.', 'section', 'of', ')$', 'iii', ')-', 'i', '$', 'conditions', 'the', 'satisfies', 'that', '$', 'b', '$\\\\', 'partition', 'a', 'with', 'start', 'to', 'need', 'we', '(,)', 'operators', 'regulated', 'the', 'define', 'to', ',', 'therefore', '.', 'points', 'isolated', 'number', 'infinite', 'an', 'in', 'surface', '-', 'two', 'given', 'a', 'intersect', 'can', 'graph', 'smooth', 'a', 'because', 'occurs', 'problem', 'this', '.', 'space', 'hilbert', 'the', 'in', 'dense', 'be', 'to', 'fails', ')', 'analytic', 'be', 'not', 'may', 'or', 'may', 'which', '(', '$', 's', '$', 'surface', '-', 'two', 'a', 'over', 'smeared', '$', 'i_s', '^', 'e', '$\\\\', 'operator', 'the', 'of', 'domain', 'the', 'that', 'is', 'extension', 'this', 'with', 'problem', 'potential', 'only', 'the', ',', 'volume', 'of', 'regularization', 'the', 'in', '.', 'space', 'hilbert', 'a', 'to', 'leads', 'then', 'space', 'this', 'of', 'completion', 'cauchy', 'the', '$.', 'infty', '\\\\', 'cyl_', '$\\\\', 'of', 'elements', 'for', 'defined', '$', 'mu_o', '\\\\', 'd', 'int', '$\\\\', 'integral', 'the', 'of', 'extension', 'natural', 'a', 'provides', 'sawin', 'and', 'baez', 'of', 'work', 'the', '.', 'following', ',', 'graph', 'a', 'of', 'defintion', 'the', 'in', \"'\", 'smooth', '`', 'by', \"'\", 'analytic', '`', 'replacing', ',', 'graphs', 'smooth', 'the', 'all', 'by', 'given', '$', 'infty', '\\\\', 'cyl_', '$\\\\', 'functions', 'cylindrical', 'of', 'set', 'the', 'by', 'spanned', 'space', 'vector', 'the', 'with', 'begin', 'can', 'we', '.', 'above', 'presented', 'results', 'the', 'for', 'essential', 'really', 'not', 'is', 'graphs', 'the', 'of', 'analyticity', 'the', ',', '2', 'footnote', 'in', 'remarked', 'we', 'as', ':', 'case', 'smooth', 'the', 'to', 'extension', ')', '2', '$.', '1', '=', 'gamma', '$\\\\', 'and', '$', '1', '=', 'hbar', '$\\\\', '$,', '1', '=', 'g', 'pi', '\\\\', '8', '$', '$,', '1', '=', 'c', '$', 'conventions', 'the', 'to', 'return', 'we', ',', 'however', ',', 'paper', 'the', 'of', 'remainder', 'the', 'in', 'ea', '\\\\', '.', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', \"''}\\\\,\", 'e', ',', 'v', '{', 'k_', '^', 'j', \"'}\", 'e', ',', 'v', '{', 'j_', '^', 'j', '}', 'e', ',', 'v', '{', 'i_', '^', 'j', \"'')\", 'e', \"',\", 'e', ',', 'e', '(', 'e', \"''}\\\\\", 'e', \"',\", 'e', ',', 'e', '{', 'sum_', '}\\\\', 'ijk', '{', 'e_', '}\\\\', '48', 'over', '\\\\', '1', '{', '&=&\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'q_v', '\\\\', '\\\\\\\\', 'nonumber', '\\\\', '}', 'where', 'rm', '{\\\\', 'quad', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '|}\\\\,', 'q_v', '{|\\\\', 'sqrt', '\\\\', 'sum_v', '\\\\', '}', '2', 'over', '\\\\', '3', '})^{', '3', '^', 'c', '}{', 'gamma', '\\\\', 'hbar', '\\\\', 'g', 'pi', '\\\\', '8', '{', 'frac', '(\\\\', 'k_o', '\\\\', '&=&\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\,\\\\', '_r', '}', 'v', '{', 'hat', '\\\\', \"'}\", 'volgamma', '{', 'label', '\\\\', 'ba', '\\\\', ':', 'by', 'given', 'is', 'operator', 'volume', 'the', '$,', 'gamma', '$\\\\', 'by', 'labelled', 'representation', 'quantum', 'the', 'in', '.', 'expression', 'final', 'the', 'in', '$', 'gamma', '$\\\\', 'parameter', 'immirzi', 'the', 'and', '$', 'hbar', '$\\\\', '$,', 'g', '$', '$,', 'c', '$', 'of', 'factors', 'the', 'restore', 'us', 'let', ':', 'constants', 'of', 'restoration', ')', '1', '.', 'remarks', 'two', 'with', 'conclude', 'we', ')}$.', '3', '^{(', 'cyl', '$\\\\', 'in', 'operator', 'an', 'defines', 'unambiguously', '()', ',', 'therefore', ').', 'in', 'introduced', 'condition', \"'\", 'consistency', 'cylindrical', '`', 'the', 'satisfy', '$', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '$\\\\', 'various', 'on', 'defined', 'operators', 'of', 'family', 'the', ',', 'is', 'that', \"'}$.\", 'g', '{\\\\', '_', ')}', '3', '^{(', 'cyl', '\\\\', 'cap', '\\\\', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '$\\\\', 'intersection', 'the', 'on', 'agree', 'operators', 'corresponding', 'the', ',', 'graphs', 'of', 'pair', 'any', 'for', 'that', 'check', 'to', 'easy', 'quite', 'is', 'it', ',', 'next', '$).', 'g', '$\\\\', 'any', 'for', '(', '$', 'g', '\\\\', '_', ')}', '3', '^{(', 'cyl', '$\\\\', 'in', 'defined', 'is', 'operator', 'the', '$,', 'g', '$\\\\', 'graph', 'the', 'to', 'reference', 'explicit', 'the', 'of', 'because', ',', 'written', 'as', '.', 'undetermined', 'remains', '$', 'k_o', '$\\\\', 'constant', 'the', '$.', 's', '$\\\\', 'on', 'orientation', 'fixed', 'the', 'to', 'respect', 'with', 'negative', 'or', 'positively', 'oriented', 'and', 'independent', 'linearly', 'are', 'they', 'if', '$', '1', 'pm', '$\\\\', 'and', 'dependent', 'linearly', 'are', 'edges', 'three', 'the', 'of', 'directions', 'tangent', 'the', 'of', '$', '0', '$', 'equals', 'which', ',', 'function', 'orientation', 'the', 'is', \"'')$\", 'e', \"',\", 'e', ',', 'e', '(', 'e', '$\\\\', 'and', '$', 'v', '$', 'vertex', 'the', 'through', 'passing', '$', 'g', '$\\\\', 'of', 'edges', 'of', 'set', 'the', 'over', \"''$\", 'e', \"',\", 'e', ',', 'e', '$', '$;', 'g', '$\\\\', 'of', 'vertices', 'of', 'set', 'the', 'over', 'runs', '$', 'v', '$', 'here', 'ea', '\\\\', '.', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', \"''}\\\\,\", 'e', ',', 'v', '{', 'k_', '^', 'j', \"'}\", 'e', ',', 'v', '{', 'j_', '^', 'j', '}', 'e', ',', 'v', '{', 'i_', '^', 'j', \"'')\", 'e', \"',\", 'e', ',', 'e', '(', 'e', \"''}\\\\\", 'e', \"',\", 'e', ',', 'e', '{', 'sum_', '}\\\\', 'ijk', '{', 'e_', '}\\\\', '48', 'over', '\\\\', '1', '{', '&=&\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'q_v', '\\\\', '\\\\\\\\', 'nonumber', '\\\\', '}', 'where', 'rm', '{\\\\', 'quad', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '|}\\\\,', 'q_v', '{|\\\\', 'sqrt', '\\\\', 'sum_v', '\\\\', 'k_o', '\\\\', '&=&\\\\', '\\\\', 'g', '\\\\', 'psi_', '\\\\,\\\\', '_r', '}', 'v', '{', 'hat', '\\\\', '}', 'volgamma', '{', 'label', '\\\\', 'ba', '\\\\', 'by', 'given', 'is', '$', 'g', '\\\\', 'psi_', '$\\\\', 'function', 'cylindrical', 'any', 'on', 'action', 'whose', '$,', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'an', 'have', 'we', '$,', 's', '$\\\\', 'in', '$', 'r', '$', 'region', 'a', 'given', '.', 'following', 'the', 'is', 'result', 'final', 'the', '.', 'exist', 'do', 'type', 'required', 'the', 'of', 'functions', 'averaging', 'the', '.,', 'e', '.', 'i', ',', 'measures', 'suitable', 'to', 'respect', 'with', 'averaging', 'from', 'result', 'does', 'form', 'this', ',', 'finally', '$.', 'k_o', '$\\\\', 'constant', 'multiplicative', 'overall', 'an', 'for', 'except', 'operator', 'averaged', 'the', 'of', 'form', 'the', 'determines', 'it', 'that', 'strong', 'so', 'is', 'covariant', 'diffeomorphism', 'and', 'defined', '-', 'well', 'be', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'final', 'the', 'that', 'requirement', 'the', 'that', 'out', 'turns', 'it', '.', 'structures', 'background', \"'\", 'relevant', '`', 'the', 'over', 'average', 'to', 'procedure', 'a', 'introduced', 'we', 'section', 'in', ',', 'situation', 'this', 'remedy', 'to', '.', 'diffeomorphisms', 'under', 'covariant', 'be', 'to', 'fails', 'operator', 'volume', 'resulting', 'the', 'therefore', 'and', 'used', 'regulators', 'the', 'of', 'memory', 'a', 'carries', 'it', ',', 'however', '.', 'defined', '-', 'well', 'is', ')', '(,', 'operator', 'limiting', 'the', ',', 'care', 'due', 'with', 'removed', 'is', 'regulator', 'the', 'if', 'that', 'showed', 'then', 'we', '.', 'theory', 'quantum', 'the', 'to', 'over', 'taken', 'be', 'could', 'form', \"'\", 'regulated', '`', 'resulting', 'the', 'that', 'such', 'space', 'phase', 'classical', 'the', 'on', '$', 'v_r', '$', 'function', 'volume', 'the', 'recasting', 'by', 'began', 'we', ',', '3', 'section', 'in', '.', 'subsections', 'three', 'previous', 'the', 'and', 'section', 'in', 'obtained', 'results', 'the', 'collect', 'now', 'us', 'let', '.', 'type', 'required', 'the', 'of', 'functions', 'averaging', 'of', 'existence', 'the', 'establishes', 'this', '}$.', 's', 'cal', '${\\\\', 'on', 'independent', 'linearly', 'all', 'are', ')$', 'theta', '\\\\', '],', 'e_k', '[', '],', 'e_j', '[', '],', 'e_i', '([', 'k', '$\\\\', 'functions', 'the', 'and', 'function', 'constant', 'the', ',', 'above', 'statement', 'the', 'in', 'asserted', 'as', ',', 'thus', 'ee', '\\\\', '.', 'a', '=\\\\', '\\\\', '0', '=\\\\', '}\\\\', 'ijk', '{', 'a_', 'be', '\\\\', 'conclude', 'we', '$,', 'k', ',', 'j', ',', 'i', '$', 'triple', 'any', 'to', 'applies', 'argument', 'this', 'since', 'ee', '\\\\', '.', '0', '=\\\\', '}\\\\', '123', '{', 'a_', 'be', '\\\\', 'obtain', 'we', ',', 'say', '$,', 'e_3', '$', 'and', '$', 'e_2', '$', 'for', 'argument', 'that', 'repeating', '$.', 's_3', ',', 's_2', '$', 'arbitrary', 'for', 'ee', '\\\\', '0', '=\\\\', ')\\\\', 'e_k', '}(', 's_c', '{', 'k_', ')\\\\', 'e_j', '}(', 's_b', '{', 'k_', '\\\\', '}\\\\,', '1bc', '{', 'e_', '}\\\\,\\\\', '1jk', '{', 'a_', 'be', '\\\\', 'find', 'we', ',', 'subtracting', 'and', '$,', 's_3', ',', 's_2', '$', 'any', 'with', ')$', 's_3', ',', 's_2', '+,', 's_', '+=(', 'theta_', '$\\\\', 'next', 'and', ')$,', 's_3', ',', 's_2', '-,', 's_', '-:=(', 'theta_', '$\\\\', '()', 'into', 'plugging', ',', 'therefore', 'ee', '\\\\', '.', '1', 'pm', '\\\\', '=\\\\', ')\\\\', 'e_i', '}(', 'pm', '\\\\', 's_', '{', 'k_', '\\\\', 'be', '\\\\', 'that', 'such', '$', 's_0', '$', 'near', '+$', 's_', '$', 'and', '-$', 's_', '$', 'surfaces', '-', 'two', 'find', 'can', 'we', '.', 'change', 'does', ')$', 'e_1', '}(', 's_1', '{', 'k_', '$\\\\', ',', 'hand', 'other', 'the', 'on', '$.', '1', '=', 'not', '\\\\', 'j', '$', 'if', 'unchanged', 'remain', ')$', 'e_j', '}(', 's_1', '{', 'k_', '$\\\\', 'functions', 'the', '$,', 's_0', '$', 'around', '$', 's_1', '$', 'vary', 'slightly', 'we', 'as', ',', 'then', '$.', 's_0', '$', 'near', 'is', '$', 's_1', '$', 'where', '}$', 's', 'cal', '${\\\\', 'of', 'points', 'the', 'consider', '.', 'germs', 'other', 'the', 'of', 'any', 'to', 'not', 'is', 'but', ']$', 'e_1', '$[', 'to', 'tangent', 'is', 'which', '$', 's_0', '$', 'surface', '-', 'two', 'a', 'pick', '}$.', 's', 'cal', '{\\\\', 'in', ')\\\\', 's_3', ',', 's_2', ',', 's_1', '=(', 'theta', '$\\\\', 'every', 'almost', 'for', 'ee', '\\\\', ',', '0', '=\\\\', ')', 'theta', '],\\\\', 'e_k', '[', '],', 'e_j', '[', '],', 'e_i', '([', 'k', '}\\\\', 'ijk', '{', 'a_', '}', 'k', '<', 'j', '<', 'i', '{', 'sum_', '\\\\', '+\\\\', '\\\\', 'a', '?}', 'id', '{', 'label', '\\\\', 'be', '\\\\', 'that', 'such', '$', 'n', ',...', '1', '=', 'k', ',', 'j', ',', 'i', '$', '}$,', 'ijk', '{', 'a_', ',\\\\,', 'a', '$', 'constants', 'exist', 'there', 'that', 'suppose', ',', 'statement', 'the', 'in', 'as', ']$', 'e_n', '],...,[', 'e_1', '$[', 'germs', 'given', ',', 'now', '.)', 'system', 'coordinate', 'initial', 'this', 'to', 'respect', 'with', 'defined', 'being', ')$', '3', '(', 'gl', '$', 'of', 'action', 'the', '$,', 'const', '=', 'a', '^', 'x', '$', 'surfaces', 'the', 'on', 'transformations', 'linear', ')$', '3', '(', 'gl', '$', 'preserving', 'orientation', 'the', 'applying', 'by', 'obtained', 'are', 'triplets', 'these', '(', '$.', 'v', '$', 'at', 'intersecting', '}$,', '3', ',', '2', ',', '1', '=', 'a', '{', '_', ')', 's_a', '(', 'equiv', '\\\\', 'theta', '$\\\\', ',', 'surfaces', '-', 'two', 'oriented', 'of', 'triplets', 'of', 'set', 'the', 'with', 'identified', 'be', 'can', '$', 's', 'cal', '$\\\\', 'regulators', 'of', 'set', 'the', 'that', 'first', 'recall', '.', 'statement', 'this', 'establish', 'therefore', 'us', 'let', 'smallskip', '\\\\', '}$.}', 's', 'cal', '${\\\\', 'on', 'functions', 'independent', 'linearly', 'of', 'set', 'a', 'constitute', 'function', 'constant', 'the', 'and', '$', 'k', '<', 'j', '<', 'i', '$', ')$,', 'theta', '\\\\', '],', 'e_k', '[', '],', 'e_j', '[', '],', 'e_i', '([', 'k', '$\\\\', 'functions', 'the', '$,', 'j', '=', 'not', '\\\\', 'i', '$', 'whenever', '$', 'e_j', '$', 'to', 'tangent', 'not', 'is', '$', 'e_i', '$', 'that', 'such', '$,', 'v', '$', 'point', 'a', 'at', ']\\\\$', 'e_n', '],...,[', 'e_1', '$\\\\{[', 'germs', 'of', 'set', 'finite', 'any', 'for', 'smallskip', '\\\\', ':', 'holds', 'statement', 'following', 'the', 'provided', 'exist', 'to', 'guaranteed', 'is', ')$', 'theta', '(\\\\', 'mu', '$\\\\', 'required', 'the', ')', 'respectively', '$', '1', '$', 'and', '$', 'k', '$\\\\', 'with', '$', 'mu', '$\\\\', 'of', '(', ')$,', 'theta', '\\\\', '6', '^', 'd', '},', 's', 'cal', '$({\\\\', 'on', 'product', 'inner', '$', '2', '^', 'l', '$', 'the', 'represent', 'equations', 'above', 'the', 'in', 'integrals', 'the', 'since', 'and', 'edges', 'three', 'the', 'of', 'directions', 'tangent', 'oriented', 'the', 'on', 'only', 'depends', '])$', 'e_k', '[', '],', 'e_j', '[', '],', 'e_i', '([', 'k', '$\\\\', 'since', ',', 'now', '?', '$', 'k_o', '$\\\\', 'constant', 'some', 'for', '$$', '1', '=', ')', 'theta', '(\\\\', 'mu', '\\\\', 'theta', '\\\\', '6', '^', 'd', '}', 's', 'cal', '{\\\\', 'int_', '\\\\', 'quad', '\\\\', '}', 'and', 'rm', '{\\\\', 'quad', '\\\\', '])', 'e_3', '],[', 'e_2', '],[', 'e_1', '([', 'e', '\\\\', 'k_o', '=\\\\', ')\\\\', 'theta', '],\\\\', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '\\\\', ')', 'theta', '(\\\\', 'mu', '\\\\', 'theta', '\\\\', '6', '^', 'd', '}', 's', 'cal', '{\\\\', 'int_', '\\\\', '$$', ',', 'vertex', 'the', 'at', '$', 'g', '$\\\\', 'of', 'edges', 'of', '$', 'e_k', ',', 'e_j', ',', 'e_i', '$', 'triplet', 'any', 'for', ',', 'that', 'such', '}$', 's', 'cal', '${\\\\', 'on', ')$', 'theta', '(\\\\', 'mu', '$\\\\', 'function', 'a', 'exist', 'there', 'does', '$,', 'g', '$\\\\', 'graph', 'any', 'of', '$', 'v', '$', 'vertex', 'any', 'given', ':', 'follows', 'as', 'question', 'the', 'rephrase', 'can', 'we', ',', 'therefore', '().', 'by', 'given', 'be', '()', 'of', '}$', 'av', '^{', 'k', '$\\\\', 'that', 'is', 'covariant', 'and', 'defined', '-', 'well', 'be', 'to', '}$', 'v_r', '{', 'hat', '$\\\\', 'for', 'condition', 'sufficient', 'and', 'necessary', 'the', 'that', 'section', 'in', 'saw', 'just', 'we', '?', 'diffeomorphisms', 'under', 'covariantly', 'transform', 'that', '}$', 'v_r', '{', 'hat', '$\\\\', 'operators', 'volume', 'to', 'lead', 'which', ')$', 'theta', '(\\\\', 'mu', '$\\\\', 'functions', 'averaging', 'exist', 'there', 'do', ':', 'existence', 'of', 'issue', 'the', 'to', 'turn', 'now', 'we', '.', 'consideration', 'under', 'graph', 'or', 'vertex', 'specific', 'the', 'on', 'not', 'and', ')$', 'theta', '(\\\\', 'mu', '$\\\\', 'function', 'averaging', 'the', 'on', 'only', 'depend', 'can', ')}$', 'mu', '{(\\\\', 'k_', '$\\\\', 'constant', 'the', 'that', 'imply', ')', '6', '(', 'and', ')', '3', '(', 'properties', ',', 'finally', '().', 'by', 'given', 'is', 'it', ')}$.', 'mu', '{(\\\\', 'k_', '$\\\\', 'constant', 'multiplicative', 'a', 'to', 'up', ',', 'uniquely', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'determines', 'averaging', 'that', 'then', '$,', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'covariant', 'diffeomorphism', 'defined', '-', 'well', 'a', 'provides', 'which', 'to', 'respect', 'with', 'averaging', '}$,', 's', 'cal', '${\\\\', 'on', '$', 'mu', '$\\\\', 'measure', 'a', 'exists', 'there', 'if', 'that', 'imply', ')', '7', '(', 'and', ')', '5', '(', 'properties', '$.', '0', '=', '])', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'then', ',', 'dependent', 'linearly', 'are', '$', 'x', '$', 'at', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '$([', 'edges', 'the', 'by', 'determined', 'directions', 'tangent', 'three', 'the', 'if', ')$]', '7', '[$(', 'item', '\\\\', ':', 'have', 'we', ',', 'thus', '.', 'well', 'as', 'case', 'this', 'in', '$', '0', '=', '])', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'conclude', 'we', ',', 'symmetry', '-', 'anti', 'and', 'invariance', 'diffeomorphism', 'by', ',', 'hence', '])$.', 'e_3', '[', '],', 'e_1', '[', '],', 'e_2', '$([', 'to', '])$', 'e_3', '[', '],', 'e_2', '[', '],', 'e_1', '$([', 'carries', 'which', '--', 'axis', 'third', 'the', 'along', '$', 'pi', '$\\\\', 'through', 'rotation', 'the', '--', 'diffeomorphism', 'preserving', 'orientation', 'an', 'exists', 'there', ',', 'finally', ')$.', '0', ',', '1', ',', '1', '$(', 'and', ')$', '0', ',', '1', ',', '0', '(', '),', '0', ',', '0', ',', '1', '$(', 'lines', 'straight', 'with', 'coincide', 'germs', 'three', 'the', ')', 'and', 'origin', 'the', 'at', 'lies', '$', 'x', '$', 'point', 'the', '(', 'which', 'in', '}$', 's', 'cal', '${\\\\', 'in', 'system', 'coordinate', 'a', 'is', 'there', \"'),\", 'edges', 'the', 'out', 'straighten', '`', 'to', '(', 'diffeomorphism', 'possible', 'a', 'modulo', ',', 'then', '.', 'other', 'each', 'to', 'tangential', 'are', 'directions', 'these', 'of', 'two', 'no', 'that', 'such', 'are', 'but', 'plane', '-', 'two', 'a', 'span', 'directions', 'tangent', 'three', 'the', 'which', 'in', 'case', 'remaining', 'the', 'consider', ',', 'finally', '.', 'parallel', '-', 'anti', 'are', 'directions', 'tangent', 'two', 'any', 'if', 'vanishes', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'that', 'implies', 'turn', 'in', 'which', '])$,', 'e_k', '],[', 'e_j', '],[', 'e_i', '([-', 'av', '^\\\\', 'k', '-\\\\', '])\\\\,=\\\\,', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', ',', 'hence', ']$.', 'e_i', '}[-', 's_a', '{', 'k_', '-\\\\', '=', ']', 'e_i', '}[', 's_a', '{', 'k_', '$\\\\', 'that', 'implies', '()', 'that', 'note', ',', 'next', '.', 'vanish', 'must', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'that', 'implies', 'immediately', 'symmetry', '-', 'anti', ',', 'coincide', 'directions', 'these', 'of', 'two', 'if', '.', 'dependent', 'linearly', 'are', 'directions', 'tangent', 'the', 'when', 'case', 'the', 'in', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'evaluate', 'to', 'property', 'this', 'use', 'now', 'can', 'we', '.', 'germs', 'three', 'the', 'by', 'defined', '$', 'x', '$', 'at', 'directions', 'tangent', 'oriented', 'the', 'on', 'only', 'depend', 'can', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', '$,', 's', '$\\\\', 'in', '$', 'x', '$', 'point', 'a', 'given', ')$]', '6', '[$(', 'item', '\\\\', 'that', 'shown', 'have', 'we', ',', 'summarize', 'to', 'ee', '\\\\', ']).', '_k', \"'\", 'e', '[', '],', '_j', \"'\", 'e', '],[', '_i', \"'\", 'e', '([', 'av', '^\\\\', 'k', '\\\\', '\\\\,', '=', '])\\\\,', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '\\\\', 'be', '\\\\', 'yields', '$', 'theta', '\\\\', '6', '^', 'd', ')', 'theta', '(\\\\', 'mu', '$\\\\', 'a', 'to', 'respect', 'with', 'integration', ',', 'case', 'this', 'in', '}$.', 's', 'cal', '${\\\\', 'on', 'everywhere', 'almost', 'holds', 'ee', '\\\\', ')', 'theta', '],\\\\', '_k', \"'\", 'e', '[', '],', '_j', \"'\", 'e', '[', '],', '_i', \"'\", 'e', '([', 'k', '\\\\', '\\\\,', '=', ')\\\\,', 'theta', '],\\\\', 'e_k', '[', '],', 'e_j', '[', '],', 'e_i', '([', 'k', '\\\\', '\\\\', '\\\\', '\\\\', 'be', '\\\\', 'equality', 'the', '$,', 'x', '$', 'at', 'directions', 'tangent', 'oriented', 'same', 'the', 'define', 'germs', 'unprimed', 'and', 'primed', 'of', 'pairs', 'three', 'the', 'whenever', ',', 'hence', ')$.', '_3', \"'}\", 'e', '}({', 's_a', '{', 'k_', '\\\\', '=\\\\', ')\\\\', 'e_3', '}(', 's_a', '{', 'k_', '$\\\\', 'have', 'we', '}$,', 's', 'cal', '${\\\\', 'on', 'everywhere', 'almost', ',', 'therefore', '.', 'surfaces', '-', 'two', 'the', 'of', 'each', 'of', 'side', 'same', 'the', 'on', 'are', '$', '_3', \"'}\", 'e', '${', 'and', '$', 'e_3', '$', 'germs', 'the', '$,', 'e_3', ',', 'e_2', ',', 'e_1', '$', 'germs', 'the', 'of', 'any', 'to', 'tangent', 'is', '$', 'v', '$', 'through', 'passing', '$', 's_a', '$', 'surfaces', '-', 'two', 'corresponding', 'the', 'of', 'none', 'that', 'such', '}$', 's', 'cal', '{\\\\', 'in', '\\\\', 'theta', '$\\\\', 'point', 'a', 'for', '$.', 'x', '$', 'at', '$', 'e_3', '$', 'to', 'tangent', 'is', '$', '_3', \"'}\", 'e', '${', 'that', 'such', '])$', '_3', \"'\", 'e', '[', '],', 'e_2', '[', '],', 'e_1', '$([', 'and', '])$', 'e_3', '[', '],', 'e_2', '[', '],', 'e_1', '$([', ',', 'orientation', 'same', 'with', 'triplets', 'two', 'consider', '.', 'follows', 'as', 'out', 'ruled', 'be', 'can', 'they', ',', 'however', '])$.', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'for', 'candidates', 'potential', 'are', 'these', ',', 'apriori', '.', 'point', 'intersection', 'the', 'at', 'edges', 'of', 'derivatives', 'higher', 'on', 'depend', 'which', ',', 'exist', 'invariants', 'other', ',', 'dependent', 'linearly', 'are', 'directions', 'tangent', 'three', 'the', 'if', ',', 'hand', 'other', 'the', 'on', '$.', 'x', '$', 'at', 'intersecting', 'edges', 'of', 'triplets', 'ordered', 'of', 'germs', 'of', 'function', 'symmetric', '-', 'anti', 'totally', ',', 'invariant', 'diffeomorphism', 'only', 'the', 'is', 'this', 'since', 'ee', '\\\\', ')', 'e_k', ',', 'e_j', ',', 'e_i', '(', 'epsilon', '\\\\', ')}\\\\,\\\\,', 'mu', '{(\\\\', 'k_', '\\\\', '=', '])', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '\\\\', '}', 'det4', '{', 'label', '\\\\', 'be', '\\\\', ',', 'then', '.', 'independent', 'linearly', 'are', '$', 'x', '$', 'at', 'define', 'they', 'directions', 'tangent', 'the', 'that', 'such', 'be', 'triplet', 'the', 'let', ')$]', '5', '[$(', 'item', '\\\\', ').', '4', ')-(', '2', '(', 'from', 'immediately', 'follows', 'property', 'next', 'the', 'ee', '\\\\', '.', '])\\\\,', '_k', \"'\", 'e', '],[', '_j', \"'\", 'e', '],[', '_i', \"'\", 'e', '([', 'av', '^\\\\', 'k', '\\\\', '\\\\,', '=', '])\\\\,', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '\\\\', 'be', '\\\\', '$,', 's', '$\\\\', 'of', 'diffeomorphism', 'preserving', 'orientation', 'an', 'by', 'related', 'edges', 'of', ')$', '_k', \"'\", 'e', ',', '_j', \"'\", 'e', ',', '_i', \"'\", 'e', '$(', 'and', ')$', 'e_k', ',', 'e_j', ',', 'e_i', '$(', 'triplets', 'two', 'any', 'given', ')$]', '4', '[$(', 'item', '\\\\', ':', 'property', 'following', 'the', 'have', 'must', 'function', 'this', 'that', 'implies', 'operator', 'volume', 'the', 'of', 'covariance', 'diffeomorphism', 'assumed', 'the', ',', 'next', '.', 'reals', 'to', '$', 's', '$\\\\', 'in', '$', 'x', '$', 'point', 'any', 'at', 'intersecting', 'edges', 'of', 'triplets', ')', 'ordered', '(', 'of', 'germs', 'from', 'function', 'a', 'provides', 'simply', 'procedure', 'averaging', 'the', ',', 'thus', '.', 'computation', 'the', 'in', 'used', 'graph', 'specific', 'the', 'on', 'not', 'and', 'edges', 'three', 'the', 'of', 'germs', 'the', 'on', 'only', 'depends', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'by', 'defined', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '}([', 'av', '^{\\\\', 'k', '\\\\', '\\\\,', 'rightarrow', '\\\\', '\\\\,', ')', 'e_k', ',', 'e_j', ',', 'e_i', '$(', 'function', 'the', ')$]', '3', '[$(', 'item', '\\\\', 'that', 'implies', 'this', '.', 'second', 'the', 'or', 'graph', 'first', 'the', 'to', 'respect', 'with', 'cylindrical', 'being', 'as', 'state', 'the', 'regard', 'we', 'whether', 'on', 'depend', 'not', 'should', 'state', 'a', 'on', 'action', 'its', ',', 'end', 'the', 'at', 'defined', '-', 'well', 'be', 'to', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'the', 'want', 'we', 'since', \"'$.\", 'g', '$\\\\', ')', 'of', 'range', 'the', '(', 'in', 'contained', 'is', '$', 'g', '$\\\\', ')', 'of', 'range', 'the', '(', 'that', 'such', '.,', 'e', '.', 'i', '$,', 'g', 'ge', \"'\\\\\", 'g', '$\\\\', 'with', \"'$\", 'g', '$\\\\', 'graph', 'a', 'to', 'respect', 'with', 'cylindrical', 'also', 'is', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'in', 'function', 'cylindrical', 'a', 'that', 'recall', ',', 'next', '.', 'arguments', 'three', 'its', 'in', 'symmetric', '-', 'anti', 'totally', 'is', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', ')$]', '2', '[$(', 'item', '\\\\', ',', 'and', ';', 'edges', 'the', 'of', 'germs', 'the', 'on', 'only', 'depends', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', ')$]', '1', '[$(', 'item', '\\\\', ':', 'have', 'we', ',', 'thus', '.', 'averaging', 'by', 'preserved', 'are', 'properties', 'these', 'that', 'verify', 'to', 'trivial', 'is', 'it', '.', 'partition', 'permissible', 'a', 'of', 'choice', 'the', 'of', 'irrespective', 'properties', 'two', 'has', '])$', 'e_k', '[', '],', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', 'that', 'section', '-', 'sub', 'last', 'the', 'of', 'end', 'the', 'at', 'saw', 'we', '.', 'form', 'its', 'constrain', 'to', ',', 'covariant', 'diffeomorphism', 'be', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'that', 'requirement', 'the', 'and', '()', '(),', 'by', 'implied', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '}([', 'av', '^{\\\\', 'k', '$\\\\', 'of', 'symmetries', 'use', 'to', 'is', 'idea', 'the', '.', 'constant', 'multiplicative', 'overall', ',', 'single', 'a', 'in', 'contained', 'is', 'dependence', 'measure', 'the', ',', 'thus', '.)', 'oriented', 'is', '$', 's', '$\\\\', 'that', 'recall', '(', '.', 'negatively', 'or', 'positively', 'oriented', 'and', 'independent', 'linearly', 'are', 'they', 'if', '$', '1', 'pm', '$\\\\', 'and', '$,', 'v', '$', 'vertex', 'the', 'at', 'dependent', 'linearly', 'are', 'edges', 'three', 'the', 'to', '$.}', 'x', '$', 'at', 'direction', 'tangent', 'oriented', 'unique', 'defines', '$', 's', '$\\\\', 'in', '$', 'x', '$', 'point', 'a', 'at', ']$', 'e', '$[', 'germ', 'a', '{', 'footnote', '\\\\', '%', 'directions', 'tangent', 'the', 'if', '$', '0', '$', 'equals', 'which', 'function', 'orientation', 'the', 'is', ')$', 'e_k', ',', 'e_j', ',', 'e_i', '(', 'e', '$\\\\', 'where', ')}$,', 'mu', '{(\\\\', 'k_', '$\\\\', 'constant', ')', 'dependent', '-', 'measure', '(', 'some', 'for', 'ee', '\\\\', ')', 'e_k', ',', 'e_j', ',', 'e_i', '(', 'e', '\\\\', ')}\\\\,\\\\,', 'mu', '{(\\\\', 'k_', '\\\\', '=', '])', 'e_k', '],[', 'e_j', '],[', 'e_i', '}([', 'av', '^{\\\\', 'k', '\\\\', '}', 'kappa2', '{', 'label', '\\\\', 'be', '\\\\', ':', 'type', 'the', 'of', 'be', 'must', 'quantity', 'the', ',', 'graph', 'any', 'of', '$', 'v', '$', 'vertex', 'a', 'containing', 'cell', 'any', 'given', ',', 'that', 'show', 'to', 'is', 'section', '-', 'sub', 'this', 'of', 'purpose', 'the', '])$?', 'e_k', '],[', 'e_j', '],[', 'e_i', '}([', 'av', '^{\\\\', 'k', '$\\\\', 'corresponding', 'the', 'about', 'say', 'we', 'can', 'what', '$.', 's', '$\\\\', 'of', 'diffeomorphisms', 'under', 'covariantly', 'transforms', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'resulting', 'the', 'that', 'such', '}$', 's', 'cal', '${\\\\', 'on', '$', 'mu', '$\\\\', 'measure', 'normalized', 'a', 'exist', 'does', 'there', 'that', 'suppose', 'us', 'let', '$}', '.', 'section', 'in', 'established', 'be', 'then', 'will', 'type', 'required', 'the', 'of', 'measures', 'of', 'existence', '.', 'constant', 'multiplicative', 'a', 'to', 'up', 'uniquely', '---', 'operator', 'volume', 'final', 'the', 'also', 'hence', 'and', '---', '}$', 'av', '^{\\\\', 'k', '$\\\\', 'determines', 'operator', 'volume', 'final', 'the', 'of', 'covariance', 'of', 'requirement', 'the', 'that', 'show', 'and', 'exist', 'measures', 'such', 'that', 'assume', 'will', 'we', 'section', 'in', '.', 'independent', 'background', 'is', 'operator', 'volume', 'final', 'the', 'which', 'for', ')$', 'theta', '(\\\\', 'mu', '$\\\\', 'find', 'to', 'need', 'we', 'and', 'case', 'the', 'not', 'is', 'this', ',', 'hand', 'other', 'the', 'on', ',', 'theory', 'quantum', 'the', 'in', ')$.', 'theta', '(\\\\', 'mu', '$\\\\', 'normalized', 'any', 'for', '$', 'v_r', '$', 'to', 'tends', 'volume', 'regulated', 'averaged', 'the', ',', 'classically', 'applicable', 'is', 'procedure', 'averaging', 'the', 'although', ',', 'section', 'in', 'saw', 'we', 'as', ':', 'negative', 'the', 'in', 'is', 'answer', 'the', '?', 'limit', 'classical', 'the', 'examining', 'by', 'selected', 'perhaps', 'be', 'measure', 'suitable', 'a', 'can', '.', 'measure', 'normalized', 'canonical', 'a', 'admit', 'not', 'does', 'and', 'compact', '-', 'non', 'is', '}$', 's', 'cal', '${\\\\', 'space', 'the', ',', 'unfortunately', '?', 'averaging', 'for', 'use', 'we', 'should', 'measure', 'what', ':', 'is', 'then', 'question', 'key', 'the', '.', 'theory', 'classical', 'the', 'in', 'functional', 'volume', 'correct', 'the', 'yield', 'does', 'procedure', 'averaging', 'the', ',', 'section', 'in', 'saw', 'we', 'as', ',', 'that', 'fact', 'the', 'from', 'comes', 'strategy', 'this', 'for', 'justification', 'physical', '.', 'operators', 'averaged', 'using', 'now', 'but', 'section', 'of', 'procedure', 'the', 'repeat', 'to', 'simply', 'is', 'idea', 'basic', 'the', ',', 'summarize', 'to', '.', 'cells', 'all', 'for', 'hold', '()', 'and', '()', ',', 'cell', 'specific', 'any', 'to', 'adapted', 'not', 'were', ')$', 'theta', '(\\\\', 'a', '^', 'x', '$', 'systems', 'coordinate', 'the', 'since', ',', 'however', '$.', 'v', '$', 'vertex', 'a', 'containing', '$', 'c', '$', 'cell', 'single', 'a', 'on', 'focussed', 'have', 'we', ',', 'presentation', 'of', 'simplicity', 'for', ',', 'far', 'so', '.', 'regulator', 'the', 'remove', 'to', 'straightforward', 'is', 'it', ',', 'section', 'in', 'as', '}$.', 'av', '^{\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'regularized', 'the', 'construct', 'can', 'one', '(),', 'in', '$', 'q_c', '$\\\\', 'of', 'place', 'in', 'these', 'using', '.', 'defined', '-', 'well', 'are', '}$', 'av', '^{\\\\', '_c', '}', 'q', '{', 'hat', '$\\\\', 'operators', 'averaged', 'the', '$,', 'mu', '$\\\\', 'measure', 'normalized', 'any', 'for', ',', 'thus', 'ee', '\\\\', ').', 'theta', '],\\\\', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '\\\\', ')', 'theta', '(\\\\', 'mu', '\\\\', 'theta', '\\\\', '6', '^', 'd', '}', 's', 'cal', '{\\\\', 'int_', '\\\\', '=\\\\', '])\\\\', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', '}', 'av', '^{\\\\', 'k', '\\\\', '}', 'det3', '{', 'label', '\\\\', 'be', '\\\\', 'where', 'ea', '\\\\', ',', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'k', '}^', 'e_k', ',', 'v', '{', 'j_', 'j', '}^', 'e_j', ',', 'v', '{', 'ij_', '}^', 'e_i', ',', 'v', '{', 'j_', '}\\\\,', 'ijk', '{', 'e_', '\\\\', '])\\\\,', 'e_k', '],[', 'e_j', '[', '],', 'e_i', '}([', 'av', 'rm', '^{\\\\', 'k', '\\\\', '}\\\\,', 'k', ',', 'j', ',', 'i', '{', 'sum_', '\\\\', '}\\\\,', '48', 'over', '\\\\', '1', '{', '&=&', '\\\\\\\\', 'nonumber', '\\\\', 'g', '\\\\', 'psi_', '\\\\', 'theta', '^\\\\', 'q_c', '\\\\', ')', 'theta', '(\\\\', 'mu', '\\\\', '\\\\,', 'theta', '\\\\', '6', '^', 'd', '}\\\\,', 's', 'cal', '{\\\\', 'int_', '\\\\', '&=&', 'g', '\\\\', 'psi_', '\\\\', '}\\\\,', 'av', '^{\\\\', 'q_c', '\\\\', '}', '1', '.', '4', '{', 'label', '\\\\', 'ba', '\\\\', ':', 'by', 'given', 'is', '$', 'theta', '^\\\\', 'q_c', '$\\\\', 'of', '}$', 'av', 'rm', '^{\\\\', 'q_c', '$\\\\', 'average', 'the', '$)', '1', '=', ')', 'theta', '(\\\\', 'mu', '\\\\', '\\\\,', 'theta', '\\\\', '6', '^', 'd', '}\\\\,', 's', 'cal', '{\\\\', 'int_', '$\\\\', 'satisfying', '.', 'e', '.', 'i', '(', ')$,', 'theta', '(\\\\', 'mu', '$\\\\', 'function', 'normalized', 'any', 'given', ',', 'now', '}$.', 's', 'cal', '${\\\\', 'on', 'measure', 'probability', 'suitable', 'a', 'to', 'respect', 'with', 'operators', 'these', 'average', 'to', 'wish', 'we', ')}$.', '1', '^{(', 'g', '\\\\', 'cyl_', '$\\\\', 'on', '}$', 'theta', '^{\\\\', 'q_c', '$\\\\', 'operator', 'an', 'obtain', 'we', '}$,', 's', 'cal', '{\\\\', 'in', '\\\\', 'theta', '$\\\\', 'each', 'for', ',', 'section', 'in', ')$', 'theta', '(\\\\', 'c', '$', 'by', '$', 'c', '$', 'replacing', '$.', 'v', '$', 'vertex', 'the', 'containing', 'partition', 'this', 'in', 'cell', 'the', ')$', 'theta', '(\\\\', 'c', '$', 'by', 'denote', '$.', 'r', '$', 'of', ')$', 'theta', '(\\\\', 'b', '$\\\\', 'partition', 'permissible', 'a', 'construct', 'again', 'can', 'we', ',', 'system', 'coordinate', 'this', 'using', '$).', 'r', '$', 'in', 'origin', 'fixed', 'some', 'around', '(', '$', 'a', '^', 'theta', '$\\\\', 'to', 'corresponding', ')$', '3', '^+(', 'gl', '$', 'of', 'element', 'an', 'of', 'action', 'the', 'by', 'first', 'the', 'from', 'obtained', ')$,', 'theta', '(\\\\', 'a', '^', 'x', '$', 'system', 'coordinate', 'second', 'a', 'obtain', 'we', '}$,', 's', 'cal', '{\\\\', 'in', '\\\\', 'a', '^', 'theta', '$\\\\', 'a', 'given', '$.', 'v', '$', 'containing', 'cell', 'the', '$', 'c', '$', 'by', 'denote', ',', 'before', 'as', ',', 'and', '$', 'g', '$\\\\', 'of', '$', 'v', '$', 'vertex', 'a', 'fix', '.', 'section', 'in', 'as', '$', 'r', '$', 'of', '$', 'b', '$\\\\', 'partition', 'permissible', ',', 'adapted', 'an', 'and', '$', 'r', '$', 'region', 'our', 'containing', '$', 's', '$\\\\', 'within', '$', 'u', '$', 'region', 'open', 'an', 'in', '$', 'a', '^', 'x', '$', 'system', 'coordinate', 'a', 'fix', '.', 'procedure', 'regularization', 'the', 'in', 'used', 'structures', 'background', 'the', 'of', 'memory', 'no', 'has', '.,', 'e', '.', 'i', ',', 'covariant', 'and', 'defined', '-', 'well', 'is', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'resulting', 'the', 'that', 'way', 'a', 'such', 'in', '}$', 's', 'cal', '${\\\\', 'space', 'the', 'over', '$', 'q_c', '$\\\\', 'operator', 'the', 'average', 'to', 'is', 'task', 'our', '$.', '6', ',', '...', ',', '1', '=', 'a', '$', 'with', ',', 'say', '$', 'a', '^', 'theta', '$\\\\', ',', 'coordinates', 'angular', 'six', 'by', 'coordinatized', 'and', '$', '2', '^', 's', 'times', '\\\\', '2', '^', 's', 'times', '\\\\', '2', '^', 's', '$', 'of', 'subset', 'open', 'an', 'with', 'identified', 'be', 'can', 'structures', 'background', \"'\", 'relevant', '`', 'of', '}$', 's', 'cal', '${\\\\', 'space', 'this', ',', 'topologically', '$.', 'diag', ')/\\\\', '3', '^+(', 'gl', '$', 'space', '-', 'coset', 'dimensional', 'finite', 'the', 'on', 'only', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', 'average', 'to', 'suffices', 'it', ',', 'dependence', 'background', 'the', 'of', 'rid', 'get', 'to', ',', 'hence', '.', 'unchanged', ']$', 'e_i', '[', 'a', '^', 'k', '$\\\\', 'each', 'leaves', 'hence', 'and', 'coordinates', 'the', 'scales', '-', 're', 'merely', ')$', '3', '^+(', 'gl', '$', 'of', '$', 'diag', '$\\\\', 'subgroup', 'diagonal', 'the', ',', 'furthermore', '$.', 'v', '$', 'at', 'transformations', 'linear', 'general', 'preserving', '-', 'orientation', 'of', 'group', 'the', ')$,', '3', '^+(', 'gl', '$', 'of', 'action', 'the', 'by', 'first', 'the', 'to', 'related', 'is', 'which', 'second', 'the', 'in', 'system', 'a', 'find', \"'.}\", 'zero', 'measure', 'of', 'sets', '`', 'ignore', 'us', 'lets', 'and', 'integration', 'involves', 'procedure', 'averaging', 'the', 'because', 'case', 'generic', 'the', 'on', 'focus', 'can', 'we', '{', 'footnote', '\\\\', 'generically', 'can', 'one', ',', 'first', 'the', 'to', 'belonging', 'system', 'coordinate', 'a', 'and', 'classes', 'equivalence', 'two', 'given', ',', 'then', '$.', 'v', '$', 'through', 'passing', '$', 'g', '$\\\\', 'of', 'edges', 'of', 'triplets', 'all', 'for', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', 'same', 'the', 'yield', 'they', 'if', 'equivalent', 'as', '$,', 'v', '$', 'at', 'centered', '$,', 'c', '$', 'in', 'systems', 'coordinate', 'two', 'regard', 'us', 'let', ',', 'this', 'see', 'to', '.', 'dimensional', 'finite', 'only', 'be', 'to', 'out', 'turns', 'averaging', 'for', 'freedom', \"'\", 'relevant', '`', 'the', ',', 'began', 'we', 'which', 'with', 'coordinates', 'background', 'the', 'of', 'choice', 'the', 'in', 'freedom', 'dimensional', '-', 'infinite', 'an', 'is', 'there', 'while', ',', 'therefore', '$.', 'v', '$', 'vertex', 'the', 'at', 'octants', 'coordinate', 'the', 'and', 'edges', 'three', 'the', 'between', 'relation', 'the', 'on', 'only', 'depends', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', 'that', 'note', '$.', 'v', '$', 'vertex', 'a', 'containing', '$', 'c', '$', 'cell', 'single', 'a', 'on', 'only', 'focus', 'first', 'us', 'let', ',', 'therefore', '$.', 'g', '$\\\\', 'of', 'vertex', 'a', 'containing', 'cells', 'with', 'associated', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', 'factors', 'the', 'through', 'only', 'appears', '(,)', 'operator', 'volume', 'regularized', 'the', 'of', 'limit', 'the', 'in', 'dependence', 'background', 'the', '.', 'operator', 'volume', 'desired', 'the', 'at', 'arrive', 'to', '-', 'and', 'sections', 'the', 'of', 'results', 'collect', 'we', ',', 'part', 'forth', 'the', 'in', ',', 'finally', '.', 'procedure', 'averaging', 'the', 'for', 'needed', 'are', 'that', 'measures', 'certain', 'of', 'existence', 'the', 'establish', 'we', ',', 'third', 'the', 'in', '.', 'constant', 'multiplicative', 'a', 'to', 'up', 'uniquely', '---', 'operator', 'volume', 'final', 'the', 'of', 'also', 'hence', 'and', '---', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'av', '^\\\\', 'k', '$\\\\', 'quantity', 'averaged', 'the', 'of', 'form', 'the', 'fix', 'procedure', 'regularization', 'the', 'on', 'requirement', 'consistency', 'the', 'and', 'operator', 'volume', 'final', 'the', 'of', 'symmetries', 'desired', 'the', 'that', 'show', 'we', ',', 'second', 'the', 'in', '.', 'strategy', 'basic', 'the', 'out', 'spell', 'we', ',', 'first', 'the', 'in', '.', 'parts', 'four', 'to', 'in', 'divided', 'is', 'discussion', 'our', '.', 'limit', 'the', 'take', 'then', 'and', '(,),', 'in', '$', 'q_c', '$\\\\', 'of', 'place', 'in', '}$', 'av', '^{\\\\', 'q_c', '$\\\\', 'operator', 'resulting', 'the', 'use', ',', 'structures', 'background', 'relevant', 'the', 'over', '$', 'q_c', '$\\\\', 'average', 'appropriately', 'to', 'need', 'we', ',', 'dependence', 'background', 'the', 'remove', 'to', '.', 'section', 'next', 'the', 'in', 'obtain', 'will', 'we', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'final', 'the', 'by', 'shared', 'therefore', 'are', 'and', 'averaging', 'by', 'preserved', 'trivially', 'are', 'properties', 'these', 'that', 'see', 'will', 'we', '$.', 'g', '\\\\', 'cyl_', '$\\\\', 'in', 'states', 'all', 'annihilates', '$', 'q_c', '$\\\\', 'operator', 'regularized', 'the', 'of', 'limit', 'the', ',', 'vertices', '.}', 'section', 'see', '.', 'vanishes', 'also', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'in', 'states', 'invariant', 'gauge', 'all', 'on', 'operator', 'limiting', 'the', 'of', 'action', 'the', 'that', 'shows', 'algebra', 'simple', ',', 'vertices', 'valent', '-', 'tri', ')', 'most', 'at', '(', 'has', '$', 'g', '$\\\\', 'if', '{', 'footnote', '\\\\', '%', 'valent', '-', 'bi', 'only', 'has', 'graph', 'a', 'if', ',', 'therefore', 'particular', 'in', '.', 'arguments', 'three', 'its', 'in', 'symmetric', '-', 'anti', 'totally', 'is', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', ')$]', '2', '[$(', 'item', '\\\\', ',', 'and', ';', 'edges', 'the', 'of', 'germs', 'the', 'on', 'only', 'depends', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', ')$]', '1', '[$(', 'item', '\\\\', ':', 'have', 'we', ',', 'procedure', 'regularization', 'the', 'in', 'used', 'partitions', 'permissible', 'of', 'choice', 'the', 'of', 'irrespective', '.', 'inspection', 'by', 'follow', 'which', '()', 'operator', 'limiting', 'the', 'of', 'properties', 'two', 'note', 'us', 'let', ',', 'section', '-', 'sub', 'this', 'conclude', 'to', '.', 'section', 'next', 'the', 'in', 'averaging', 'this', 'out', 'carry', 'will', 'we', '.', 'structures', 'background', 'relevant', 'over', 'operator', 'regularized', 'the', \"'\", 'averaging', '`', 'suitably', 'by', 'it', 'eliminate', 'can', 'one', ',', 'type', 'simple', 'rather', 'a', 'of', 'is', 'dependence', 'background', 'the', 'since', ',', 'however', '.', 'operator', 'volume', 'the', 'for', 'candidate', 'viable', 'a', 'to', 'lead', 'not', 'does', 'it', ',', 'defined', '-', 'well', 'is', '()', 'of', ')}$', 'b', '^{(\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'the', 'of', 'limit', 'the', 'although', ',', 'hence', '.', 'procedure', 'regularization', 'the', 'in', 'used', 'structure', 'background', 'the', 'on', '.,', 'e', '.', 'i', '])$,', 'e_k', '[', '],', 'e_j', '[', '],', 'e_i', '([', 'k', '$\\\\', 'term', 'the', 'through', 'partitions', 'of', 'choice', 'our', 'of', 'memory', 'a', 'carries', '()', 'operator', 'limiting', 'this', ',', 'however', ',', 'unfortunately', '$.', 'g', '$\\\\', 'for', 'that', 'with', 'coincides', \"'$\", 'g', '$\\\\', 'using', ')}$', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'in', 'derived', 'operator', 'volume', 'resulting', 'the', 'therefore', '.', 'identically', 'vanishes', '$', 'q_c', '$\\\\', 'operator', 'the', ',', 'vertex', 'valent', '-', 'bi', 'a', 'for', ',', 'however', \"'$.\", 'g', '$\\\\', 'of', 'vertices', 'of', 'set', 'the', 'in', 'missing', 'be', 'may', '$', 'g', '$\\\\', 'of', 'vertices', 'valent', '-', 'bi', 'some', 'or', '/', 'and', 'vertices', 'valent', '-', 'bi', 'extra', 'some', 'have', 'may', \"'$\", 'g', '$\\\\', 'that', 'is', 'difference', 'only', 'the', '$,', 'g', '$\\\\', 'of', 'that', 'as', 'same', 'the', 'is', 'range', 'whose', \"'$\", 'g', '$\\\\', 'graph', 'different', 'a', 'construction', 'above', 'the', 'in', 'used', 'we', ')}$', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'space', 'the', 'given', 'if', ',', 'now', '$.', 'g', '\\\\', 'cyl_', '$\\\\', 'completing', 'cauchy', 'by', 'obtained', '$', 'g', '\\\\', 'h_', '$', 'space', 'hilbert', 'the', 'on', 'adjoint', '-', 'self', 'and', 'defined', '-', 'well', 'is', 'operator', 'limiting', 'the', 'that', 'show', 'can', 'one', ',', 'section', '-', 'sub', 'last', 'the', 'in', 'used', 'arguments', 'the', 'using', '.)', 'octants', 'opposite', 'or', 'same', 'the', 'in', 'lie', '$', 'e_k', ',', 'e_j', ',', 'e_i', '$', 'edges', 'the', 'of', 'two', 'any', 'if', 'vanishes', '])$', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '$\\\\', ',', 'particular', 'in', '(', 'ee', '\\\\', ']).', 'e_k', '([', 'c', '^', 'k', '\\\\', '])', 'e_j', '([', 'b', '^', 'k', '])\\\\', 'e_i', '([', 'a', '^', 'k', '}\\\\', 'abc', '{', 'e_', '\\\\', '\\\\,:=\\\\,', '])', 'e_k', '],[', 'e_j', '],[', 'e_i', '([', 'k', '\\\\', '}', 'det2', '{', 'label', '\\\\', 'be', '\\\\', 'where', 'and', '$', 'v', '$', 'through', 'passing', 'edges', 'the', 'over', 'is', 'sum', 'the', 'where', 'ee', '\\\\', ',', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'k', '}^', 'e_k', ',', 'v', '{', 'j_', 'j', '}^', 'e_j', ',', 'v', '{', 'ij_', '}^', 'e_i', ',', 'v', '{', 'j_', '}\\\\,', 'ijk', '{', 'e_', '\\\\', '])\\\\,', 'e_k', '],[', 'e_j', '[', '],', 'e_i', '([', 'k', '\\\\', '}\\\\,', 'k', ',', 'j', ',', 'i', '{', 'sum_', '\\\\', '}\\\\,', '48', 'over', '\\\\', '1', '{', '=', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'q_c', '\\\\', '}', '0', 'rightarrow', '\\\\', 'e', '{\\\\', 'lim_', '\\\\', '}', 'hq42', '{', 'label', '\\\\', 'be', '\\\\', '$:', 'v', '$', 'to', '$', 'c', '$', 'cell', 'the', 'shrink', 'and', 'partition', 'the', 'refine', 'we', 'as', 'unchanged', 'is', 'it', ',', 'hence', '$.', 'v', '$', 'at', 'surfaces', 'these', 'of', 'properties', 'the', 'through', 'only', '$', 's_a', '$', 'surfaces', '-', 'two', 'three', 'the', 'on', 'depends', '$', 'q_c', '$\\\\', 'operator', 'the', 'of', 'action', 'the', '$.', 'v', '$', 'vertex', 'a', 'contains', '$', 'c', '$', 'which', 'in', 'case', 'trivial', '-', 'non', 'the', 'on', 'focus', 'now', 'us', 'let', '().', 'and', '()', 'to', '()', 'reducing', 'by', 'calculation', 'the', 'streamlined', 'have', 'partitions', 'permissible', 'on', 'conditions', 'the', ',', 'summarize', 'to', '$.', 'e_i', '$', 'edge', 'the', 'contains', 'which', ')$', 's_3', ',', 's_2', ',', 's_1', '$(', 'surfaces', '-', 'two', 'the', 'by', 'defined', 'octants', 'the', 'on', 'only', 'depend', 'and', '$', '1', 'pm', '\\\\', ',', '0', '$', 'are', 'vectors', 'these', 'of', \"'\", 'components', '`', 'possible', 'the', \"'.\", 'vectors', '`', 'as', ']$', 'e_i', '[', 'a', '^', 'k', '$\\\\', 'to', 'refer', 'will', 'we', ',', 'simplicity', 'for', '$.', 'v', '$', 'vertex', 'the', 'through', 'passing', '$', 'g', '$\\\\', 'of', 'edges', 'the', 'label', '$', 'k', ',', 'j', ',', 'i', '$', 'where', 'ee', '\\\\', ',', '\\\\,', 'g', '\\\\', 'psi_', '\\\\', '\\\\,', 'k', '}^', 'e_k', ',', 'v', '{', 'j_', 'j', '}^', 'e_j', ',', 'v', '{', 'ij_', '}^', 'e_i', ',', 'v', '{', 'j_', '])', 'e_k', '([', 'c', '^', 'k', '])\\\\', 'e_j', '([', 'b', '^', 'k', '])\\\\', 'e_i', '([', 'a', '^', 'k', '\\\\', '}\\\\,', 'abc', '{', 'e_', '}\\\\', 'ijk', '{', 'e_', '\\\\', '}\\\\,', 'k', ',', 'j', ',', 'i', '{', 'sum_', '}\\\\,\\\\', '48', 'over', '\\\\', '1', '{', '=\\\\', 'g', '\\\\', 'psi_', '}\\\\,\\\\', 'c', '{', 'q_', '\\\\', '}', 'hq3', '{', 'label', '\\\\', 'be', '\\\\', ':', 'implies', 'partition', 'the', 'on', ')$', 'ii', '$(', 'condition', 'and', '()', 'then', '$,', 'v', '$', 'say', ',', 'vertex', 'a', 'contain', 'does', '$', 'c', '$', 'cell', 'the', 'if', 'ee', '\\\\', '0', '\\\\', '=', '\\\\', 'g', '\\\\', 'psi_', '\\\\', '}\\\\,', 'c', '{', 'q_', '\\\\', '}', 'hq2', '{', 'label', '\\\\', 'be', '\\\\', 'to', 'reduces', '()', '}$,', 'abc', '{', 'eta_', '$\\\\', 'by', 'forced', 'symmetrization', '-', 'anti', 'to', 'due', ',', 'partition', 'the', 'on', ')$', 'iii', '$(', 'condition', 'by', 'then', ',', 'vertex', 'a', 'contain', 'not', 'does', 'it', 'if', '.', 'all', 'at', 'vertex', 'no', 'or', '$', 'g', '$\\\\', 'of', 'vertex', 'one', 'contains', 'either', '$', 'c', '$', 'cell', 'a', ',', 'partition', 'the', 'on', 'condition', 'first', 'the', 'of', 'because', 'that', 'note', ')}$.', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'in', \"'}$\", 'g', '{\\\\', 'psi_', '$\\\\', 'element', 'an', 'on', '}$', 'c', '{', 'q_', '$\\\\', 'operator', 'the', 'of', 'action', 'the', 'evaluate', 'and', 'conditions', 'these', 'satisfies', '$', 'b', '$\\\\', 'partition', 'the', 'that', 'suppose', 'now', 'us', 'let', '.', 'exist', 'to', 'fails', 'limit', 'the', 'general', 'in', ',', 'arbitrarily', 'taken', 'are', 'refinements', 'if', ';', 'defined', '-', 'well', 'is', 'operator', 'limiting', 'the', 'that', 'ensure', 'they', ',', 'see', 'will', 'we', 'as', '.', 'partitions', 'allowed', 'the', 'restrict', 'do', 'conditions', 'these', ',', 'nonetheless', '.', 'them', 'satisfy', 'automatically', 'procedure', 'limiting', 'the', 'in', 'needed', 'refinements', 'subsequent', ',', 'achieved', 'is', 'conditions', 'two', 'these', 'satisfying', 'refinement', 'a', 'once', ',', 'furthermore', '.', 'partition', 'that', 'of', 'refinement', 'permissible', 'a', 'by', 'satisfied', '.}', 'negligible', 'are', 'result', 'final', 'the', 'to', 'partitions', 'generic', '-', 'non', 'such', 'from', 'contributions', ',', 'section', 'of', 'procedure', 'averaging', 'the', 'of', 'because', '.', 'presentation', 'of', 'simplicity', 'for', 'only', 'imposed', 'is', 'restriction', 'this', ',', 'however', '$.', 'b', '$\\\\', 'partition', 'the', 'construct', 'to', 'used', 'systems', 'coordinate', 'permissible', 'the', 'on', 'restriction', 'mild', 'a', 'impose', 'does', 'cell', 'any', 'in', '$', 's_a', '$', 'surfaces', 'the', 'in', 'lie', 'to', 'allowed', 'not', 'are', 'edges', 'the', 'that', 'fact', 'the', '{', 'footnote', '\\\\', '%', 'generically', 'be', 'can', 'conditions', 'third', 'and', 'second', 'the', ',', 'condition', 'first', 'the', 'satisfying', 'partition', 'a', 'given', ').', 'vertices', 'containing', 'cells', 'within', '(', 'appropriately', '$', 's_a', '$', 'surfaces', 'the', 'choosing', 'by', 'simply', 'met', 'be', 'can', 'condition', 'first', 'the', ',', 'cells', 'the', 'of', 'walls', 'the', 'on', 'lie', 'not', 'do', '$', 'g', '$\\\\', 'graph', 'the', 'of', 'vertices', 'the', 'which', 'in', '$', 'b', '$\\\\', 'partition', 'any', 'given', '.', 'meet', 'to', 'easy', 'quite', 'are', 'requirements', 'these', '.', 'points', 'two', 'at', 'most', 'at', '$', 'g', '$\\\\', 'intersects', '$', 'c', '$', 'to', '$', 'b', '$\\\\', 'by', 'associated', '$', 's_a', '$', 'surfaces', 'of', 'triplet', 'the', 'then', ',', 'vertices', 'the', 'of', 'any', 'contain', 'not', 'does', '$', 'c', '$', 'cell', 'a', 'if', ')$]', 'iii', '[$(', 'item', '\\\\', ',', 'and', '$;', 'g', '$\\\\', 'of', 'range', 'the', 'and', '$', 'c', '$', 'to', 'associated', '$', 's_a', '$', 'surfaces', '-', 'two', 'three', 'the', 'of', 'union', 'the', 'between', 'point', 'intersection', 'isolated', 'unique', 'the', 'is', '$', 'v', '$', 'then', '$,', 'v', '$', 'say', ',', 'vertex', 'a', 'contain', 'does', '$', 'c', '$', 'cell', 'a', 'if', ')$]', 'ii', '[$(', 'item', '\\\\', '$;', 'b', '$\\\\', 'partition', 'the', 'by', '$', 'c', '$', 'to', 'assigned', '$', 's_3', ',', 's_2', ',', 's_1', '$', 'surfaces', '-', 'two', 'of', 'triplet', 'the', 'of', 'point', 'intersection', 'the', 'with', 'coincides', 'and', '$,', 'c', '$', 'say', ',', 'cells', 'the', 'of', 'one', 'of', 'interior', 'the', 'in', 'contained', 'is', '$)', 'r', '$', 'within', '(', '$', 'g', '$\\\\', 'graph', 'the', 'of', 'vertex', 'every', ')$]', 'i', '[$(', 'item', '\\\\', '):', '2', '.', 'fig', 'see', '(', 'conditions', 'three', 'following', 'the', 'satisfy', '$', 'b', '$\\\\', 'partitions', 'permissible', 'the', '$)', 'e', '$\\\\', 'small', 'sufficiently', 'for', '(', 'that', 'assume', 'will', 'we', ',', 'precisely', 'more', '$.', 'g', '$\\\\', 'graph', 'the', 'on', 'depend', 'will', '$', 'r', '$', 'region', 'the', 'of', 'partition', 'the', 'of', 'refinements', 'allowed', 'the', ')}$.', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'on', 'focus', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'fix', '.', 'step', 'first', 'the', 'with', 'begin', 'then', 'us', 'let', '$.', 'h', '$\\\\', 'on', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'defined', '-', 'well', 'a', 'constitute', 'together', '.,', 'e', '.', 'i', ',', 'sense', 'appropriate', 'the', 'in', 'compatible', 'are', 'they', 'that', 'verify', 'will', 'we', ',', 'finally', '$.', 'g', '\\\\', 'cyl_', '$\\\\', 'various', 'on', 'operators', 'of', 'family', 'a', 'obtain', 'thus', 'will', 'we', '$,', 'g', '$\\\\', 'varying', 'by', '$.', 'g', '$\\\\', 'on', 'based', 'functions', 'cylindrical', 'the', 'of', '$', 'g', '\\\\', 'cyl_', '$\\\\', 'space', 'the', 'preserve', 'fact', 'in', 'will', 'operators', 'the', ',', 'moreover', '$.', 'g', '$\\\\', 'as', 'range', 'same', 'the', 'has', 'which', \"'$\", 'g', '$\\\\', 'graph', 'another', 'choose', 'we', 'if', 'unchanged', 'stay', 'will', 'operators', 'the', 'that', 'see', 'will', 'we', ',', 'however', '$.', 'g', '$\\\\', 'use', 'will', 'we', 'that', 'for', '}$.', 'b', '^{\\\\', 'v_r', '$', 'from', ')}$', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'on', '$', 'g', '^\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'the', 'obtain', 'to', 'removed', 'be', 'to', 'is', 'regulator', 'the', 'how', 'specify', 'and', ')}$', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'on', 'just', 'focus', 'meaningfully', 'can', 'we', ',', 'hence', '.', 'invariant', 'subspace', 'this', 'leave', '}$', 'b', '^{\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'and', '$', 'q_c', '$\\\\', 'operators', 'regulated', 'the', '$.', 'g', '$\\\\', 'of', 'range', 'the', 'with', 'coincides', 'range', 'whose', \"'$\", 'g', '$\\\\', 'graph', 'a', 'to', 'respect', 'with', 'cylindrical', 'are', 'which', \"'}$\", 'g', '{\\\\', 'psi_', '$\\\\', 'states', 'all', 'of', 'consisting', '$', 'cyl', '$\\\\', 'of', ')}$', 'g', '(\\\\', 'r', '{', 'cyl_', '$\\\\', 'subspace', 'the', 'consider', 'and', '$', 'g', '$\\\\', 'graph', 'a', 'fix', 'will', 'we', ',', 'first', '.', 'follows', 'as', 'proceed', 'will', 'we', ',', 'theory', 'quantum', 'the', 'in', 'regulator', 'the', 'remove', 'to', '.', 'unmentioned', 'go', 'often', 'involved', 'restrictions', 'the', 'that', \"'\", 'natural', '`', 'so', 'seem', 'strategies', 'these', 'of', 'some', ',', 'indeed', '.', 'question', 'in', 'loop', 'wilson', 'the', 'to', 'tailored', 'often', 'is', 'lattices', 'these', 'of', 'refinement', 'the', 'and', 'lattices', 'rectangular', 'allows', 'only', 'one', ',', 'limit', 'continuum', 'the', 'in', 'loops', 'wilson', 'of', 'values', 'expectation', 'compute', 'to', ',', 'lattices', 'on', 'based', 'theories', 'gauge', 'in', ',', 'similarly', '.', 'constant', 'theory', 'the', 'of', 'parameters', 'and', 'offs', '-', 'cut', 'of', 'ratios', 'certain', 'keeping', 'limits', 'take', 'or', '/', 'and', 'order', 'specific', 'a', 'in', 'regulators', 'the', 'remove', 'to', 'has', 'generally', 'one', 'dimensions', 'low', 'in', 'theories', 'field', 'scalar', 'interacting', 'in', ',', 'example', 'for', '.', 'theory', 'field', 'quantum', 'in', 'place', '-', 'common', 'a', 'are', 'subtleties', 'such', 'that', 'however', 'note', '.', 'zero', 'to', 'tends', '$', 'e', '$\\\\', 'as', 'refined', 'be', 'to', 'is', '$', 'b', '$\\\\', 'partition', 'the', 'how', 'on', 'restrictions', 'appropriate', 'specifying', 'by', 'procedure', 'limiting', 'the', \"'\", 'line', '-', 'stream', '`', 'to', 'has', 'one', 'now', ',', 'precisely', 'more', '.', 'subtleties', 'certain', 'involves', 'procedure', 'limiting', 'the', ',', 'hand', 'other', 'the', 'on', ',', 'theory', 'quantum', 'the', 'in', ')$.', 'e', '(', 'v_r', '\\\\,', 'rightarrow', '\\\\', ')\\\\,', 'e', '}(', 'e', '\\\\', 'b_', '^{\\\\', 'v_r', '$', 'have', 'we', '$,', '0', 'rightarrow', '\\\\', 'e', '$\\\\', 'limit', 'the', 'in', ';', 'fashion', 'smooth', 'any', 'in', 'shrink', '$', 'c', '$', 'cells', 'the', 'let', 'and', '$', 'b', '$\\\\', 'partition', 'any', 'with', 'begin', 'can', 'we', '.', 'regulator', 'the', 'remove', 'to', 'straightforward', 'is', 'it', ',', 'theory', 'classical', 'the', 'in', '$.', 'r', '$', 'region', 'the', 'of', '$', 'b', '$\\\\', 'partition', 'of', 'choice', 'our', 'on', 'depends', 'it', '}$.', 'b', '^{\\\\', 'v_r', '$', 'functional', 'volume', 'approximate', 'the', 'of', 'analog', 'quantum', 'the', 'is', 'this', '.', 'operator', 'adjoint', '-', 'self', 'negative', '-', 'non', 'a', 'is', '}$', 'b', '^{\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', ',', 'construction', 'by', 'ee', '\\\\', '}.', '2', 'over', '\\\\', '1', '|^{', 'q_c', '|\\\\', 'sum_c', '\\\\', '}\\\\:=\\\\', 'b', '^{\\\\', '_r', '}', 'v', '{', 'hat', '\\\\', '}', 'hv1', '{', 'label', '\\\\', 'be', '\\\\', ':', 'via', 'operator', 'volume', 'regulated', 'defined', '-', 'well', 'a', 'and', 'extension', 'adjoint', '-', 'self', 'its', 'take', 'can', 'we', ',', 'hence', '.', 'functions', 'cylindrical', '$', '3', '^', 'c', '$', 'of', ')}$', '3', '^{(', 'cyl', '$\\\\', 'domain', 'the', 'on', 'operator', 'adjoint', '-', 'self', 'essentially', 'an', 'therefore', 'is', '()', 'of', 'side', 'right', 'the', 'that', 'verify', 'to', 'easy', 'is', 'it', '.', 'operators', 'adjoint', '-', 'self', 'essentially', 'commuting', 'of', 'products', 'only', 'contains', 'sum', 'the', ',', 'hence', '.', 'commute', 'operators', 'these', '.', 'edges', 'distinct', 'with', 'associated', 'operators', 'contain', '()', 'of', 'side', 'right', 'the', 'on', 'products', 'the', ',', 'therefore', '$.', '0', '])=', 'e_3', '([', 'c', '^', 'k', '\\\\', '])', 'e_2', '([', 'b', '^', 'k', '])\\\\', 'e_1', '([', 'a', '^', 'k', '}\\\\', 'abc', '{', 'eta_', '$\\\\', 'have', 'we', ']$,', 'e_2', ']=[', 'e_1', '$[', 'whenever', ',', 'furthermore', '.', 'operator', 'adjoint', '-', 'self', 'essentially', 'an', 'is', '}$', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', 'each', 'that', 'know', 'we', ',', 'now', '.', 'operator', 'adjoint', '-', 'self', 'a', 'is', '}$', 'c', '{', 'q_', '$\\\\', 'that', 'show', 'to', 'necessary', 'is', 'it', ',', 'this', 'for', '}$.', 'c', '{', 'q_', '$\\\\', 'of', 'root', '-', 'square', 'and', 'value', 'absolute', 'the', 'take', 'to', 'need', 'we', ')}$,', 'b', '^{(\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'regulated', 'the', 'define', 'to', '.', 'terms', 'zero', '-', 'non', 'of', 'number', 'finite', 'a', 'only', 'has', 'result', 'the', 'because', 'defined', '-', 'well', 'is', 'functions', 'cylindrical', 'on', 'operator', 'this', 'of', 'action', 'the', ',', 'involved', 'are', 'sums', 'infinite', 'although', ',', 'section', 'in', 'as', '$.', '3', ',', '2', ',', '1', '=', 'r', '$', '$,', 'x_r', '$', 'at', 'starting', 'germs', 'od', 'set', 'the', 'through', 'runs', ']$', 'e_r', '$[', 'where', 'and', 'ee', '\\\\', ']),', 'e', '}([', 's_d', '{', 'k_', ']):=\\\\', 'e', '([', 'd', '^', 'k', '\\\\', '}', 'det1', '{', 'label', '\\\\', 'be', '\\\\', 'denoted', 'we', 'where', 'ea', '\\\\', '},', 'e_3', ',', 'x_3', '{', 'k_', '^', 'j', '}', 'e_2', ',', 'x_2', '{', 'j_', '^', 'j', '}', 'e_1', ',', 'x_1', '{', 'i_', '^', 'j', '])\\\\,', 'e_3', '([', 'c', '^', 'k', '])\\\\', 'e_2', '([', 'b', '^', 'k', '])\\\\', 'e_1', '([', 'a', '^', 'k', '\\\\', ']}', 'e_3', '],[', 'e_2', '],[', 'e_1', '{[', 'sum_', '}\\\\', 's_c', 'in', '\\\\', 'x_3', '{', 'sum_', '\\\\', '}', 's_b', 'in', '\\\\', 'x_2', '{', 'sum_', '}\\\\', 's_a', 'in', '\\\\', 'x_1', '{', 'sum_', '}\\\\', 'abc', '{', 'eta_', '}\\\\', 'ijk', '{', 'e_', '}\\\\', '48', 'over', '\\\\', '1', '{', '\\\\,', '&=&', '\\\\\\\\', 'nonumber', '\\\\', '}', 's_c', '{', 'k_', '^', 'e', '}\\\\', 's_b', '{', 'j_', '^', 'e', '}\\\\', 's_a', '{', 'i_', '^', 'e', '\\\\', '}', 'abc', '{', 'eta_', '\\\\', '}', 'ijk', '{', 'e_', '\\\\', '!}', '3', 'over', '\\\\', '1', '{', '&=&\\\\,', '}\\\\,', 'c', '{', 'q_', '\\\\', '}', 'hq1', '{', 'label', '\\\\', 'ba', '\\\\', ':', 'by', 'simply', 'given', 'is', '()', 'to', 'corresponding', '$', 'q_c', '$\\\\', 'operator', 'the', '.', 'operator', 'volume', 'regulated', 'the', 'define', 'to', 'straightforward', 'is', 'it', '()),', 'see', '(', 'these', 'of', '}$', 's', '{', 'i_', '^', 'e', '$\\\\', 'analogs', 'quantum', 'the', 'have', 'already', 'we', 'since', '.', 'triads', 'smeared', ')', 'dimensionally', '-', 'two', '(', 'through', 'only', 'variables', 'space', 'phase', 'classical', 'the', 'on', 'depends', '()', 'of', '}$', 'b', '^{\\\\', 'v_r', '$', 'volume', 'regulated', 'the', '.', 'vertices', 'surrounding', 'cells', 'of', 'boundaries', 'the', 'on', 'registered', 'be', 'can', 'which', 'structure', 'extrinsic', 'the', 'to', 'only', 'sensitive', 'is', 'operator', 'quantum', 'resulting', 'the', 'whence', 'cell', 'any', 'inside', 'happens', 'what', 'of', 'details', 'the', 'on', 'depend', 'not', 'does', 'expression', 'this', '.', 'cells', 'of', 'boundary', 'the', 'on', 'smeared', 'triads', 'of', 'terms', 'in', 'expressed', 'is', 'functional', 'volume', 'regulated', 'the', 'where', 'regularization', \"'\", 'external', '`', 'an', 'discuss', 'we', ',', 'appendix', 'the', 'in', '.', 'vertices', 'at', 'graph', 'the', 'of', 'structure', 'intrinsic', 'the', 'to', '.', 'e', '.', 'i', ',', 'graphs', 'of', 'vertices', 'at', 'edges', 'the', 'to', 'vectors', 'tangent', 'between', 'relation', 'the', 'to', 'sensitive', 'be', 'to', 'out', 'turn', 'will', 'operator', 'final', 'the', ',', 'result', 'a', 'as', ').', 'section', 'in', ')$', 'i', '$', 'condition', 'the', 'see', '(', 'cells', 'of', 'interior', 'the', 'through', 'passing', 'surfaces', 'two', 'over', 'smeared', 'are', 'which', 'triads', 'of', 'terms', 'in', 'expressed', 'is', 'functional', 'volume', 'regulated', 'the', 'because', \"'\", 'internal', '`', 'called', 'is', 'regularization', 'this', '.', 'theory', 'quantum', 'the', 'in', 'role', 'important', 'an', 'plays', 'it', 'that', 'section', 'in', 'see', 'will', 'we', ',', 'however', '.', 'theory', 'classical', 'the', 'in', 'unnecessary', 'course', 'of', 'is', 'averaging', ',', 'procedure', 'regularization', 'the', 'in', 'steps', 'other', 'all', 'like', '$.', '0', '\\\\', 'rightarrow', '\\\\', 'e', '$\\\\', 'as', ')$', 'e', '(', 'v_r', '\\\\,', 'rightarrow', '\\\\', ']\\\\,', 'e', '[', '}', 'av', '^{\\\\', 'v_r', '$', ',', 'then', 'ea', '\\\\', ']|}.', 'e', '}[', 'av', '}^{\\\\', 'c', '{', 'q_', '{|', 'sqrt', '}\\\\', 'c', '\\\\', 'in', '\\\\', 'c', '{', 'sum_', '\\\\', '&:=&', ']', 'e', '}[', 'av', '}^{\\\\', 'r', '{', 'v_', '\\\\\\\\', 'nonumber', '\\\\', '}', 'theta', '^{\\\\', 'q_c', ')', 'theta', '(\\\\', 'mu', '\\\\', ')', 'theta', '(\\\\', 'n', '^', 'd', '}', 's', 'cal', '{\\\\', 'int_', '\\\\', '&:=&', ']', 'e', '[', '}', 'av', '}^{\\\\', 'c', '{', 'q_', '}', 'qav', '{', 'label', '\\\\', 'ba', '\\\\', 'set', '$),', '1', '=', ')', 'theta', '(\\\\', 'mu', '\\\\', 'theta', '\\\\', 'n', '^', 'd', '}', 's', 'cal', '{\\\\', 'int_', '$\\\\', '.,', 'e', '.', 'i', '(', '}$,', 's', 'cal', '${\\\\', 'on', ')$', 'theta', '(\\\\', 'mu', '$\\\\', 'function', 'normalized', 'a', 'given', '.', 'follows', 'as', 'procedure', 'averaging', ')', 'trivial', 'rather', '(', 'a', 'introduce', 'can', 'we', ',', 'then', '$.', 'theta', '$\\\\', 'in', 'uniform', 'is', 'convergence', 'the', 'that', 'such', 'is', 'systems', 'coordinate', 'of', 'family', 'the', 'that', 'assume', 'us', 'let', '$.', '0', '\\\\', 'rightarrow', '\\\\', 'e', '$\\\\', 'as', ')$', 'e', '(', 'v_r', '\\\\,', 'rightarrow', '\\\\', ']\\\\,', 'e', ')}[', 'theta', '}(\\\\', 'e', '{\\\\', 'b_', '^{\\\\', 'v_r', '$', 'that', 'such', ']$', 'e', ')}[', 'theta', '}(\\\\', 'e', '{\\\\', 'b_', '^{\\\\', 'v_r', '$', 'obtain', 'we', '$,', 'theta', '$\\\\', 'each', 'for', ']$.', 'e', ')}[', 'theta', '(\\\\', 'e', '\\\\', 'b_', '^{\\\\', 'v_r', '$', 'and', ']$', 'e', '}[', 'theta', '^{\\\\', 'q_c', '$', ',', 'triads', 'of', 'functionals', 'regulated', 'of', 'families', 'parameter', '$', 'n', '$', 'obtain', 'we', ',', 'above', 'given', 'steps', 'repeating', ',', 'then', '$.', 'a', '^', 'theta', '$\\\\', 'say', ',', 'parameters', '$', 'n', '$', 'by', '}$', 's', 'cal', '${\\\\', 'of', 'points', 'the', 'label', 'us', 'let', '.)', 'general', '}$', 's', 'cal', '${\\\\', 'keep', 'can', 'we', ',', 'however', ',', 'theory', 'classical', 'the', 'in', '}$.', 's', 'cal', '${\\\\', 'specific', 'a', 'to', 'led', 'is', 'one', ',', 'theory', 'quantum', 'in', ',', 'section', 'in', 'see', 'will', 'we', 'as', '(', '$.', 'a', '^', 'x', '$', 'to', 'related', 'smoothly', 'and', 'containing', ',', 'systems', 'coordinate', 'of', 'family', 'parameter', '$-', 'n', '$', 'an', 'denote', '}$', 's', 'cal', '${\\\\', 'let', '.', 'perspective', 'classical', 'a', 'from', 'procedure', 'this', 'justifying', 'by', 'section', '-', 'sub', 'this', 'conclude', 'will', 'we', '.', 'procedure', \"'\", 'averaging', '`', 'certain', 'a', 'introduce', 'to', 'have', 'will', 'we', ',', 'particular', 'in', '.', 'subtle', 'more', 'much', 'be', 'however', 'will', 'regulators', 'of', 'removal', 'the', '$.', 'q_c', '$\\\\', 'operators', 'quantum', 'regulated', 'construct', 'to', 'able', 'be', 'will', 'we', 'section', '-', 'sub', 'next', 'the', 'in', ',', 'triads', 'smeared', 'to', 'corresponding', 'operators', 'quantum', 'the', 'have', 'already', 'we', 'since', '.', 'triads', 'smeared', 'dimensionally', '-', 'two', 'the', 'of', 'terms', 'in', 'expressed', 'be', 'can', ')$', 'e', '(', 'v_r', '$', 'function', 'space', 'phase', 'the', ',', 'theory', 'classical', 'the', 'in', ',', 'thus', '$$', '.', '0', '\\\\', 'rightarrow', '\\\\', 'e', '\\\\', '\\\\', '\\\\', '}\\\\', 'as', 'rm', '{\\\\', '\\\\', '\\\\', '\\\\', ')', 'e', '(', 'v_r', '\\\\,', 'rightarrow', '\\\\', ']\\\\,', 'e', '}[', 'e', '\\\\', 'b_', '^{\\\\', 'v_r', '$$', ':', 'have', 'we', '$', 'e', '$', 'triad', 'every', 'for', 'then', ',', 'above', 'as', '$', 'e', '\\\\', 'b_', '$\\\\', 'partition', 'a', 'fix', 'we', '$', 'e', '$\\\\', 'each', 'for', 'and', ')', 'cell', 'every', 'for', '$', 'e', '\\\\', '<\\\\', '\\\\', 'l_c', '$', '.,', 'e', '.', 'i', '(', '$', 'e', '$\\\\', 'by', 'above', 'from', 'bounded', 'is', '$', 'l_c', '$', '$', '0', '>', 'e', '$\\\\', 'some', 'for', 'that', 'assume', 'we', 'if', ',', 'indeed', 'ee', '\\\\', ']|}.', 'e', '}[', 'c', '{', 'q_', '{|', 'sqrt', '}\\\\', 'c', '\\\\', 'in', '\\\\', 'c', '{', 'sum_', '\\\\', ':=\\\\', ']\\\\', 'e', '}[', 'b', '^{\\\\', 'v_r', '}', 'apprvol', '{', 'label', '\\\\', 'be', '\\\\', '$', 'b', '$\\\\', 'partition', 'the', 'with', 'associated', '$,', 'r', '$', 'region', 'the', 'of', 'volume', 'the', 'of', ']$', 'e', '}[', 'b', '^{\\\\', 'v_r', '$', 'expression', 'approximate', 'an', 'provides', 'naturally', '$', 'q', '$', 'of', 'expression', 'approximate', 'this', '$.', 'c', '$', 'cube', '-', 'cell', 'the', 'of', 'point', 'internal', 'any', 'at', '$)', 'a_i', '^', 'e', '$', 'triad', 'the', 'by', 'defined', '(', '}$', 'ab', '{', 'q_', '$', 'metric', 'the', 'of', '$', 'q', '$', 'determinant', 'the', 'approximates', '$,', 'c', '$', 'of', 'size', ')', 'coordinate', '(', 'the', 'is', '$', 'l_c', '$', 'where', '$,', '6', '^', 'l_c', ')|/', 'e', '(', 'q_c', '$|', ',', 'clearly', \"'.\", 'triad', 'smeared', '$-', 's', '`$', 'the', 'is', '$', 'b', '^', 'dx', 'wedge', '\\\\', 'a', '^', 'dx', 'i', '}^', 'ab', '{', 'e_', 'int_s', '}\\\\', '2', 'over', '\\\\', '1', '{', '}=', 's', '{', 'i_', '^', 'e', '$', ',', 'before', 'as', ',', 'where', 'ee', '\\\\', '}}', 'c', '{', 's_', '{', 'k_', '^', 'e', '}}', 'b', '{', 's_', '{', 'j_', '^', 'e', '}}', 'a', '{', 's_', '{', 'i_', '^', 'e', '}\\\\,\\\\,', 'abc', '{', 'eta_', '\\\\,\\\\', '}', 'ijk', '^{', 'e', '\\\\', '!}', '3', 'over', '\\\\', '1', '{', ':=\\\\', '\\\\', ']', 'e', '}[', 'c', '{', 'q_', '}', 'q', '{', 'label', '\\\\', 'be', '\\\\', 'space', 'phase', 'classical', 'the', 'on', 'functional', 'a', 'define', 'we', ')$', 's_3', ',', 's_2', ',', 's_1', '=(', 's', '$', 'and', '$', 'c', '\\\\', 'in', '\\\\', 'c', '$', 'every', 'for', '$,', 'b', '$\\\\', 'given', '$.', 'b', '$\\\\', 'by', 'denoted', 'and', '$', 'r', '$', 'of', 'partition', 'a', 'called', 'be', 'will', '$),', 'c', '$', 'to', \"'\", 'dual', '(`', '$', 's', '$', 'surfaces', 'of', 'triples', 'and', 'cells', 'of', ')$,', 's', ',', 'c', '$(', 'pairs', 'of', 'family', 'a', 'such', ').', 'axes', 'coordinate', 'the', 'of', 'that', 'by', 'induced', 'is', 'orientation', 'whose', 'and', '(', '$', 'c', '$', 'of', 'interior', 'the', 'in', 'intersect', 'which', '$$', ',', '3', ',', '2', ',', '1', '=', 'a', '\\\\', '\\\\', '\\\\', 'a', '}^', 'const', 'rm', '{\\\\', '=', 'a', '^', 'x', '$$', 'by', 'defined', ')', 'boundary', 'without', '(', 'surfaces', '-', 'two', 'oriented', 'of', ')$', 's_3', ',', 's_2', ',', 's_1', '=(', 's', '$', 'triple', 'ordered', 'an', 'consider', '$', 'c', '\\\\', 'in', '\\\\', 'c', '$', 'cell', 'each', 'within', '.', 'boundaries', 'their', 'in', 'points', 'only', 'share', 'can', 'cells', 'different', 'two', '$.)', 'r', '$', 'with', 'intersection', 'its', 'only', 'consider', '$,', 'r', '$', 'in', 'contained', 'not', 'is', '$', 'c', '$', 'cube', 'a', 'if', '(', '.', 'planes', 'coordinate', 'the', 'to', 'parallel', 'are', 'sides', 'whose', 'cubes', 'closed', 'of', '$', 'c', '$\\\\', 'family', 'a', 'with', 'it', 'cover', 'and', '$', 'r', '$', 'containing', '$', 's', '$\\\\', 'in', 'neighborhood', 'a', 'in', '$', 'a', '^', 'x', '$', 'coordinates', 'global', 'fix', '.', 'system', 'coordinate', 'single', 'a', 'by', 'covered', 'be', 'can', 'which', '$', 'r', '$', 'regions', 'for', 'operators', 'volume', 'the', 'define', 'to', 'suffice', 'will', 'it', ',', 'hence', '$.', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'quantum', 'the', 'for', 'holds', 'reasoning', 'same', 'the', 'that', 'out', 'turns', 'it', '.', 'unity', 'of', 'partition', 'the', 'of', 'choice', 'specific', 'the', 'of', 'independent', 'is', 'answer', 'final', 'the', 'where', 'ee', '\\\\', ',', '}\\\\,', 'phi_u', '\\\\', ',', 'r', '{', 'v_', '}}', 'u', 'cal', '{\\\\', 'in', '\\\\', 'u', '{', 'sum_', '\\\\', '=', 'v_r', '}', 'unity', '{', 'label', '\\\\', 'be', '\\\\', 'have', 'we', '}$$', '2', 'over', '\\\\', '1', '|^{', 'e', '}\\\\,', 'det', 'rm', '|{\\\\', 'phi_u', '\\\\', '\\\\,', '3x', '^', 'd', 'int_r', '\\\\', '=', '}}', 'phi_u', ',{\\\\', 'r', '{', 'v_', '$$', 'set', 'we', 'if', ',', 'then', '}$.', 'u', 'cal', '${\\\\', 'to', 'associated', 'unity', 'of', 'partition', 'a', 'be', '}}$', 'u', 'cal', '{\\\\', 'in', '\\\\', 'u', '{', '_', ')', 'phi_u', '$(\\\\', 'let', '.', 'system', 'coordinate', 'single', 'a', 'by', 'covered', 'is', '}$', 'u', 'cal', '{\\\\', 'in', '\\\\', 'u', '$', 'each', 'that', 'such', 'neighborhoods', 'of', '}$', 'u', 'cal', '${\\\\', 'family', 'a', 'by', 'it', 'cover', 'can', 'we', '$,', 'r', '$', 'region', 'any', 'given', 'that', 'first', 'note', ',', 'this', 'see', 'to', '.', 'restrictive', 'overly', 'not', 'is', 'assumption', 'this', 'that', 'out', 'turns', 'it', ',', 'however', '$).', 'a', '^', 'x', '($', 'system', 'coordinate', 'single', 'a', 'by', 'covered', 'be', 'can', '$', 'r', '$', 'that', 'assume', 'to', 'necessary', 'be', 'will', 'it', ',', 'procedure', 'regularization', 'the', 'for', '.', 'space', 'phase', 'classical', 'the', 'on', 'ee', '\\\\', '}', '2', 'over', '\\\\', '1', '|^{', 'e', '}\\\\,', 'det', 'rm', '|{\\\\', '\\\\,', '3x', '^', 'd', 'int_r', '\\\\', '):=', 'e', '(', 'v_r', 'be', '\\\\', 'function', 'the', 'to', 'corresponding', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'the', 'construct', 'to', 'wish', 'we', '$.', 's', '$\\\\', 'in', '$', 'r', '$', 'region', 'open', 'an', 'fix', '.', 'section', 'in', 'out', 'carried', 'is', 'procedure', 'averaging', 'the', '.', 'structures', 'background', 'relevant', 'the', 'over', \"'\", 'average', '`', 'to', 'need', 'we', ',', 'operator', 'covariant', 'a', 'obtain', 'to', '.', 'steps', 'intermediate', 'the', 'in', 'introduced', ')', 'coordinates', ',', 'namely', '(', 'structure', 'background', 'the', 'of', 'memory', 'a', 'carries', 'operator', 'this', ',', 'however', '.', 'operator', 'defined', '-', 'well', 'a', 'yields', 'limit', 'the', 'that', 'show', 'and', 'shrink', 'cells', 'the', 'let', 'we', ',', 'part', 'last', 'the', 'in', '.', 'theory', 'quantum', 'the', 'to', 'expression', \"'\", 'regulated', '`', 'this', 'over', 'take', 'we', ',', 'second', 'the', 'in', '.', 'cells', 'small', 'into', 'consideration', 'under', 'region', 'the', 'dividing', 'by', 'functional', 'volume', 'the', 'of', 'expression', 'approximate', 'an', 'introduce', 'and', 'theory', 'classical', 'the', 'consider', 'we', ',', 'first', 'the', 'in', '.', 'parts', '3', 'to', 'in', 'divided', 'be', 'will', 'discussion', 'this', '.', 'operators', 'volume', 'the', 'of', 'regularization', 'first', 'the', 'introduce', 'now', 'can', 'we', '.', 'repeatedly', 'used', 'be', 'will', ')}$', '1', '^{(', 'cyl', '$\\\\', 'on', '$', 'i_s', '^', 'e', '$\\\\', 'and', '}$', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', 'operators', 'the', ',', 'paper', 'the', 'of', 'remainder', 'the', 'in', '.', 'preliminaries', 'mathematical', 'of', 'discussion', 'our', 'concludes', 'this', '.', 'adjoint', '-', 'self', 'essentially', 'be', 'to', 'out', 'turns', '$$', ')', 'ab', ')}(\\\\', '0', '^{(', 'cyl', '\\\\', '\\\\', 'rightarrow', '\\\\', ')\\\\', 'ab', ')}(\\\\', '1', '^{(', 'cyl', '\\\\', ':\\\\,', '}\\\\', 's', '{', 'i_', '^', 'e', '\\\\', '$$', 'operator', 'the', '$.', 'v', '$', 'intersecting', '$', 'g', '$\\\\', 'of', 'edges', 'the', ')', 'of', 'labels', '(', 'the', 'through', '$', 'i', '$', 'and', '$,', 's', '$', 'in', 'contained', '$', 'g', '$\\\\', 'of', 'vertices', 'the', 'through', 'runs', '$', 'v', '$', 'where', 'ee', '\\\\', 'g', '\\\\', 'psi_', '}}\\\\,\\\\', 'i', '{', 'e_', ',', 'v', '{', 'i_', '^', 'j', '}])\\\\,', 'i', '{', 'e_', '([', 'k_s', '}\\\\', 'i', '{', 'sum_', '\\\\', 'sum_v', '}\\\\', 'over2', '\\\\', '1', '{', '=\\\\', '}\\\\', 'g', '{\\\\', 'psi_', '}\\\\,\\\\', 's', '{', 'i_', '^', 'e', '\\\\', '}', 'sto', '{', 'label', '\\\\', 'be', '\\\\', 'reads', '$', 'g', '\\\\', 'psi_', '\\\\', '=', 'psi', '$\\\\', 'on', '$', 'i_s', '^', 'e', '$\\\\', 'of', 'action', 'the', ',', 'then', '$.', 'g', '$\\\\', 'of', 'vertex', 'a', 'is', '$', 's', '$', 'and', '$', 'g', '$\\\\', 'of', 'range', 'the', 'between', 'point', 'intersection', 'isolated', 'every', 'that', 'such', '$', 'g', '$\\\\', 'graph', 'a', 'using', '()', 'by', 'it', 'represent', 'to', 'convinient', 'is', 'it', '$', 'cyl', '\\\\', 'in', '\\\\', 'psi', '$\\\\', 'function', 'a', 'given', '.', 'terms', 'vanishing', '-', 'non', 'of', 'number', 'finite', 'a', 'only', 'have', 'sums', 'the', 'because', 'defined', '-', 'well', 'is', 'result', 'the', ',', 'function', 'cylindrical', 'any', 'on', 'side', 'right', 'the', 'act', 'we', 'when', ',', 'however', '.', 'infinite', 'are', '()', 'in', 'sums', 'the', 'ee', '\\\\', '}', 'cr', '.\\\\', 'otherwise', ',&', '0', 'cr', '$,\\\\', 's', '$', 'below', 'lies', '$', 'e', '$', 'if', ',&', '1', '-', 'cr', '$\\\\', 's', '$', 'above', 'lies', '$', 'e', '$', 'if', '&', ',', '1', '{', 'cases', '\\\\', '=\\\\', '\\\\', '])', 'e', '([', 'k_s', '\\\\', '}', 'kappa1', '{', 'label', '\\\\', 'be', '\\\\', 'where', 'and', '$,', 'x', '$', 'at', 'starting', 'germs', 'of', 'set', 'the', 'through', 'runs', ']$', 'e', '$[', '$,', 'x', '$', 'every', 'for', ',', 'and', '$', 's', '$', 'of', '$', 'x', '$', 'points', 'the', 'all', 'over', 'ranges', 'sum', 'first', 'the', 'where', 'ee', '\\\\', '},', 'e', ',', 'x', '{', 'i_', '^', 'j', '])', 'e', '([', 'k_s', '\\\\', ']}', 'e', '{[', 'sum_', '\\\\', '}\\\\,\\\\,', 's', 'in', '\\\\', 'x', '{', 'sum_', '}\\\\', '2', 'over', '\\\\', '1', '{', '=\\\\', '}\\\\', 's', '{', 'i_', '^', 'e', '\\\\', '}', 'he2', '{', 'label', '\\\\', 'be', '\\\\', ':', 'result', 'following', 'the', 'to', 'leads', 'regularization', 'careful', 'a', '$).', 's', '$', 'to', 'respect', 'with', \"'\", 'down', '`', 'and', \"'\", 'up', '`', 'of', 'notion', 'the', 'defines', 'naturally', 'which', '$', 'sigma', '$\\\\', 'and', '$', 's', '$', 'of', 'orientation', 'relative', 'the', 'on', 'depends', '$', 'i_s', '^', 'e', '$', 'of', 'action', 'the', 'that', 'note', '(', '.', 'boundary', 'without', 'surface', '-', 'two', 'analytic', 'an', 'is', '$', 's', '$', 'where', '$,', 'b', '^', 'dx', 'wedge', '\\\\', 'a', '^', 'dx', '}', 'ai', '^{', 'e', '}', 'abc', '{', 'eta_', '\\\\', 'int_s', '\\\\', '}', '2', 'over', '\\\\', '1', '{', 'textstyle', '\\\\', ':=', 'i_s', '^', 'e', '$', 'expressions', 'classical', 'the', 'of', 'analogs', 'quantum', 'the', ',', 'operators', 'triad', 'smeared', 'the', 'of', 'definition', 'the', 'from', 'recall', 'us', 'let', ',', 'finally', '$.', 'x', '$', 'at', 'starting', '$', 'e', '$', 'edge', 'an', 'of', 'germ', 'the', 'as', 'to', 'referred', 'be', 'will', ']$', 'e', '$[', ',', 'follows', 'what', 'in', ')$.', '2', '(', 'su', '$', 'of', 'constants', 'structure', 'the', 'are', '}$', 'k', '{', '_', '}{}', 'ij', '^{', 'epsilon', '$\\\\', 'and', 'relation', 'equivalence', 'above', 'the', 'by', 'defined', 'edges', 'of', 'class', 'equivalence', 'the', 'denotes', ']$', 'e', '$[', 'where', 'ee', '\\\\', ',', '}\\\\,', 'e', ',', 'x', '{', 'k_', '^', 'j', '}', 'k', '{', '_', '}{}', 'ij', '^{', 'epsilon', '\\\\', \"']}\\\\,\", 'e', '],[', 'e', '{[', 'delta_', '\\\\', \"'}\\\\,\", 'x', ',', 'x', '{', 'delta_', '\\\\', 'i', '=', \"'}]\", 'e', \"',\", 'x', '{', 'j_', '^', 'j', '},\\\\,', 'e', ',', 'x', '{', 'i_', '^', 'j', '[', '}', 'jcom', '{', 'label', '\\\\', 'be', '\\\\', ':', 'by', 'given', 'are', 'operators', 'these', 'between', 'relations', 'commutation', 'the', ',', 'finally', \"'$.\", 'e', 'sim', '\\\\', 'e', '$', 'and', \"'$\", 'i', '=', 'i', \"',\\\\,\", 'x', '=', 'x', '$', 'if', 'only', 'and', 'if', \"'}$\", 'e', \"',\", 'x', '{', '_', \"'}\", 'i', '^{', 'j', '=', '}', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', ',', 'then', '.', 'orientation', 'modulo', 'overlap', \"'$\", 'e', '$', 'and', '$', 'e', '$', 'which', 'on', '$', 'x', '$', 'of', 'neighbourhood', 'a', 'is', 'there', 'if', 'only', 'and', 'if', \"'$\", 'e', 'sim', '\\\\', 'e', '$', ':', 'ends', 'the', 'of', 'one', 'as', '$', 'x', '$', 'sharing', 'edges', 'the', 'for', 'relation', 'equivalence', 'an', 'introduce', 'us', 'let', '$', 's', '\\\\', 'in', '\\\\', 'x', '$', 'point', 'a', 'given', ',', 'next', '.)', 'see', ',', 'operators', 'such', 'of', 'adjointness', '-', 'self', 'essential', 'on', 'results', 'general', 'for', '(', ')}$.', '1', '^{(', 'cyl', '$\\\\', 'domain', 'the', 'on', 'adjoint', '-', 'self', 'essentially', 'is', '}$', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', 'that', 'show', 'can', 'one', '$.', '1', '^', 'c', '$', 'is', '()', 'in', '$', 'psi', '$\\\\', 'which', 'for', '$', 'ab', '$\\\\', 'on', 'functions', 'cylindrical', 'all', 'of', 'space', 'the', ')}$', '1', '^{(', 'cyl', '$\\\\', 'by', 'denote', '}$.', 'g', '{\\\\', 'psi_', '\\\\', '}', 'e', ',', 'x', '{', 'i_', '^', 'j', '=', \"'}\", 'g', '{\\\\', 'psi_', '\\\\', '}', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', 'then', '}$,', 'g', '{\\\\', 'psi_', '\\\\', '=', \"'}\", 'g', '{\\\\', 'psi_', '$\\\\', \"'$,\", 'g', '$\\\\', 'and', '$', 'g', '$\\\\', 'graphs', 'distinct', 'two', 'to', 'respect', 'with', 'cylindrical', 'is', '$', 'cyl', '$\\\\', 'of', 'element', 'an', 'if', ':', 'defined', '-', 'well', 'are', 'operators', 'these', ')$.', '2', '(', 'su', '$', 'on', 'form', 'killing', 'the', 'is', '}$', 'ij', '{', 'k_', '$', 'where', '$$', 'k', '^', 'tau', '}\\\\', 'ijk', '^{', 'epsilon', '\\\\', '=', ']', 'j', '^', 'tau', '\\\\', ',\\\\,', 'i', '^', 'tau', '[\\\\', 'quad', '\\\\', '}', 'and', 'rm', '{\\\\', 'quad', '\\\\', '},', 'ij', '^{', 'k', '=', 'j', '^', 'tau', '\\\\', 'i', '^', 'tau', '\\\\', '}\\\\,', 'tr', 'rm', '{\\\\', '2', '-', '$$', 'satisfying', ',', 'matrices', ')$', '2', '(', 'su', '$', 'are', '$', 'i', '^', 'tau', '$\\\\', ',', 'here', '.}', '.', 'ref', 'in', ')', '11', '.', '3', '(', '-', ')', '9', '.', '3', '(', '.', 'eq', 'see', ',', 'details', 'for', '$.', 'i', '^', 'r', '$-', 'field', 'vector', 'invariant', 'right', 'the', 'by', 'replaced', 'be', 'should', '$', 'l_i', '$', ',', 'point', '-', 'beginning', 'the', 'than', 'rather', '$', 'e_j', '$', 'edge', 'the', 'of', 'point', '-', 'end', 'the', 'is', '$', 'x', '$', 'if', '.', 'operators', 'like', '-', 'momentum', 'angular', 'are', '}$', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', 'that', 'sense', 'this', 'in', 'is', 'it', '.', 'edge', 'th', '$-', 'j', '$', 'the', 'with', 'associated', ')$', '2', '(', 'su', '$', 'of', 'copy', 'the', 'of', '$', 'i', '^', 'l', '$', 'field', 'vector', 'invariant', '-', 'left', ')', 'the', 'by', 'derivative', 'lie', '(', 'the', 'just', 'is', '()', 'of', 'side', 'right', 'the', 'on', 'operator', 'the', '{', 'footnote', '\\\\', '$.%', 'x', '$', 'at', 'outgoing', 'is', '$', 'e_j', '$', 'if', 'ea', ')]\\\\', 'e_n', '(', 'ab', '...\\\\', '),', 'i', '^', 'tau', '\\\\', 't', '}(', 'exp', 'rm', '){\\\\', 'e_j', '(', 'ab', '\\\\', '...,', '),', 'e_1', '(', 'ab', '(\\\\', 'psi', '}[\\\\', 'dt', '}{', 'd', '{', 'frac', '\\\\', 'i', '\\\\,', '&=&', '\\\\\\\\', 'nonumber', '\\\\', '}', 'a_b', '))^', 'e_j', '(', 'ab', '(\\\\', 'partial', '{\\\\', '}', 'psi', '\\\\', 'partial', '{\\\\', 'frac', '\\\\', '\\\\,', 'a_b', ')^', 'i', '^', 'tau', ')\\\\', 'e_j', '(', 'ab', '(\\\\', 'i', '\\\\,', '&=&', '\\\\,', ')', 'ab', '})(\\\\', 'g', '{\\\\', 'psi_', '\\\\', '}\\\\,', 'e', ',', 'x', '{', 'i_', '^', 'j', '(', '}', 'jop', '{', 'label', '\\\\', 'ba', '\\\\', ',', 'then', '$.', 'g', '$\\\\', 'of', 'vertex', 'a', 'is', '$', 'x', '$', 'that', 'assume', 'can', 'we', ',', 'generality', 'of', 'loss', 'without', '$,', 'x', '$', 'at', 'originating', '$', 'e', '$', 'with', 'segment', 'finite', 'a', 'shares', 'which', '$', 'e_j', '$', 'edge', 'an', 'has', '$', 'g', '$\\\\', 'hand', 'other', 'the', 'on', 'if', 'ee', '.\\\\', '0', '\\\\,', '=', '\\\\,', ')', 'ab', '})(\\\\', 'g', '{\\\\', 'psi_', '\\\\', '}\\\\,', 'e', ',', 'x', '{', 'i_', '^', 'j', '(', 'be', '\\\\', ',', 'points', 'end', 'its', 'of', 'one', 'as', '$', 'x', '$', 'with', '$', 'e', '$', 'of', 'segment', 'a', 'contain', 'not', 'does', 'which', 'graph', 'a', 'to', 'respect', 'with', '()---', 'in', 'as', 'represented', '.,', 'e', '.', 'i', '---', 'cylindrical', 'as', 'regarded', 'be', 'can', 'which', '$', 'g', '\\\\', 'psi_', '$\\\\', 'given', '.', 'index', ')$', '2', '(', 'su', '$', 'an', 'is', '$', 'i', '$', ',', 'before', 'as', ',', 'where', '$,', 'x', '$', 'at', 'begins', 'which', '$', 'e', '$', 'edge', 'an', 'and', '$', 's', '$\\\\', 'in', '$', 'x', '$', 'point', 'a', 'with', 'associated', '}$,', 'e', ',', 'x', '{', 'i_', '^', 'j', '$', 'operators', \"'\", 'like', 'momentum', 'angular', '`', 'are', 'us', 'to', 'interest', 'special', 'of', '.', 'practice', 'in', 'convenient', 'especially', 'be', 'to', 'out', 'turns', 'strategy', 'this', '.', 'extensions', 'adjoint', '-', 'self', 'their', 'consider', 'then', 'and', '$', 'cyl', '$\\\\', 'on', 'operators', 'interesting', 'physically', 'define', 'first', 'can', 'we', '$,', 'h', '$\\\\', 'in', 'dense', 'is', 'it', 'since', '$.', 'cyl', '$\\\\', 'space', 'the', 'is', 'this', '.', 'large', 'very', 'is', 'which', '$', 'ab', '$\\\\', 'on', 'functions', 'of', 'space', 'a', 'obtain', 'we', '$,', 's', '$\\\\', 'on', 'graphs', 'finite', 'all', 'through', '$', 'g', '$\\\\', 'vary', 'we', 'as', ',', 'however', '.', 'freedom', 'of', 'degrees', 'of', 'number', 'finite', 'a', 'only', 'with', 'system', 'a', 'of', 'states', 'quantum', 'of', 'space', 'the', 'as', 'of', 'thought', 'be', 'can', 'it', 'that', 'sense', 'the', 'in', \"'\", 'small', 'rather', '`', 'but', 'dimensional', 'infinite', 'is', '$', 'g', '$\\\\', 'graph', 'fixed', 'a', 'by', 'defined', 'functions', 'cylindrical', 'of', 'space', 'the', '.', 'functions', 'cylindrical', 'called', 'are', '}$', 'g', '{\\\\', 'psi_', '$\\\\', ',', 'terminology', 'standard', 'following', ',', 'therefore', '$.', 'ab', '$\\\\', 'on', \"'\", 'coordinates', '`', 'of', 'number', 'finite', 'a', 'of', 'only', 'depends', 'it', '$;', 'g', '$\\\\', 'of', 'edges', '$', 'n', '$', 'the', 'on', 'does', '$', 'ab', '$\\\\', 'connection', 'the', 'what', 'about', 'only', \"'\", 'knows', '`', '}$', 'g', '{\\\\', 'psi_', '$\\\\', 'that', 'note', '$.)', 'psi', '$\\\\', 'subscript', 'the', 'omit', 'will', 'we', ',', 'simplicity', 'notational', 'for', ',', 'however', '}$.', 'psi', ',\\\\', 'g', '{\\\\', 'psi_', '$\\\\', 'as', 'written', 'be', 'should', 'side', 'left', 'the', 'on', 'function', 'the', ',', 'strictly', '(', 'ee', '\\\\', '))', 'e_n', '(', 'ab', ',\\\\', '...', '),', 'e_1', '(', 'ab', '(\\\\', 'psi', '\\\\', '\\\\,', '=', ')\\\\,', 'ab', '(\\\\', '}', 'g', '{\\\\', 'psi_', '\\\\', '}', 'cylin', '{', 'label', '\\\\', 'be', '\\\\', ':', 'follows', 'as', '$', 'ab', '$\\\\', 'on', 'function', 'a', 'define', 'can', 'we', ',', 'then', '$.', 'n', ')]^', '2', '(', 'su', '$[', 'on', '$', 'c', 'rightarrow', '\\\\', 'n', ')]^', '2', '(', 'su', '[', ':', 'psi', '$\\\\', 'function', 'valued', '-', 'complex', 'a', 'and', '$,', 'n', ',...,', '1', '=', 'i', '$', '$,', 'e_i', '$', '.}', 'vertices', 'the', 'boundaries', 'their', 'in', 'points', 'the', ',', 'edges', 'called', 'are', 'graph', 'a', 'of', '$', 'e_i', '$', 'elements', 'the', '.', 'boundaries', 'the', 'in', 'contained', 'is', '}$', 'i_2', '{', 'cap_', '}\\\\', 'i_1', '{', 'e_', '$', 'intersection', 'the', '$', 'i_2', '=', 'not', '\\\\', 'i_1', '$', 'for', 'and', 'boundary', ')', 'point', 'two', '(', 'a', 'has', '$', 'e_i', '$', 'each', 'that', 'such', '$', 'sigma', '$\\\\', 'of', 'manifolds', '-', 'sub', 'analytic', ',', 'dimensional', '-', 'one', 'oriented', 'of', '\\\\}$', 'e_n', ',...,', 'e_1', '$\\\\{', 'set', 'finite', 'a', 'mean', 'we', '$', 'g', '$\\\\', 'graph', 'a', 'by', '{', 'footnote', '\\\\', '%', 'edges', 'of', '$)', 'n', '$', 'say', '(', 'number', 'finite', 'a', 'with', '$', 'g', '$\\\\', 'graph', 'a', 'fix', '.', '$)', 'ab', '$\\\\', 'connection', 'generalized', 'the', 'of', \"'\", 'holonomy', '`', 'the', 'as', 'regarded', 'be', 'can', 'which', '(', ')$,', '2', '(', 'su', '$', 'of', ')$', 'p', '}(', 'a', '{', 'overline', '$\\\\', 'element', 'an', '$,', 's', '$\\\\', 'in', '$', 'p', '$', 'path', 'analytic', 'any', 'to', 'assigns', '$', 'ab', '$\\\\', 'of', '$', 'ab', '$\\\\', 'element', 'each', '.', 'follows', 'as', 'constructed', 'are', 'these', '.', 'useful', 'especially', 'be', 'to', 'out', 'turns', 'which', \"'\", 'functions', 'cylindrical', '`', 'of', '$', 'cyl', '$\\\\', 'subspace', 'dense', 'a', 'contains', '$', 'h', '$\\\\', '.', '$', 'ab', '$\\\\', 'on', 'measure', 'invariant', 'diffeomorphism', 'natural', 'a', 'is', '$', 'o', '^', 'mu', '$\\\\', 'where', ')$', 'o', '^', 'mu', '\\\\', 'd', ',', 'ab', '(\\\\', '2', '^', 'l', '=', 'h', '$\\\\', 'by', 'given', 'is', 'states', 'quantum', ')', 'kinematic', '(', 'of', '$', 'h', '$\\\\', 'space', 'hilbert', 'the', ',', 'thus', '.', 'space', 'configuration', 'the', 'as', 'connections', ')', 'generalized', 'suitably', '(', 'of', '$', 'ab', '$\\\\', 'space', 'the', 'consider', 'to', 'led', 'naturally', 'is', 'one', ',', 'theory', 'quantum', 'in', ',', 'introduction', 'the', 'in', 'noted', 'as', 'ee', '\\\\', '.', '|}\\\\,', 'e', 'det', '{|\\\\', 'sqrt', '\\\\', '3x', '^', 'd', 'int_r', '\\\\', 'equiv', '\\\\', '}', 'q', '{', 'sqrt', '\\\\', '3x', '^', 'd', 'int_r', '\\\\', ':=', 'v_r', 'be', '\\\\', ':', 'by', 'given', 'is', ')', 'chart', 'single', 'a', 'by', ',', 'simplicity', 'for', ',', 'covered', '(', '$', 'r', '$', 'region', 'a', 'of', 'volume', 'the', ',', 'structures', 'riemannian', 'these', 'of', 'terms', 'in', '$.', 'a_i', '^', 'e', '|', 'e', '}', 'det', 'rm', '|{\\\\', 'equiv', '\\\\', 'a_i', '^', 'e', '}', 'q', '{', 'sqrt', '\\\\', '=', 'a_i', '^', 'e', '$', ':', 'have', 'also', 'we', '}$),', 'ab', '^{', 'q', '$', 'of', 'inverse', 'the', '(', '}$', 'ab', '{', 'q_', '$', 'of', 'determinant', 'the', '$', 'q', '$', 'by', 'denote', 'we', 'if', ')$.', '2', '(', 'su', '$', 'on', 'metric', 'killing', '-', 'cartan', 'the', 'is', '$', 'tr', '\\\\', '2', '=-', 'k', '$', 'where', '}$', 'ij', '^{', 'k', 'b_j', '^', 'e', 'a_i', '^', 'e', ':=', '}', 'ab', '^{', 'q', '$', 'metric', 'definite', 'positive', ',', 'contravariant', 'a', 'define', 'just', 'can', 'we', ',', 'fields', 'these', 'given', '.', 'orientations', 'both', 'with', '$', 'a_i', '^', 'e', '$', 'fields', 'frame', 'contains', 'space', 'phase', 'the', 'that', 'note', '$.', '3', ',', '2', ',', '1', '=', 'a', ',', 'i', '$', 'with', '})$', 'ia', '^{', 'e', '$(', 'matrix', 'the', 'of', 'determinant', 'the', 'for', 'stands', '$', 'e', '\\\\,', 'det', '$\\\\', 'where', 'ee', '\\\\', ',', '|}}', 'e', '\\\\,', 'det', '{|\\\\', 'sqrt', '\\\\', 'over', '\\\\', '_i', '}', 'a', '^{', 'e', '{', '=\\\\', '\\\\', 'a', '^', 'e_i', '}', 'e', '{', 'label', '\\\\', 'be', '\\\\', ':', 'via', '$', 'a_i', '^', 'e', '$', 'fields', 'vector', 'of', 'triplet', 'a', 'define', 'can', 'we', '$,', 'a_i', '^', 'e', '$', 'densities', 'vector', 'given', 'that', 'first', 'note', ',', 'this', 'see', 'to', '$.', 'a_i', '^', 'e', '$', 'momenta', 'the', 'in', 'coded', 'is', '$', 's', '$\\\\', 'manifold', '-', 'three', 'the', 'of', 'geometry', 'riemannian', '.', 'triads', 'as', 'simply', 'to', 'referred', 'be', 'will', '$', 'a_i', '^', 'e', '$', 'the', ',', 'brevity', 'for', ',', 'weighted', 'density', 'are', 'they', 'although', '$.', 's', '$\\\\', 'of', 'orientation', 'of', 'change', 'the', 'under', 'invariant', 'is', '$', 'i', '^', '_a', '}', 'a', '{', 'delta', '$\\\\', 'vector', 'tangent', 'a', 'on', '$', 'a_i', '^', 'e', '$', 'vector', 'cotangent', 'the', 'of', '}$$', 'i', '{', 'e_', 'wedge', '\\\\', 'i', '^', 'a', 'delta', '\\\\', 's', '\\\\', 'int_', '\\\\', '\\\\,\\\\,', 'equiv', '\\\\', '\\\\,\\\\,', 'i', '^', '_a', '}', 'a', '{', 'delta', '\\\\', 'a_i', '^', 'e', '\\\\,', '3x', '^', 'd', 's', '\\\\', 'int_', '$$\\\\', 'action', 'the', ',', 'thus', '.', 'density', 'pseudo', 'civita', '-', 'levi', 'the', 'is', '}$', 'abc', '^{', 'eta', '$\\\\', 'where', ')$,', '2', '(', 'su', '$', 'in', 'values', 'with', '---', '$', 'c_i', '^', 'e', '}', 'abc', '{', 'eta_', '\\\\', 'textstyle', '\\\\', '}:=', 'abi', '{', 'e_', '$', 'forms', '-', 'two', 'pseudo', ',', 'equivalently', ',', 'or', '---', 'one', 'weight', 'of', '$', 'a_i', '^', 'e', '$', 'densities', 'vector', 'degenerate', '-', 'non', 'are', \"'\", 'momenta', 'conjugate', '`', 'the', '.)', 'here', 'discuss', 'to', 'wish', 'we', 'issues', 'the', 'for', 'irrelevant', 'are', 'they', 'because', 'fields', 'on', 'conditions', 'boundary', 'specify', 'not', 'will', 'we', '(', '.', 'index', 'algebra', '-', 'lie', 'the', '$,', 'i', '$', 'and', ',', 'index', 'form', 'the', 'is', '$', 'a', '$', 'where', '$,', 's', '$\\\\', 'on', '$', 'i', '^', 'a_a', '$', 'form', '-', 'one', 'valued', ')$-', '2', '(', 'su', '$', 'an', 'as', '$', 'b', '$', 'on', '$', 'a', '$', 'connection', 'each', 'regard', 'and', 'trivialization', 'a', 'fix', 'can', 'we', ',', 'trivial', 'are', 'manifolds', '-', 'three', 'over', 'bundles', ')$', '2', '(', 'su', '$', 'all', 'since', '$.', 'b', '$', 'on', 'connections', 'smooth', 'of', 'consist', 'will', '$', 'c', '$\\\\', 'space', 'configuration', 'our', '$.', 's', '$\\\\', 'over', '$', 'b', '$', 'bundle', ')$', '2', '(', 'su', '$', 'principal', 'a', 'and', '$', 's', '$\\\\', 'manifold', '-', 'three', '.}', 'section', 'of', 'end', 'the', 'at', 'discussed', 'is', 'point', 'this', '.', 'graphs', 'and', 'manifolds', 'smooth', 'for', 'through', 'go', 'to', 'made', 'be', 'can', 'constructions', 'our', '.', 'directly', 'results', 'previous', 'use', 'to', 'us', 'allows', 'it', 'since', 'simplicity', 'for', 'it', 'make', 'we', ';', 'essential', 'not', 'is', 'analyticity', 'of', 'assumption', 'the', 'work', 'this', 'in', '{', 'footnote', '\\\\', '%', 'analytic', ',', 'orientable', 'an', 'fix', '.', 'detail', 'in', 'discussed', 'be', 'will', 'issues', 'corresponding', 'the', ',', 'therefore', ',', 'confusion', 'potential', 'remove', 'to', '.', 'gravity', 'quantum', 'perturbative', '-', 'non', 'on', 'literature', 'recent', 'the', 'in', 'conventions', 'and', 'viewpoints', 'in', 'arisen', 'has', 'diversity', 'some', 'that', 'out', 'turns', 'it', '.', 'notation', 'fix', 'to', 'serve', 'also', 'will', 'discussion', 'this', '.', 'geometry', 'riemannian', 'quantum', 'to', 'approach', 'present', 'the', 'underlie', 'that', 'ideas', 'mathematical', 'the', 'recall', 'briefly', 'we', ',', 'section', 'this', 'in', '.', 'sector', 'immirzi', 'any', 'in', 'result', 'main', 'the', 'state', 'also', 'and', '$', 'g', '$', 'and', '$', 'hbar', '$\\\\', '$,', 'c', '$', 'restore', 'will', 'we', ',', 'section', 'in', '.', 'sector', '$', '1', '=', 'gamma', '$\\\\', 'the', 'with', 'work', 'will', 'we', ',', 'discussion', 'main', 'the', 'in', ',', 'thus', '.', 'parameter', 'real', 'zero', '-', 'non', 'a', 'is', '$', 'gamma', '$\\\\', 'where', '$,', 'a_i', '^', 'e', ')\\\\,', 'gamma', '/\\\\', '1', '(', '=', 'a_i', '^', 'e', '\\\\!', 'gamma', '${}^\\\\', '$,', 'i', '^', 'k_a', 'gamma', '\\\\', '-', 'i', '^', 'gamma_a', '\\\\', '=', 'i', '^', 'a_a', '\\\\!', 'gamma', '${}^\\\\', 'pair', 'canonical', 'the', 'with', 'begins', 'one', 'if', 'result', 'theories', 'quantum', 'inequivalent', 'unitarily', ',', 'barbero', 'of', 'work', 'earlier', 'using', 'immirzi', 'by', 'out', 'pointed', 'as', '.', 'curvature', 'extrinsic', 'the', 'is', '$', 'i', '^', 'k_a', '$', 'and', '$', 'a_i', '^', 'e', '$', 'triad', 'the', 'with', 'compatible', 'connection', 'spin', 'the', 'is', '$', 'i', '^', 'gamma_a', '$\\\\', 'where', '$', 'i', '^', 'k_a', '-', 'i', '^', 'gamma_a', '\\\\', '=', 'i', '^', 'a_a', '$', 'be', 'to', '$', 'i', '^', 'a_a', '$', 'connection', 'real', 'the', 'chosen', 'and', '$', '1', '=', 'hbar', '$\\\\', 'and', '$', '1', '=', 'g', 'pi', '\\\\', '8', '$', '$,', '1', '=', 'c', '$', 'set', 'have', 'we', ',', 'discussion', 'main', 'the', 'in', ',', 'simplicity', 'for', '.', 'procedures', 'regularization', 'the', 'compares', 'and', 'results', 'main', 'the', 'summarizes', 'section', '.', 'section', 'in', 'discussed', 'are', 'operator', 'volume', 'the', 'of', 'properties', 'some', '.', 'appendix', 'the', 'in', 'discussed', 'is', 'operator', 'smolin', '-', 'rovelli', 'the', 'to', 'leading', 'regularization', 'the', ',', 'pietri', 'de', 'by', 'introduced', 'techniques', 'using', ',', 'and', 'and', 'sections', 'in', 'detail', 'in', 'discussed', 'is', 'operator', 'first', 'the', 'to', 'leading', 'regularization', '.', 'preliminaries', 'to', 'devoted', 'is', 'section', '.', 'follows', 'as', 'organized', 'is', 'paper', 'the', '.', 'recently', 'only', 'begun', 'has', 'analysis', 'systematic', 'a', 'such', '.', 'operators', 'length', 'and', 'area', 'the', 'to', 'relation', 'their', '.,', 'g', '.', 'e', '--', 'properties', 'their', 'analyze', 'further', 'to', 'needs', 'one', ',', 'them', 'between', 'relation', 'the', 'of', 'understanding', 'deeper', 'a', 'get', 'to', '.', 'differences', 'important', 'to', 'lead', 'can', 'they', ',', 'dynamics', 'quantum', 'to', '.,', 'g', '.', 'e', ',', 'applications', 'various', 'in', ',', 'nonetheless', \"'.\", 'ambiguity', 'quantization', '`', 'a', 'as', 'simply', 'interpreted', 'be', 'can', 'them', 'between', 'difference', 'the', 'and', 'similar', 'rather', 'are', 'operators', 'two', 'the', 'of', 'expressions', 'actual', 'the', '.', 'spectrum', 'discrete', 'purely', 'with', '$', 'h', '$\\\\', 'on', 'operators', 'adjoint', '-', 'self', ',', 'defined', '-', 'well', 'are', 'they', '.', 'regularizations', 'systematic', 'through', 'constructed', 'be', 'can', 'operators', 'both', 'that', 'see', 'will', 'we', '$.', 's', '$\\\\', 'of', 'structure', 'differential', 'the', 'to', 'sensitive', 'not', 'is', 'operator', 'this', ',', 'sense', 'certain', 'a', 'in', '.)', 'in', ',', 'here', 'discussed', 'framework', 'the', 'in', ',', 'and', ',', 'in', 'rovelli', 'and', 'pietri', 'de', 'by', 'introduced', 'was', 'operator', 'that', 'of', 'expression', 'form', '-', 'closed', 'final', 'the', '(', '.', 'representation', 'loop', 'the', 'in', 'smolin', 'and', 'rovelli', 'by', 'given', 'construction', 'a', 'on', 'based', 'is', 'which', 'scheme', 'regularization', 'different', 'a', 'consider', 'will', 'we', ',', 'appendix', 'the', 'in', '$.', 's', '$\\\\', 'manifold', '-', 'three', 'the', 'on', 'structure', 'differential', 'the', 'to', 'sensitive', 'is', 'operator', 'this', 'that', 'see', 'will', 'we', '.)', 'in', 'thiemann', 'by', 'studied', 'also', 'was', 'operator', 'the', '.', 'loll', 'by', 'discussed', 'was', 'theory', 'lattice', 'a', 'to', 'restriction', 'its', 'and', 'in', 'reported', 'was', 'operator', 'volume', 'this', 'of', 'form', 'final', 'the', '(', '.', 'in', 'operators', 'area', 'to', 'us', 'led', 'that', 'lines', 'the', 'along', 'regularization', 'a', 'discuss', 'will', 'we', ',', 'paper', 'the', 'of', 'body', 'main', 'the', 'in', '.}', 'appendix', 'the', 'of', 'beginning', 'the', 'see', ',', 'point', 'this', 'of', 'discussion', 'further', 'a', 'for', '{', 'footnote', '\\\\', '.%', 'interest', 'physical', 'of', 'operators', 'all', 'for', 'applicable', 'is', 'that', 'scheme', 'uniform', 'a', 'thus', 'is', 'there', ';', 'constraint', 'hamiltonian', 'the', 'of', 'that', 'with', 'consistent', 'operators', 'volume', 'of', 'regularization', 'our', 'makes', 'property', 'this', '$.', 'psi', '\\\\', 'epsilon_', '\\\\', 'le', '\\\\', 'epsilon', '$\\\\', 'all', 'for', '.,', 'e', '.', 'i', ',', 'stage', 'finite', 'a', 'at', 'achieved', 'is', 'limit', 'the', ',', 'treatment', 'our', 'in', ',', 'finally', '.', 'overlooked', 'often', 'are', 'that', 'subtleties', 'other', 'some', 'out', 'point', 'and', 'assumptions', 'underlying', 'the', 'out', 'spell', 'also', 'will', 'we', ',', 'process', 'the', 'in', '.', 'situation', 'this', 'rectify', 'will', 'we', '$.', 'h', '\\\\', 'in', '\\\\', 'psi', '$\\\\', 'states', 'of', 'subset', 'dense', 'a', 'for', 'exist', 'should', ')$', 'psi', '\\\\', 'cdot', '\\\\', 'e', '^\\\\', '_r', '}', 'v', '{', 'hat', '(\\\\', '}', '0', 'rightarrow', '\\\\', 'e', '{\\\\', 'lim_', '$\\\\', 'limit', 'the', ')', 'topology', 'space', 'hilbert', 'the', 'in', '(', 'then', ',', 'operator', 'volume', 'the', 'of', 'version', 'regulated', 'the', '$', 'epsilon', '^\\\\', '_r', '}', 'v', '{', 'hat', '$\\\\', 'by', 'denote', 'we', 'if', ':', 'property', 'basic', 'rather', 'following', 'the', 'has', 'which', 'literature', 'the', 'in', 'appeared', 'has', 'scheme', 'regularization', 'no', ',', 'far', 'so', ',', 'that', 'appears', 'it', ')', 'theory', 'continuum', 'the', 'for', '(', 'particular', 'in', '.', 'operators', 'area', 'for', 'that', 'than', 'complicated', 'more', 'considerably', 'be', 'to', 'out', 'turns', 'problem', 'the', ',', 'indeed', '.', 'subtle', 'quite', 'is', 'regularization', 'of', 'issue', 'the', ',', 'imagine', 'might', 'one', 'as', ',', 'triads', 'the', 'of', 'function', 'polynomial', '-', 'non', ',', 'complicated', 'rather', 'a', 'is', '$', 'v_r', '$', 'since', '.', 'space', 'phase', 'classical', 'the', 'on', '|}$', 'e', '}', 'det', 'rm', '{|{\\\\', 'sqrt', '\\\\', '\\\\,', '3x', '^', 'd', 'int_r', '\\\\', ':=', 'v_r', '$', 'function', 'the', 'of', 'analog', 'quantum', 'the', '---', '$', 'r', '$', 'region', 'dimensional', '-', 'three', 'a', 'with', 'associated', '$', '_r', '}', 'v', '{', 'hat', '$\\\\', 'operator', 'volume', 'the', 'discuss', 'to', 'wish', 'now', 'we', '.', 'space', 'phase', 'classical', 'the', 'on', 'defined', '$', 'a_s', '$', 'functions', 'area', 'the', 'of', 'analogs', 'quantum', 'the', 'are', 'these', '.', 'boundary', 'without', '$', 's', '$', 'surfaces', 'dimensional', '-', 'two', 'with', 'associated', '$', '_s', '}', 'a', '{', 'hat', '$\\\\', 'operators', 'area', 'obtain', 'to', 'regularized', 'were', 'operators', 'triad', 'the', 'of', 'products', 'appropriate', 'of', 'roots', '-', 'square', ',', 'in', '.', 'metric', 'background', 'the', 'by', 'available', 'made', 'structures', 'geometrical', 'the', 'using', ',', 'dimensions', 'three', 'in', 'forms', '-', 'two', 'field', 'electric', 'and', 'forms', '-', 'one', 'connection', 'both', 'smears', 'one', ',', 'example', 'for', ',', 'time', '-', 'space', 'minkowski', 'in', 'fields', 'maxwell', 'of', 'theory', 'quantum', 'the', 'in', ',', 'contrast', 'by', '.', 'theory', 'the', 'of', 'invariance', 'diffeomorphism', 'underlying', 'the', 'with', 'intertwined', 'deeply', 'is', 'feature', 'this', '.', 'smearing', 'dimensional', '-', 'two', 'a', 'through', 'regulated', 'naturally', 'are', 'operators', 'triad', 'forms', '-', 'two', 'the', '.', 'curves', 'dimensional', '-', 'one', 'along', 'forms', '-', 'one', 'connection', 'the', 'integrating', 'by', 'obtained', ']$,', 'alpha', '}[\\\\', 'h', '{', 'hat', '$\\\\', 'holonomies', 'are', 'connections', 'in', 'information', 'code', 'that', 'operators', 'the', ',', 'thus', '.', 'manifolds', '-', 'n', 'on', 'integrated', 'are', 'forms', '-', 'n', 'when', 'result', 'operators', 'defined', '-', 'well', ',', 'procedure', 'regularization', 'the', 'in', ':', 'analysis', 'and', 'geometry', 'between', 'synergy', 'remarkable', 'a', 'is', 'there', ',', 'geometry', 'quantum', 'to', 'approach', 'this', 'in', ',', 'generally', 'more', '.', 'affirmative', 'the', 'in', 'is', 'answer', 'the', 'triads', 'for', ',', 'however', ',', 'surprisingly', 'somewhat', '.', 'dimensions', 'three', ')', 'least', 'at', '(', 'in', 'smeared', 'are', 'they', 'unless', 'result', 'not', 'will', 'operators', 'defined', '-', 'well', 'that', 'expect', 'would', 'one', ',', 'theory', 'field', 'quantum', 'minkowskian', 'from', ':', 'obvious', 'apriori', 'not', 'is', 'answer', 'the', '?', 'behaved', '-', 'well', 'be', 'operators', 'quantum', 'corresponding', 'the', 'can', '.', 'surfaces', 'dimensional', '-', 'two', 'on', 'support', 'with', '$', 'f_i', '$', 'fields', 'test', 'valued', '-', 'algebra', '-', 'lie', 'against', 'them', 'smear', 'to', 'natural', 'is', 'it', ',', 'functions', 'space', 'phase', 'obtain', 'to', '}$.', 'abi', '{', 'e_', '$', 'forms', '-', 'two', 'pseudo', 'as', 'of', 'thought', 'naturally', 'be', 'can', '--', 'weighted', 'density', 'being', '--', 'triads', ',', 'above', 'remarked', 'as', '.', 'operators', 'triad', 'these', 'of', 'products', 'appropriate', 'the', 'regularizing', 'by', '--', 'length', 'and', 'volume', ',', 'area', 'to', 'corresponding', 'those', '.,', 'g', '.', 'e', '--', 'operators', 'geometric', 'construct', 'to', 'is', 'idea', 'the', ',', 'specifically', '.', 'case', 'quantum', 'the', 'in', 'objects', 'basic', 'the', 'are', 'these', ',', 'geometry', 'riemannian', 'classical', 'in', 'as', '.', 'triads', 'the', 'to', 'corresponding', '$', 'e', '$\\\\', 'distributions', 'valued', '-', 'operator', ',', 'manner', 'systematic', 'a', 'in', ',', 'introduce', 'can', 'one', ',', 'particular', 'in', '$.', 'h', '$\\\\', 'on', 'operators', 'interesting', 'physically', 'define', 'then', 'can', 'one', ',', '$', 'ab', '$\\\\', 'on', 'geometry', 'differential', 'developed', '-', 'well', 'the', 'using', '.', 'space', 'phase', 'full', 'the', 'of', 'analog', 'quantum', 'the', '.,', 'e', '.', 'i', ',', 'states', 'quantum', 'kinematic', 'of', 'space', 'the', 'represents', '$', 'h', '$\\\\', ',', 'physically', '.', '$', 'ab', '$\\\\', 'on', 'functions', 'integrable', '-', 'square', 'of', ')$', 'o', '^', 'mu', '\\\\', 'd', ',', 'ab', '(\\\\', '2', '^', 'l', '$', 'space', 'the', 'be', 'to', 'taken', 'be', 'can', '$', 'h', '$\\\\', 'space', 'hilbert', 'the', 'and', '$', 'o', '^', 'mu', '$\\\\', 'measure', 'invariant', 'diffeomorphism', 'natural', 'a', 'admits', '$', 'ab', '$\\\\', 'that', 'out', 'turns', 'it', '.)', 'smolin', 'and', 'rovelli', 'by', 'earlier', 'introduced', \"'\", 'representation', 'loop', '`', 'the', 'from', 'came', 'work', 'this', 'for', 'motivation', 'the', 'of', 'much', '(', '.', 'authors', 'of', 'number', 'a', 'by', 'papers', 'of', 'series', 'a', 'in', 'developed', 'were', 'tools', 'necessary', 'the', ').', 'field', 'background', 'other', 'any', 'or', '(', 'metric', 'fiducial', 'a', 'to', 'refer', 'not', 'does', 'also', 'which', '$', 'ab', '$\\\\', 'on', 'calculus', 'functional', 'a', 'needs', 'one', ',', 'thereon', 'operators', 'geometric', 'and', 'states', 'quantum', 'of', '$', 'h', '$\\\\', 'space', 'hilbert', 'the', 'obtain', 'to', '.', 'space', 'configuration', ')', 'quantum', '(', 'the', 'as', '$', 's', '$\\\\', 'on', 'connections', ')', 'generalized', 'suitably', '(', 'of', '$', 'ab', '$\\\\', 'space', 'the', 'consider', 'to', 'led', 'naturally', 'is', 'one', ',', 'then', ',', 'theory', 'quantum', 'the', 'in', ').', 'density', 'pseudo', 'civita', '-', 'levi', 'the', 'is', '}$', 'abc', '{', 'eta_', '$\\\\', 'where', '$,', 'c_i', '^', 'e', '}', 'abc', '{', 'eta_', '\\\\', ':=', '}', 'abi', '{', 'e_', '$', 'form', '-', 'two', ')', 'pseudo', '(', 'a', ',', 'equivalently', ',', 'or', '(', 'algebra', 'lie', ')$', '2', '(', 'su', '$', 'the', 'in', 'values', 'with', ')$', 'x', '(', 'a_i', '^', 'e', '$', 'density', 'vector', 'a', 'is', 'variable', 'momentum', 'the', '.)', 'indices', 'algebra', '-', 'lie', ')$', '2', '(', 'su', '$', 'the', 'are', '....$', ',', 'k', ',', 'j', ',', 'i', '$', 'indices', 'and', '$', 's', '$\\\\', 'of', 'space', 'tangent', 'the', 'to', 'refer', '...$', ',', 'c', ',', 'b', ',', 'a', '$', 'indices', '(', '$.', 's', '$\\\\', 'manifold', '-', 'three', 'a', 'on', ')$', 'x', '(', 'i', '^', 'a_a', '$', 'connection', ')$', '2', '(', 'su', '$', 'an', 'is', 'variable', 'configuration', 'the', ',', 'here', 'used', 'approach', 'quantization', 'canonical', 'the', 'in', '.', 'summary', 'brief', 'a', 'with', 'begin', 'us', 'let', '.)', 'in', 'introduced', 'was', 'text', 'main', 'the', 'in', 'derive', 'we', 'operator', 'volume', 'the', '(', '.', 'operators', 'volume', 'of', 'construction', 'similar', 'a', 'out', 'carry', 'to', 'is', 'paper', 'this', 'of', 'purpose', 'the', '.', 'operators', 'area', 'constructing', 'of', 'problem', 'the', 'to', 'applied', 'and', 'in', 'developed', 'were', 'techniques', 'basic', '.', 'geometry', 'of', 'theory', 'quantum', 'resulting', 'the', 'present', 'to', 'is', 'papers', 'of', 'series', 'this', 'of', 'goal', 'the', '.', 'detail', 'in', 'out', 'borne', 'being', 'are', 'expectations', 'these', ',', 'quantization', 'canonical', 'on', 'based', 'approach', 'perturbative', '-', 'non', 'specific', 'a', 'in', '.', 'states', 'classical', '-', 'semi', 'the', 'of', 'graining', 'coarse', 'on', 'approximation', 'an', 'as', 'only', 'emerge', 'then', 'would', 'geometry', 'riemannian', 'familiar', '.', 'theory', 'this', 'constructing', 'for', 'pointers', 'provide', ',', 'time', 'same', 'the', 'at', ',', 'and', ',', 'geometry', 'of', 'theory', 'quantum', 'corresponding', 'a', 'require', 'would', 'gravity', 'quantum', 'of', 'formulation', 'perturbative', '-', 'non', 'a', 'that', 'expects', 'therefore', 'one', '.', 'gravity', 'of', 'theories', 'modern', 'other', 'and', 'relativity', 'general', 'for', 'framework', 'mathematical', 'the', 'provides', 'geometry', 'riemannian'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "1cdxwQ0xgzZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d8727a-5f7b-4836-e45b-2f363cc2e16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = DataLoader(train_data, batch_size=4, num_workers=2, worker_init_fn=worker_init_fn)\n",
        "valid_iterator = DataLoader(valid_data, batch_size=4, num_workers=2, worker_init_fn=worker_init_fn)\n",
        "test_iterator = DataLoader(test_data, batch_size=4, num_workers=2, worker_init_fn=worker_init_fn)"
      ],
      "metadata": {
        "id": "ClSLGSNzLZTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in  train_iterator:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "-0L-8_GYTn5Y",
        "outputId": "f1bb31f7-5fb9-4c18-d2c1-7823aca0ca97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-fb7c1d7a8083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 150, in _worker_loop\n    init_fn(worker_id)\n  File \"<ipython-input-123-a579aefaa5c8>\", line 6, in worker_init_fn\n    split_size = len(dataset.data) // worker_info.num_workers\nAttributeError: 'Subset' object has no attribute 'data'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def _len_sort_key(x):\n",
        "#     return len(x.src)\n",
        "\n",
        "# BATCH_SIZE = 128\n",
        "\n",
        "# train_iterator, valid_iterator = BucketIterator.splits(\n",
        "#     (train_data, valid_data), \n",
        "#     batch_size = BATCH_SIZE, \n",
        "#     device = device,\n",
        "#     sort_key=_len_sort_key\n",
        "# )"
      ],
      "metadata": {
        "id": "2Zaz4300g1bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "iKzsTnE9i1cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        \n",
        "        # Compute an embedding from the src data and apply dropout to it\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src sent len, batch size, emb dim]\n",
        "        \n",
        "        # Compute the RNN output values of the encoder RNN. \n",
        "        # outputs, hidden and cell should be initialized here. Refer to nn.LSTM docs ;)\n",
        "        \n",
        "        _, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs = [src sent len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        if self.bidirectional:\n",
        "            #print(hidden.shape)\n",
        "            hidden = hidden.reshape(self.n_layers, 2, -1, self.hid_dim)\n",
        "            hidden = hidden.transpose(1, 2).reshape(self.n_layers, -1, 2 * self.hid_dim)\n",
        "\n",
        "            cell = cell.reshape(self.n_layers, 2, -1, self.hid_dim)\n",
        "            cell = cell.transpose(1, 2).reshape(self.n_layers, -1, 2 * self.hid_dim)\n",
        "            #print(hidden.shape)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "QXG23Mzog1db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder\n"
      ],
      "metadata": {
        "id": "ajI8r_hnjBc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        # Compute an embedding from the input data and apply dropout to it\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        # Compute the RNN output values of the encoder RNN. \n",
        "        # outputs, hidden and cell should be initialized here. Refer to nn.LSTM docs ;)\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        \n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #sent len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "BhOxIRkYi-b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seq2Seq"
      ],
      "metadata": {
        "id": "youc8e5RjRyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        if encoder.bidirectional:\n",
        "            assert encoder.hid_dim * 2 == decoder.hid_dim, \\\n",
        "                \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        else:\n",
        "            assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "                    \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(-1) \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "metadata": {
        "id": "Abtxhlmli-eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "PTP8hRCHj_3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PttJ5wum3qkk",
        "outputId": "7ac429d0-1208-4ff6-e4f0-139da7cbfb30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwhGbW8f36KU",
        "outputId": "a0aa33e3-40e1-4ab7-c29e-3aab9a8750d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.rand(5, 3)\n",
        "y = y.cuda()"
      ],
      "metadata": {
        "id": "IQZH1DxX4Zl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For reloading \n",
        "# import modules\n",
        "# import imp\n",
        "# imp.reload(modules)\n",
        "\n",
        "# Encoder = modules.Encoder\n",
        "# Attention = modules.Attention\n",
        "# Decoder = modules.DecoderWithAttention\n",
        "# Seq2Seq = modules.Seq2Seq\n",
        "\n",
        "# INPUT_DIM = len(SRC.vocab)\n",
        "# OUTPUT_DIM = len(TRG.vocab)\n",
        "INPUT_DIM = 3000\n",
        "OUTPUT_DIM = 3000\n",
        "\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "# enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM // 2, N_LAYERS, ENC_DROPOUT, BIDIRECTIONAL)\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, BIDIRECTIONAL)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "# dont forget to put the model to the right device\n",
        "model = Seq2Seq(enc, dec, device)"
      ],
      "metadata": {
        "id": "rpbbB8bJi-g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ESftlK4pCY2j",
        "outputId": "41877480-af16-4b6f-d9c4-66b05fe3e1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-281bb118eecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0mnum_weights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     torch._cudnn_rnn_flatten_weight(\n\u001b[0m\u001b[1;32m    173\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms07EJlDi-jR",
        "outputId": "b4ac9762-655b-4d01-8f5f-c3563d9b993e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(3000, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(3000, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (out): Linear(in_features=512, out_features=3000, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thwJ2OoSi-lh",
        "outputId": "6290bf94-088b-4bfd-cbc8-c4030c5e2751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 10,431,416 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "PAD_IDX = 1\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg sent len, batch size]\n",
        "        #output = [trg sent len, batch size, output dim]\n",
        "        \n",
        "        output = output[1:].view(-1, OUTPUT_DIM)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg sent len - 1) * batch size]\n",
        "        #output = [(trg sent len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # Let's clip the gradient\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        history.append(loss.cpu().data.numpy())\n",
        "        if (i+1)%10==0:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "\n",
        "            clear_output(True)\n",
        "            ax[0].plot(history, label='train loss')\n",
        "            ax[0].set_xlabel('Batch')\n",
        "            ax[0].set_title('Train loss')\n",
        "            if train_history is not None:\n",
        "                ax[1].plot(train_history, label='general train history')\n",
        "                ax[1].set_xlabel('Epoch')\n",
        "            if valid_history is not None:\n",
        "                ax[1].plot(valid_history, label='general valid history')\n",
        "            plt.legend()\n",
        "            \n",
        "            plt.show()\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    history = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg sent len, batch size]\n",
        "            #output = [trg sent len, batch size, output dim]\n",
        "\n",
        "            output = output[1:].view(-1, OUTPUT_DIM)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg sent len - 1) * batch size]\n",
        "            #output = [(trg sent len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "lWko1w4Gi-oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "9AvGE4rUj6YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "N_EPOCHS = 12\n",
        "CLIP = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
        "    \n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq3aULbKj6aW",
        "outputId": "aa1af128-cff2-4589-f824-66a97471f782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 21s\n",
            "\tTrain Loss: 4.626 | Train PPL: 102.094\n",
            "\t Val. Loss: 4.247 |  Val. PPL:  69.866\n",
            "Epoch: 02 | Time: 1m 24s\n",
            "\tTrain Loss: 4.353 | Train PPL:  77.693\n",
            "\t Val. Loss: 3.524 |  Val. PPL:  33.930\n",
            "Epoch: 03 | Time: 1m 25s\n",
            "\tTrain Loss: 3.823 | Train PPL:  45.751\n",
            "\t Val. Loss: 2.995 |  Val. PPL:  19.995\n",
            "Epoch: 04 | Time: 1m 28s\n",
            "\tTrain Loss: 3.634 | Train PPL:  37.849\n",
            "\t Val. Loss: 2.748 |  Val. PPL:  15.616\n",
            "Epoch: 05 | Time: 1m 39s\n",
            "\tTrain Loss: 3.307 | Train PPL:  27.313\n",
            "\t Val. Loss: 2.790 |  Val. PPL:  16.288\n",
            "Epoch: 06 | Time: 2m 1s\n",
            "\tTrain Loss: 3.285 | Train PPL:  26.696\n",
            "\t Val. Loss: 2.762 |  Val. PPL:  15.835\n",
            "Epoch: 07 | Time: 2m 40s\n",
            "\tTrain Loss: 3.257 | Train PPL:  25.983\n",
            "\t Val. Loss: 2.660 |  Val. PPL:  14.295\n",
            "Epoch: 08 | Time: 3m 21s\n",
            "\tTrain Loss: 3.194 | Train PPL:  24.378\n",
            "\t Val. Loss: 2.578 |  Val. PPL:  13.169\n",
            "Epoch: 09 | Time: 4m 34s\n",
            "\tTrain Loss: 3.157 | Train PPL:  23.507\n",
            "\t Val. Loss: 2.553 |  Val. PPL:  12.843\n",
            "Epoch: 10 | Time: 5m 59s\n",
            "\tTrain Loss: 3.159 | Train PPL:  23.538\n",
            "\t Val. Loss: 2.564 |  Val. PPL:  12.984\n",
            "Epoch: 11 | Time: 4m 48s\n",
            "\tTrain Loss: 3.170 | Train PPL:  23.808\n",
            "\t Val. Loss: 2.585 |  Val. PPL:  13.268\n",
            "Epoch: 12 | Time: 3m 12s\n",
            "\tTrain Loss: 3.154 | Train PPL:  23.427\n",
            "\t Val. Loss: 2.611 |  Val. PPL:  13.611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at our network quality:"
      ],
      "metadata": {
        "id": "gMIqrmg2ks6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_on_eos(tokens_iter):\n",
        "    for token in tokens_iter:\n",
        "        if token == '<eos>':\n",
        "            break\n",
        "        yield token\n",
        "\n",
        "def remove_tech_tokens(tokens_iter, tokens_to_remove=['<sos>', '<unk>', '<pad>']):\n",
        "    return [x for x in tokens_iter if x not in tokens_to_remove]\n",
        "\n",
        "def generate_translation(src, trg, model, TRG_vocab):\n",
        "    model.eval()\n",
        "\n",
        "    output = model(src, trg, 0) #turn off teacher forcing\n",
        "    # output = output[1:].argmax(-1)\n",
        "\n",
        "    original = remove_tech_tokens(cut_on_eos([TRG_vocab.itos[x] for x in list(trg[:,0].cpu().numpy())]))\n",
        "    generated = remove_tech_tokens(cut_on_eos([TRG_vocab.itos[x] for x in list(output[:, 0].cpu().numpy())]))\n",
        "    \n",
        "    print('Original: {}'.format(' '.join(original)))\n",
        "    print('Generated: {}'.format(' '.join(generated)))\n",
        "    print()\n",
        "\n",
        "def get_text(x, TRG_vocab):\n",
        "     generated = remove_tech_tokens(cut_on_eos([TRG_vocab.itos[elem] for elem in list(x)]))\n",
        "     return generated"
      ],
      "metadata": {
        "id": "aIf3D7HVj6c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best-val-model.pt'))\n",
        "batch = next(iter(valid_iterator))\n",
        "\n",
        "for idx in range(10):\n",
        "    src = batch.src[:, idx:idx+1]\n",
        "    trg = batch.trg[:, idx:idx+1]\n",
        "    generate_translation(src, trg, model, TRG.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "4hsIEXf2j6es",
        "outputId": "4d1e9890-5b4c-485e-8cee-aa9a07356a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: исследуется проблема научного дискурса с интегрального подхода . рассматриваются вопросы определения интегрального подхода в , дискурса , его и особое внимание уделяется . предлагается интегральная модель научного дискурса с его , , , и . намечаются перспективы дальнейшего исследования .\n",
            "Generated: \n",
            "\n",
            "Original: ( больных . в , при . , на .\n",
            "Generated: \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-cb48319ca70b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgenerate_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-161-3b6be10acbf9>\u001b[0m in \u001b[0;36mgenerate_translation\u001b[0;34m(src, trg, model, TRG_vocab)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#turn off teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-154-b9055c950470>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mteacher_force\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#get the highest predicted token from our predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mtop1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;31m#if teacher forcing, use actual next token as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m#if not, use predicted token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot perform reduction function argmax on a tensor with no elements because the operation does not have an identity"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nC4ZCJqFuJw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization with Seq2Seq Model"
      ],
      "metadata": {
        "id": "Tl_qSbarvOpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Importing the Dataset"
      ],
      "metadata": {
        "id": "ymAg7yzzybca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "N5wGTiGkuJzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary = pd.read_csv('news_summary.csv', encoding='iso-8859-1')\n",
        "# raw = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "vq4LLJfjuJ2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"outoutGeneralRelativityAndQuantumCosmology_0_result.feather\"\n",
        "summary = pd.read_feather(filename)"
      ],
      "metadata": {
        "id": "ClTn6gKpX_2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre1 =  raw.iloc[:,0:2].copy()\n",
        "# pre1['head + text'] = pre1['headlines'].str.cat(pre1['text'], sep =\" \") \n",
        "\n",
        "pre2 = summary.iloc[:,0:6].copy()\n",
        "# pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")"
      ],
      "metadata": {
        "id": "CnWhFeP3uJ4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = pd.DataFrame()\n",
        "pre['text'] = pre2['clear']\n",
        "pre['summary'] = pre2['Annotation']"
      ],
      "metadata": {
        "id": "DbsOQUt8uJ7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ia4VNbDYxur8",
        "outputId": "e98b0467-9683-4ec7-ae68-8643c2323e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  \\n\\n \\let\\miguu=\\footnote\\n \\def\\footnote#1#2{...   \n",
              "1  \\nIn a modern Quantum Mechanics (QM) the parti...   \n",
              "2  \\documentclass[12pt,a4paper]{article}\\n\\usepac...   \n",
              "3  \\nThe inflationary universe scenarios explain ...   \n",
              "4  \\font\\mybb=msbm10 at 12pt\\n\\def\\bbxx#1{\\hbox{\\...   \n",
              "\n",
              "                                             summary  \n",
              "0   Although we have convincing evidence that a b...  \n",
              "1   We argue that correct account of the quantum ...  \n",
              "2   We give a brief overview of black-hole soluti...  \n",
              "3   Taking into account the effect of self-intera...  \n",
              "4   It is argued that D=10 type II strings and M-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5300614a-3df7-418b-8819-d29ce8b9731f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n\\n \\let\\miguu=\\footnote\\n \\def\\footnote#1#2{...</td>\n",
              "      <td>Although we have convincing evidence that a b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nIn a modern Quantum Mechanics (QM) the parti...</td>\n",
              "      <td>We argue that correct account of the quantum ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\documentclass[12pt,a4paper]{article}\\n\\usepac...</td>\n",
              "      <td>We give a brief overview of black-hole soluti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe inflationary universe scenarios explain ...</td>\n",
              "      <td>Taking into account the effect of self-intera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\font\\mybb=msbm10 at 12pt\\n\\def\\bbxx#1{\\hbox{\\...</td>\n",
              "      <td>It is argued that D=10 type II strings and M-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5300614a-3df7-418b-8819-d29ce8b9731f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5300614a-3df7-418b-8819-d29ce8b9731f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5300614a-3df7-418b-8819-d29ce8b9731f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre['text'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n5wDyXzxyrr",
        "outputId": "1cf6f20b-a606-46fe-8427-7902fe51f21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \\n\\n \\let\\miguu=\\footnote\\n \\def\\footnote#1#2{...\n",
              "1    \\nIn a modern Quantum Mechanics (QM) the parti...\n",
              "2    \\documentclass[12pt,a4paper]{article}\\n\\usepac...\n",
              "3    \\nThe inflationary universe scenarios explain ...\n",
              "4    \\font\\mybb=msbm10 at 12pt\\n\\def\\bbxx#1{\\hbox{\\...\n",
              "5    \\input harvmac\\n\\n\\def\\eg{ e.g.,\\ }\\n\\def\\ie{ ...\n",
              "6    \\nIf one attempts to quantise fields on acausa...\n",
              "7    \\n\\n PACS numbers :04.20.Cv, 04.20.Fy, 04.20.M...\n",
              "8    \\nA fair amount of intuition about the kinemat...\n",
              "9    \\nBlack holes in 2-D space-times are toy model...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Cleaning the Data"
      ],
      "metadata": {
        "id": "Jv182GaNymEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#Removes non-alphabetic characters:\n",
        "def text_strip(column):\n",
        "    for row in column:\n",
        "        \n",
        "        # #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
        "        \n",
        "        # row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
        "        # row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
        "        # row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
        "        \n",
        "        # row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
        "        # row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
        "        # row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
        "        # row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
        "        # row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
        "        \n",
        "        # row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
        "        \n",
        "        # row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
        "        # row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
        "        # row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
        "        # row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
        "        \n",
        "        \n",
        "        # row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
        "        # row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
        "        # row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
        "        \n",
        "        # row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "        \n",
        "        # #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
        "        # try:\n",
        "        #     url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
        "        #     repl_url = url.group(3)\n",
        "        #     row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
        "        # except:\n",
        "        #     pass #there might be emails with no url in them\n",
        "        \n",
        "\n",
        "        \n",
        "        # row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
        "        \n",
        "        # #Should always be last\n",
        "        # row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "\n",
        "        \n",
        "        \n",
        "        yield row[::-1]"
      ],
      "metadata": {
        "id": "7_WdkhPSxyuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brief_cleaning1 = text_strip(pre['text'])\n",
        "brief_cleaning2 = text_strip(pre['summary'])"
      ],
      "metadata": {
        "id": "fW3zQHtUxywn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "# nlp.max_length = 1700000 \n",
        "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process:\n",
        "#If data loss seems to be happening(i.e len(text) = 50 instead of 75 etc etc) in this cell , decrease the batch_size parametre "
      ],
      "metadata": {
        "id": "2hRK_y8ywKFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "text = [str(doc) for doc in nlp.pipe(pre['text'][0], batch_size=5000,  n_process = -1)]\n",
        "\n",
        "# text = brief_cleaning1[::-1]\n",
        "# for x in brief_cleaning1:\n",
        "#   break\n",
        "# text = [str(doc) for doc in x]\n",
        "\n",
        "#Takes 7-8 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGofSkv8xyzH",
        "outputId": "9c3876ba-8484-47cd-d877-7611f86ce97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22 µs, sys: 0 ns, total: 22 µs\n",
            "Wall time: 37 µs\n",
            "Time to clean up everything: 0.0 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "\n",
        "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(brief_cleaning2, batch_size=5000)]\n",
        "#Takes 7-8 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSZxHy4tx-Gn",
        "outputId": "2bc5df73-743a-41c4-c022-f0fe653e70d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to clean up everything: 0.21 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwOqCuuDukJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "TrKtbK9Lx-J7",
        "outputId": "a752d5e6-a12c-4dfe-d818-d386585b2e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-50f3c185cf30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "LlOkdHZOx-Vk",
        "outputId": "9e3c12bd-aa16-4999-a06a-9ced14a0f806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'_START_  although we have convincing evidence that black hole bears an entropyproportional to its surface horizon area the ``statistical mechanical explanation of this entropy remains unknown two basic questions in thisconnection are what is the microscopic origin of the entropy and why does thelaw of entropy increase continue to hold when the horizon entropy is included after review of some of the difficulties in answering these questions ipropose an explanation of the law of entropy increase which comes near to aproof in the context of the ``semi-classical approximation and which alsoprovides proof in full quantum gravity under the assumption that the latterfulfills certain natural expectations like the existence of conserved energydefinable at infinity this explanation seems to require fundamentalspacetime discreteness in order for the entropy to be consistently finite andi recall briefly some of the ideas for what the discreteness might be if suchideas are right then our knowledge of the horizon entropy will allow us to``count the atoms of spacetime . _END_'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Determining the Maximum Permissible Sequence Lengths"
      ],
      "metadata": {
        "id": "7Z3plnmhzxDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre['cleaned_text'] = pd.Series(text)\n",
        "pre['cleaned_text'] = pre['text']\n",
        "pre['cleaned_summary'] = pd.Series(summary)"
      ],
      "metadata": {
        "id": "Grq9S40pxy1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_count = []\n",
        "summary_count = []"
      ],
      "metadata": {
        "id": "5Y_P75RQzWH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in pre['cleaned_text']:\n",
        "    text_count.append(len(sent.split()))\n",
        "for sent in pre['cleaned_summary']:\n",
        "    summary_count.append(len(sent.split()))"
      ],
      "metadata": {
        "id": "t6QzScvdzWKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "dbb76798-571e-4e70-d1ff-8b1b4cefac64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-2752f08cff5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msummary_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_df= pd.DataFrame()\n",
        "graph_df['text']=text_count\n",
        "graph_df['summary']=summary_count"
      ],
      "metadata": {
        "id": "38_tPt7WzWM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "graph_df.hist(bins = 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ScAKSFMrzcpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how much % of summary have 0-15 words\n",
        "cnt=0\n",
        "for i in pre['cleaned_summary']:\n",
        "    if(len(i.split())<=15):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(pre['cleaned_summary']))"
      ],
      "metadata": {
        "id": "T3nZE5bdzcrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how much % of text have 0-70 words\n",
        "cnt=0\n",
        "for i in pre['cleaned_text']:\n",
        "    if(len(i.split())<=100):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(pre['cleaned_text']))"
      ],
      "metadata": {
        "id": "WYZjqEJWzcu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
        "max_text_len=100\n",
        "max_summary_len=15"
      ],
      "metadata": {
        "id": "Vr3XFqp40Ahj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Selecting Plausible Texts and Summaries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xpu0414N0RUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the Summaries and Text between max len defined above\n",
        "\n",
        "cleaned_text =np.array(pre['cleaned_text'])\n",
        "cleaned_summary=np.array(pre['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "post_pre=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "metadata": {
        "id": "S2Fa1UW80Akn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_pre.head(2)"
      ],
      "metadata": {
        "id": "1PANVxPn0AnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_pre['summary'] = post_pre['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "metadata": {
        "id": "kpIJi3JC0YFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_pre.head(2)"
      ],
      "metadata": {
        "id": "1-UuiDCR0YIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Tokenizing the Text"
      ],
      "metadata": {
        "id": "7doX7wMF0joV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "metadata": {
        "id": "TgHYCPsH0YMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "metadata": {
        "id": "4u-ViAIz0sBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "id": "iX3TWXYb0sDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ],
      "metadata": {
        "id": "iISp9zBP0sF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "metadata": {
        "id": "XfUz8fyX0sIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "id": "atKj396-1Do6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "metadata": {
        "id": "PL2LWE_n1Dsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Removing Empty Texts and Summaries"
      ],
      "metadata": {
        "id": "9mSJeZ581RYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "metadata": {
        "id": "QdrnNlfJ1Dwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "metadata": {
        "id": "FWjNbI4F0sKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Creating the Model"
      ],
      "metadata": {
        "id": "je8quGjF1c1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K \n",
        "import gensim\n",
        "from numpy import *\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cczqqwWP1W_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Training the Model"
      ],
      "metadata": {
        "id": "qxwUWUiI1riN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "Q_vJBvYN1XBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "metadata": {
        "id": "wUhKZ_C51XEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [x_tr, y_tr[:, :-1]],\n",
        "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "    epochs=50,\n",
        "    callbacks=[es],\n",
        "    batch_size=128,\n",
        "    validation_data=([x_val, y_val[:, :-1]],\n",
        "                     y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:\n",
        "                     , 1:]),\n",
        "    )"
      ],
      "metadata": {
        "id": "F5__gNcD1xrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "TBV5-1Ud11v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "metadata": {
        "id": "oP_eHZMp11ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference Models\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
        "                      state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
        "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "DqOr6mZY1103"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "    # Encode the input as state vectors.\n",
        "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
        "                + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if sampled_token != 'eostok':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find the stop word.\n",
        "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
        "            >= max_summary_len - 1:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        (e_h, e_c) = (h, c)\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "i3FfktEt2BCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To convert sequence to summary\n",
        "def seq2summary(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0 and i != target_word_index['sostok'] and i \\\n",
        "            != target_word_index['eostok']:\n",
        "            newString = newString + reverse_target_word_index[i] + ' '\n",
        "\n",
        "    return newString\n",
        "\n",
        "\n",
        "# To convert sequence to text\n",
        "def seq2text(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0:\n",
        "            newString = newString + reverse_source_word_index[i] + ' '\n",
        "\n",
        "    return newString"
      ],
      "metadata": {
        "id": "Bw5iPRzs2BFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 19):\n",
        "    print ('Review:', seq2text(x_tr[i]))\n",
        "    print ('Original summary:', seq2summary(y_tr[i]))\n",
        "    print ('Predicted summary:', decode_sequence(x_tr[i].reshape(1,\n",
        "           max_text_len)))\n",
        "    print '\\n'"
      ],
      "metadata": {
        "id": "d1acdZew2BHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZiH448W2BJu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}